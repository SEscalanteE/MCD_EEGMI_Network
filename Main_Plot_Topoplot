{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205},{"sourceId":9807934,"sourceType":"datasetVersion","datasetId":5993939},{"sourceId":9814905,"sourceType":"datasetVersion","datasetId":6017386},{"sourceId":9815493,"sourceType":"datasetVersion","datasetId":6017842},{"sourceId":9817281,"sourceType":"datasetVersion","datasetId":6019130},{"sourceId":9839457,"sourceType":"datasetVersion","datasetId":5993000},{"sourceId":9848440,"sourceType":"datasetVersion","datasetId":6042771},{"sourceId":9848445,"sourceType":"datasetVersion","datasetId":6042776},{"sourceId":9848450,"sourceType":"datasetVersion","datasetId":6042780},{"sourceId":9983951,"sourceType":"datasetVersion","datasetId":6143856},{"sourceId":10014579,"sourceType":"datasetVersion","datasetId":6122737},{"sourceId":10092214,"sourceType":"datasetVersion","datasetId":6223333}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install cudnn --yes","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:06:53.433852Z","iopub.execute_input":"2024-11-05T22:06:53.434403Z","iopub.status.idle":"2024-11-05T22:08:33.34489Z","shell.execute_reply.started":"2024-11-05T22:06:53.434338Z","shell.execute_reply":"2024-11-05T22:08:33.343324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"i = 0\n\nmodel_ = ['TCFusion', 'DeepConv', 'EEGNet', 'ShallowConv', 'KCS-FCNet', 'KREEGNet'][i]\n\ntheta_band = [4,8]\nalpha_band = [8,13]\nbeta_band = [13,40]\n\nband = alpha_band\n\nPenultimate_layer = 1 #+ (model_ == 'EEGNet')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-05T22:08:33.3485Z","iopub.execute_input":"2024-11-05T22:08:33.349004Z","iopub.status.idle":"2024-11-05T22:08:33.356346Z","shell.execute_reply.started":"2024-11-05T22:08:33.348954Z","shell.execute_reply":"2024-11-05T22:08:33.35517Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git >/dev/null\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models@Marcos-L-patch-1\n!pip install -U git+https://github.com/keisen/tf-keras-vis\n!pip install -U keras\n!pip install -U tensorflow\n!pip install -U tf_keras","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:08:33.358134Z","iopub.execute_input":"2024-11-05T22:08:33.359355Z","iopub.status.idle":"2024-11-05T22:12:41.775166Z","shell.execute_reply.started":"2024-11-05T22:08:33.359296Z","shell.execute_reply":"2024-11-05T22:12:41.772613Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle as pkl\nimport os\nimport time\nfrom shutil import copy2\nimport json\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import cohen_kappa_score, roc_auc_score, accuracy_score, \\\n                            f1_score, recall_score, precision_score\nimport tensorflow_probability as tfp\nfrom scipy.signal import freqz, filtfilt, resample\nfrom scipy.signal import butter as bw\nfrom tf_keras_vis import layercam\nfrom tf_keras_vis.utils.model_modifiers import ReplaceToLinear\nfrom tf_keras_vis.utils.scores import CategoricalScore, InactiveScore\n\nfrom gcpds.databases import GIGA_MI_ME\nfrom gcpds.visualizations.topoplots import topoplot\nfrom EEG_Tensorflow_models.Models import DeepConvNet, ShallowConvNet, EEGNet, TCNet_fusion","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:41.778295Z","iopub.execute_input":"2024-11-05T22:12:41.778848Z","iopub.status.idle":"2024-11-05T22:12:53.7931Z","shell.execute_reply.started":"2024-11-05T22:12:41.778787Z","shell.execute_reply":"2024-11-05T22:12:53.791974Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#channels = ['Fp1','Fpz','Fp2',\n #            'AF7','AF3','AFz','AF4','AF8',\n  #           'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n   #          'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n    #         'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n     #        'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n      #       'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n       #      'PO7','PO3','POz','PO4','PO8',\n        #     'O1','Oz','O2',\n         #    'Iz']\n\nchannels = ['Fp1','Fp2',\n            'T7','C3','C4','T8',\n            'O1','O2']\n\n#channels = ['Fp1','Fp2',\n#            'F7','F3','F4','F8',\n#            'T7','C3','C4','T8',\n#            'P7','P3','P4','P8',\n#            'O1','O2']\n\n#channels = ['Fp1','Fp2',\n#             'AF3','AF4',\n#             'F7','F3','Fz','F4','F8',\n#             'FC5','FC1','FC2','FC6',\n#             'T7','C3','Cz','C4','T8',\n#             'CP5','CP1','CP2','CP6',\n#             'P7','P3','Pz','P4','P8',\n#             'PO3','PO4',\n#             'O1','Oz','O2']\n\nareas = {\n    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n    #'Central': ['Cz'],\n    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n}\n\narcs = [\n    #'hemispheres',\n    'areas',\n    'channels',\n]","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.796193Z","iopub.execute_input":"2024-11-05T22:12:53.79732Z","iopub.status.idle":"2024-11-05T22:12:53.809824Z","shell.execute_reply.started":"2024-11-05T22:12:53.797229Z","shell.execute_reply":"2024-11-05T22:12:53.808651Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\nload_args = dict(db = db,\n                 eeg_ch_names = channels,\n                 fs = db.metadata['sampling_rate'],\n                 f_bank = np.asarray([[4., 40.]]),\n                 vwt = np.asarray([[2.5, 5]]),\n                 new_fs = 128.)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.811403Z","iopub.execute_input":"2024-11-05T22:12:53.811798Z","iopub.status.idle":"2024-11-05T22:12:53.829699Z","shell.execute_reply.started":"2024-11-05T22:12:53.811756Z","shell.execute_reply":"2024-11-05T22:12:53.828496Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n  \"\"\"\n  Apply digital butterworth filter\n  INPUT\n  ------\n  1. X: (D array)\n    array with signals.\n  2. N: (int+)\n    The order of the filter.\n  3. Wn: (float+ or 1D array)\n    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n  4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n    The type of filter\n  5. fs: (float+)\n    The sampling frequency of the digital system.\n  6. axis: (int), Default=1.\n    The axis of x to which the filter is applied.\n  7. padtype: (str) or None, {'odd', 'even', 'constant'}\n    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n  8. padlen: (int+) or None, Default=0\n    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n  9. method: (str), {'pad', 'gust'}\n    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n  10. irlen: (int) or None, Default=nONE\n    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n    For a long signal, specifying irlen can significantly improve the performance of the filter.\n  OUTPUT\n  ------\n  X_fil: (D array)\n    array with filtered signals.\n  \"\"\"\n  b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n  return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\n\nclass TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n  \"\"\"\n  Time frequency representation of EEG signals.\n\n  Parameters\n  ----------\n    1. sfreq:  (float) Sampling frequency in Hz.\n    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n    3. vwt:    (2D array) Interest time windows. Default=None\n  Methods\n  -------\n    1. fit(X, y=None)\n    2. transform(X, y=None)\n  \"\"\"\n  def __init__(self, sfreq, f_bank=None, vwt=None):\n    self.sfreq = sfreq\n    self.f_bank = f_bank\n    self.vwt = vwt\n# ------------------------------------------------------------------------------\n\n  def _validation_param(self):\n    \"\"\"\n    Validate Time-Frequency characterization parameters.\n    INPUT\n    -----\n      1. self\n    ------\n      2. None\n    \"\"\"\n    if self.sfreq <= 0:\n      raise ValueError('Non negative sampling frequency is accepted')\n\n\n    if self.f_bank is None:\n      self.flag_f_bank = False\n    elif self.f_bank.ndim != 2:\n      raise ValueError('Band frequencies have to be a 2D array')\n    else:\n      self.flag_f_bank = True\n\n    if self.vwt is None:\n      self.flag_vwt = False\n    elif self.vwt.ndim != 2:\n      raise ValueError('Time windows have to be a 2D array')\n    else:\n      self.flag_vwt = True\n\n# ------------------------------------------------------------------------------\n  def _filter_bank(self, X):\n    \"\"\"\n    Filter bank Characterization.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n    OUTPUT\n    ------\n      1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n    \"\"\"\n    X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n    for f in np.arange(self.f_bank.shape[0]):\n      X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n    return X_f\n\n# ------------------------------------------------------------------------------\n  def _sliding_windows(self, X):\n    \"\"\"\n    Sliding Windows Characterization.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n    OUTPUT\n    ------\n      1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n    \"\"\"\n    window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n    X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n    for w in np.arange(self.vwt.shape[0]):\n        X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n    return X_w\n\n# ------------------------------------------------------------------------------\n  def fit(self, X, y=None):\n    \"\"\"\n    fit.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n      2. y: (1D array) target labels. Default=None\n    OUTPUT\n    ------\n      1. None\n    \"\"\"\n    pass\n\n# ------------------------------------------------------------------------------\n  def transform(self, X, y=None):\n    \"\"\"\n    Time frequency representation of EEG signals.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n    OUTPUT\n    ------\n      1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n    \"\"\"\n    self._validation_param()     #Validate sfreq, f_freq, vwt\n\n    #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n    if self.flag_f_bank:\n        X_f = self._filter_bank(X)\n    else:\n        X_f = X[:,:,:,np.newaxis]\n\n    if self.flag_vwt:\n      X_wf = []\n      for f in range(X_f.shape[3]):\n        X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n      X_wf = np.stack(X_wf, axis=-1)\n    else:\n      X_wf = X_f[:,:,:,np.newaxis,:]\n\n    return X_wf\n\ndef kappa(y_true, y_pred):\n    if len(y_true.shape) == 1:\n        return cohen_kappa_score(y_true, np.argmax(y_pred, axis = 1))\n    else:\n        return cohen_kappa_score(np.argmax(y_true, axis = 1), np.argmax(y_pred, axis = 1))","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.831894Z","iopub.execute_input":"2024-11-05T22:12:53.832412Z","iopub.status.idle":"2024-11-05T22:12:53.863295Z","shell.execute_reply.started":"2024-11-05T22:12:53.832333Z","shell.execute_reply":"2024-11-05T22:12:53.862009Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RFFKernel(tf.keras.layers.Layer):\n    def __init__(self, n_features=1, scale = None, **kwargs):\n        super().__init__(**kwargs)\n        self.n_features = n_features\n        self.initializer = tf.keras.initializers.Constant(value=scale)\n\n    def build(self, batch_input_shape):\n        self.sigma = self.add_weight(name = 'sigma_scale',\n                              shape = (),\n                              initializer = self.initializer,\n                              trainable = False)\n\n        self.features = self.add_weight(\n                        name=\"features\",\n                        shape=(batch_input_shape[2], self.n_features),\n                        dtype=tf.float32,\n                        initializer=tf.keras.initializers.RandomNormal(stddev=1.0),\n                        trainable=True,)\n\n        self.bias = self.add_weight(\n                        name=\"bias\",\n                        shape=(self.n_features,),\n                        dtype=tf.float32,\n                        initializer=tf.keras.initializers.RandomUniform(minval=0.0, maxval=2 * np.pi),\n                        trainable=True,)\n\n        super().build(batch_input_shape)\n\n    def call(self, X):\n        X = tf.transpose(X, perm  = (0, 3, 1, 2)) #(N, F, C, T)\n        X = X * self.sigma\n        phi = tf.matmul(a = X, b = self.features)\n        phi = tf.nn.bias_add(phi, self.bias)\n        phi = tf.cos(phi)\n        kernel = tf.matmul(phi, phi, transpose_b = True)\n        norm_kernel = tf.linalg.diag_part(kernel, )\n        norm_kernel = tf.expand_dims(norm_kernel,-1)\n        norm_kernel = tf.matmul(norm_kernel, norm_kernel, transpose_b=True)\n        norm_kernel = tf.math.sqrt(norm_kernel)\n        kernel = tf.math.divide(kernel, norm_kernel)\n        return kernel\n\nclass Triu(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n    def build(self, batch_input_shape):\n        self.dims = batch_input_shape\n        super().build(batch_input_shape)\n    def call(self, X):\n        dims = self.dims\n        ones = tf.ones(dims[2:]) #(C, C)\n        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n        triu = tf.boolean_mask(X, mask, axis = 2) #(N, F, C*(C-1)/2)\n        triu.set_shape((dims[0], dims[1], int(dims[2]*(dims[3]-1)/2)))\n        return triu\n    \nclass get_triu(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def build(self, batch_input_shape):\n        super().build(batch_input_shape)\n\n    def call(self, X): \n        N, F, C, C = X.shape\n        ones = tf.ones_like(X[0,0,...]) #(C, C)\n        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n        triu = tf.expand_dims(tf.boolean_mask(X, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n\n        triu.set_shape([N,F,int(C*(C-1)/2),1])\n        return triu\n\n    def compute_output_shape(self, batch_input_shape):\n        N, F, C, C = list(batch_input_shape)\n        return tf.TensorShape([N, F, int(C*(C-1)/2),1])\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {**base_config}","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.865028Z","iopub.execute_input":"2024-11-05T22:12:53.865458Z","iopub.status.idle":"2024-11-05T22:12:53.892019Z","shell.execute_reply.started":"2024-11-05T22:12:53.865416Z","shell.execute_reply":"2024-11-05T22:12:53.89039Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def centering(K):\n    n = K.shape[0]\n    unit = np.ones([n, n])\n    I = np.eye(n)\n    H = I - unit / n\n    return np.dot(np.dot(H, K), H)  # HKH are the same with KH, KH is the first centering, H(KH) do the second time, results are the sme with one time centering","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.89378Z","iopub.execute_input":"2024-11-05T22:12:53.894273Z","iopub.status.idle":"2024-11-05T22:12:53.908895Z","shell.execute_reply.started":"2024-11-05T22:12:53.894206Z","shell.execute_reply":"2024-11-05T22:12:53.90758Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_GIGA(db,\n              sbj,\n              eeg_ch_names,\n              fs,\n              f_bank,\n              vwt,\n              new_fs,\n              run=None):\n\n    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n    db.load_subject(sbj)\n    if run == None:\n        X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    else:\n        X, y = db.get_run(run, classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    X = X[:, index_eeg_chs, :] #spatial rearrangement\n    X = np.squeeze(tf_repr.transform(X))\n    #Resampling\n    if new_fs == fs:\n        pass#print('No resampling, since new sampling rate same.')\n    else:\n        #print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.910914Z","iopub.execute_input":"2024-11-05T22:12:53.911426Z","iopub.status.idle":"2024-11-05T22:12:53.922152Z","shell.execute_reply.started":"2024-11-05T22:12:53.911384Z","shell.execute_reply":"2024-11-05T22:12:53.920853Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_tuned_model(nb_classes: int,\n                    Chans: int,\n                    Samples: int,\n                    l1: int = 0,\n                    l2: int = 0,\n                    dropoutRate: float = 0.5,\n                    filters: int = 1,\n                    maxnorm: float = 2.0,\n                    maxnorm_last_layer: float = 0.5,\n                    kernel_time_1: int = 20,\n                    n_features: int = 1024,\n                    scale: float = 0.01,\n                    strid_filter_time_1: int = 1,\n                    bias_spatial: bool = False) -> tf.keras.Model:\n\n\n    input_main   = tf.keras.layers.Input((Chans, Samples, 1),name='Input')\n\n    block        = tf.keras.layers.Conv2D(filters,(1,kernel_time_1),strides=(1,strid_filter_time_1),\n                            use_bias=bias_spatial,\n                            kernel_constraint = tf.keras.constraints.max_norm(maxnorm, axis=(0,1,2))\n                            )(input_main)\n\n    block        = tf.keras.layers.BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n\n    block        = tf.keras.layers.Activation('elu')(block)\n\n    #*************************Kernel***********************************\n    kernels      = RFFKernel(n_features = n_features, scale = scale)(block)\n\n    block_triu   = Triu()(kernels)\n\n    block        = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,-1))(block_triu)\n    #*************************Kernel***********************************\n\n    block        = tf.keras.layers.AveragePooling2D(pool_size=(kernels.shape[1],1),strides=(1,1))(block)\n\n    block        = tf.keras.layers.BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n\n    block        = tf.keras.layers.Activation('elu')(block)\n\n    block        = tf.keras.layers.Flatten()(block)\n\n    block        = tf.keras.layers.Dropout(dropoutRate)(block)\n\n    block        = tf.keras.layers.Dense(nb_classes, kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1,l2=l2),name='logits',\n                              kernel_constraint = tf.keras.constraints.max_norm(maxnorm_last_layer)\n                              )(block)\n\n    softmax      = tf.keras.layers.Activation('softmax',name='output')(block)\n\n    model = tf.keras.Model(inputs=input_main, outputs=[softmax, kernels, ])#block_w])\n\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), loss=['categorical_crossentropy', None], loss_weights=[1.0, 0.0],)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.924217Z","iopub.execute_input":"2024-11-05T22:12:53.924744Z","iopub.status.idle":"2024-11-05T22:12:53.944208Z","shell.execute_reply.started":"2024-11-05T22:12:53.924686Z","shell.execute_reply":"2024-11-05T22:12:53.943017Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GFC(tf.keras.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def build(self, batch_input_shape):\n        self.gammad = self.add_weight(name = 'gammad',\n                                shape = (),\n                                initializer = 'zeros',\n                                trainable = True)\n        super().build(batch_input_shape)\n\n    def call(self, X): \n        X = tf.transpose(X, perm  = (0, 3, 1, 2)) #(N, F, C, T)\n        R = tf.reduce_sum(tf.math.multiply(X, X), axis = -1, keepdims = True) #(N, F, C, 1)\n        D  = R - 2*tf.matmul(X, X, transpose_b = (0, 1, 3, 2)) + tf.transpose(R, perm = (0, 1, 3, 2)) #(N, F, C, C)\n\n        ones = tf.ones_like(D[0,0,...]) #(C, C)\n        mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n        mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n        mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n        triu = tf.expand_dims(tf.boolean_mask(D, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n        sigma = tfp.stats.percentile(tf.math.sqrt(triu), 50, axis = 2, keepdims = True) #(N, F, 1, 1)\n\n        A = tf.math.exp(-1/(2*tf.pow(10., self.gammad)*tf.math.square(sigma))*D) #(N, F, C, C)\n        A.set_shape(D.shape)\n        return A\n\n    def compute_output_shape(self, batch_input_shape):\n        N, C, T, F = batch_input_shape#.as_list()\n        return tf.TensorShape([N, F, C, C])\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {**base_config}\n\ndef KREEGNet(number_of_classes: int,\n          number_of_channels: int,\n          number_of_time_samples: int, \n          dropout_rate: float,\n          kernLength: int,\n          F1: int, \n          D: int,\n          F2: int,\n          norm_rate: int,\n          dropout_type: str):\n    \"\"\" Keras Implementation of EEGNet\n    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n    Note that this implements the newest version of EEGNet and NOT the earlier\n    version (version v1 and v2 on arxiv). We strongly recommend using this\n    architecture as it performs much better and has nicer properties than\n    our earlier version. For example:\n        \n        1. Depthwise Convolutions to learn spatial filters within a \n        temporal convolution. The use of the depth_multiplier option maps \n        exactly to the number of spatial filters learned within a temporal\n        filter. This matches the setup of algorithms like FBCSP which learn \n        spatial filters within each filter in a filter-bank. This also limits \n        the number of free parameters to fit when compared to a fully-connected\n        convolution. \n        \n        2. Separable Convolutions to learn how to optimally combine spatial\n        filters across temporal bands. Separable Convolutions are Depthwise\n        Convolutions followed by (1x1) Pointwise Convolutions. \n        \n    \n    While the original paper used Dropout, we found that SpatialDropout2D \n    sometimes produced slightly better results for classification of ERP \n    signals. However, SpatialDropout2D significantly reduced performance \n    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n    the default Dropout in most cases.\n        \n    Assumes the input signal is sampled at 128Hz. If you want to use this model\n    for any other sampling rate you will need to modify the lengths of temporal\n    kernels and average pooling size in blocks 1 and 2 as needed (double the \n    kernel lengths for double the sampling rate, etc). Note that we haven't \n    tested the model performance with this rule so this may not work well. \n    \n    The model with default parameters gives the EEGNet-8,2 model as discussed\n    in the paper. This model should do pretty well in general, although it is\n\tadvised to do some model searching to get optimal performance on your\n\tparticular dataset.\n    We set F2 = F1 * D (number of input filters = number of output filters) for\n    the SeparableConv2D layer. We haven't extensively tested other values of this\n    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n    overcomplete). We believe the main parameters to focus on are F1 and D. \n    Inputs:\n        \n      nb_classes      : int, number of classes to classify\n      number_of_channels, number_of_time_samples  : number of channels and time points in the EEG data\n      dropout_rate     : dropout fraction\n      kernLength      : length of temporal convolution in first layer. We found\n                        that setting this to be half the sampling rate worked\n                        well in practice. For the SMR dataset in particular\n                        since the data was high-passed at 4Hz we used a kernel\n                        length of 32.     \n      F1, F2          : number of temporal filters (F1) and number of pointwise\n                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n      D               : number of spatial filters to learn within each temporal\n                        convolution. Default: D = 2\n      dropout_type     : Either SpatialDropout2D or Dropout, passed as a string.\n    \"\"\"\n    \n    if dropout_type == 'SpatialDropout2D':\n        dropout_type = tf.keras.layers.SpatialDropout2D\n    elif dropout_type == 'Dropout':\n        dropout_type = tf.keras.layers.Dropout\n    else:\n        raise ValueError('dropout_type must be one of SpatialDropout2D '\n                         'or Dropout, passed as a string.')\n    \n    input_   = tf.keras.layers.Input(shape = (number_of_channels, number_of_time_samples, 1))\n\n    ##################################################################\n    #Temporal Convolution\n    block1       = tf.keras.layers.Conv2D(F1, (1, kernLength), padding = 'same',\n                          name = 'Temporal_Conv2D',\n                          use_bias = False)(input_)\n    block1       = tf.keras.layers.BatchNormalization()(block1)\n    adj_mat      = GFC(name = 'gfc')(block1)\n    \n    ##################################################################\n    #Spatial Convolution\n    block1       = tf.keras.layers.DepthwiseConv2D((number_of_channels, 1),\n                                   name = 'Spatial_Depth_wise_Conv2D',\n                                   depth_multiplier = D,\n                                   use_bias = False, \n                                   depthwise_constraint = tf.keras.constraints.max_norm(1.))(block1)\n    block1       = tf.keras.layers.BatchNormalization()(block1)\n    block1       = tf.keras.layers.Activation('elu')(block1)\n    block1       = tf.keras.layers.AveragePooling2D((1, 4))(block1)\n    block1       = dropout_type(dropout_rate)(block1)\n    \n    ##################################################################\n    #Separable Convolution\n    block2       = tf.keras.layers.SeparableConv2D(F2, (1, 16), padding = 'same',\n                                   name = 'Separable_Conv2D',\n                                   use_bias = False)(block1)\n    block2       = tf.keras.layers.BatchNormalization()(block2)\n    block2       = tf.keras.layers.Activation('elu')(block2)\n    block2       = tf.keras.layers.AveragePooling2D((1, 8))(block2)\n    block2       = dropout_type(dropout_rate)(block2)\n    \n    ##################################################################\n    # Classification block\n    flatten      = tf.keras.layers.Flatten(name = 'flatten')(block2)\n    dense        = tf.keras.layers.Dense(number_of_classes, name = 'output', \n                         kernel_constraint = tf.keras.constraints.max_norm(norm_rate))(flatten)\n    softmax      = tf.keras.layers.Activation('softmax', name = 'out_activation')(dense)\n    \n    return tf.keras.Model(inputs=input_, outputs = [softmax, adj_mat])\n\n\ndef KCS_FCNet(nb_classes: int,\n              Chans: int,\n              Samples: int,\n              l1: int = 0, \n              l2: int = 0, \n              dropoutRate: float = 0.5,\n              filters: int = 1, \n              maxnorm: float = 2.0,\n              maxnorm_last_layer: float = 0.5,\n              kernel_time_1: int = 20,\n              strid_filter_time_1: int = 1,\n              bias_spatial: bool = False):\n\n\n    input_main   = tf.keras.layers.Input((Chans, Samples, 1),name='Input')                    \n    \n    block        = tf.keras.layers.Conv2D(filters,(1,kernel_time_1),strides=(1,strid_filter_time_1),\n                                            use_bias=bias_spatial,\n                                            kernel_constraint = tf.keras.constraints.max_norm(maxnorm, axis=(0,1,2))\n                                            )(input_main)\n    \n    block        = tf.keras.layers.BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n\n    block        = tf.keras.layers.Activation('elu')(block)      \n    \n    block        = GFC()(block)\n\n    block        = get_triu()(block)\n\n    block        = tf.keras.layers.AveragePooling2D(pool_size=(block.shape[1],1),strides=(1,1))(block)\n    \n    block        = tf.keras.layers.BatchNormalization(epsilon=1e-05, momentum=0.1)(block)\n\n    block        = tf.keras.layers.Activation('elu')(block) \n    \n    block        = tf.keras.layers.Flatten()(block)    \n\n    block        = tf.keras.layers.Dropout(dropoutRate)(block) \n\n    block        = tf.keras.layers.Dense(nb_classes, kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1,l2=l2),name='logits',\n                              kernel_constraint = tf.keras.constraints.max_norm(maxnorm_last_layer)\n                              )(block)\n\n    softmax      = tf.keras.layers.Activation('softmax',name='output')(block)\n    \n    return tf.keras.Model(inputs=input_main, outputs=softmax)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.946063Z","iopub.execute_input":"2024-11-05T22:12:53.946513Z","iopub.status.idle":"2024-11-05T22:12:53.98855Z","shell.execute_reply.started":"2024-11-05T22:12:53.94647Z","shell.execute_reply":"2024-11-05T22:12:53.987261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(path:str, model_args:dict) -> tf.keras.Model:\n    if path.endswith('.keras'):\n        os.system(f'unzip -o {path} -d ./tmp/')\n        path = './tmp/model.weights.h5'\n        with open('./tmp/config.json', 'rb') as f:\n            config = json.load(f)\n        model_args['n_features'] = config['config']['layers'][4]['config']['n_features']\n        model_args['scale'] = config['config']['layers'][4]['config']['scale']\n\n    model = get_tuned_model(**model_args)\n    model.load_weights(path)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:53.990289Z","iopub.execute_input":"2024-11-05T22:12:53.990693Z","iopub.status.idle":"2024-11-05T22:12:54.008991Z","shell.execute_reply.started":"2024-11-05T22:12:53.990652Z","shell.execute_reply":"2024-11-05T22:12:54.007562Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model(model_name, nb_classes = 2, weights_path = None):\n    if model_name == 'DeepConv':\n        model_params = dict(nb_classes = nb_classes,\n                          dropoutRate = 0.25, version='2018')\n        model = DeepConvNet(**model_params, Chans = 64, Samples = 320)\n        \n        if weights_path:\n            model.load_weights(weights_path)\n    elif model_name == 'ShallowConv':\n        model_params = dict(nb_classes = nb_classes,\n                          dropoutRate = 0.5,\n                          version = '2018')\n        model = ShallowConvNet(**model_params, Chans = 64, Samples = 320)\n        if weights_path:\n            model.load_weights(weights_path)\n    elif model_name == 'EEGNet':\n        model_params = dict(nb_classes = nb_classes,\n                          dropoutRate = 0.5,\n                          kernLength = 32,\n                          F1 = 8,\n                          D = 2,\n                          F2 = 16,\n                          norm_rate = 0.25,\n                          dropoutType = 'Dropout')\n        model = EEGNet(**model_params, Chans = 64, Samples = 320)\n        if weights_path:\n            model.load_weights(weights_path)\n    elif model_name == 'TCFusion':\n        model_params = dict(nb_classes = nb_classes,\n                          layers = 2,\n                          kernel_s = 4,\n                          filt = 12,\n                          dropout = 0.3,\n                          activation = 'relu',\n                          F1 = 24,\n                          D = 2,\n                          kernLength = 32,\n                          N_residuals = 2)\n        model = TCNet_fusion(**model_params, Chans = 8, Samples = 320)\n        if weights_path:\n            model.load_weights(weights_path)\n    elif model_name == 'KREEGNet':\n        model_params = dict(number_of_classes = 2,\n                          dropout_rate = 0.5,\n                          kernLength = int(load_args['new_fs']/4),\n                          F1 = 8,\n                          D = 2,\n                          F2 = 16,\n                          norm_rate = 0.25,\n                          dropout_type = 'Dropout')\n        model = KREEGNet(**model_params, number_of_channels = 64, number_of_time_samples = 320)\n        if weights_path:\n            model.load_weights(weights_path)\n    elif model_name == 'KCS-FCNet':\n        try:\n            model_params = dict(nb_classes = 2,\n                              dropoutRate = 0.5,\n                              kernel_time_1 = 50,\n                              strid_filter_time_1 = 1,\n                              filters = 4,\n                              maxnorm = 2.0,\n                              maxnorm_last_layer = 0.5,)\n            model = KCS_FCNet(**model_params, Chans = 64, Samples = 320)\n            if weights_path:\n                model.load_weights(weights_path)\n        except Exception as e:\n            error = str(e)\n            filters = error.index('Received: value.shape=(')+33\n            kernel_time = error.index('Received: value.shape=(')+26\n            model_params = dict(nb_classes = 2,\n                              dropoutRate = 0.5,\n                              kernel_time_1 = int(error[kernel_time:kernel_time + 2]),\n                              strid_filter_time_1 = 1,\n                              filters = int(error[filters:filters+1]),\n                              maxnorm = 2.0,\n                              maxnorm_last_layer = 0.5,)\n            model = KCS_FCNet(**model_params, Chans = 64, Samples = 320)\n            if weights_path:\n                model.load_weights(weights_path)\n    else:\n        model_args = dict(nb_classes = 2,\n                          Chans = 8,\n                          Samples = int(2.5*128),\n                          dropoutRate = 0.25,\n                          kernel_time_1 = int(128/4),\n                          filters = 3,)\n        model = load_model(weights_path, model_args)\n\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:54.014383Z","iopub.execute_input":"2024-11-05T22:12:54.014816Z","iopub.status.idle":"2024-11-05T22:12:54.036224Z","shell.execute_reply.started":"2024-11-05T22:12:54.014775Z","shell.execute_reply":"2024-11-05T22:12:54.034911Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def band_cam(cam, fs=128, fc1=4,fc2=40):\n    vfreq = np.fft.rfftfreq(cam.shape[2], 1/fs)\n    f_ = (vfreq >=fc1) & (vfreq<=fc2) #frequency band\n    \n    cam_f = np.fft.rfft(cam, axis=2) # Fourier of CAM\n    #cam_f_ = abs(cam_f) #Find magnitudes\n    cam_f[:,:,~f_] = 0 # Filter CAM spectrum\n    \n    cam_t = np.fft.irfft(cam_f,axis=2) #Return EEG to time representation\n    return cam_t","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:54.038011Z","iopub.execute_input":"2024-11-05T22:12:54.038594Z","iopub.status.idle":"2024-11-05T22:12:54.05347Z","shell.execute_reply.started":"2024-11-05T22:12:54.03853Z","shell.execute_reply":"2024-11-05T22:12:54.052118Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_sbj = 50\nsubjects = np.arange(52)+1\nsubjects = np.delete(subjects,[28,33]) # delete 29 and 34\n\ntry:\n    os.mkdir(f'./{model_}_CAMs_Channels_{len(channels)}')\n    for i in range(5):\n        os.mkdir(f'./{model_}_CAMs_Channels_{len(channels)}/Fold_{i}')\nexcept Exception as e:\n    print(str(e))","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:54.055181Z","iopub.execute_input":"2024-11-05T22:12:54.055743Z","iopub.status.idle":"2024-11-05T22:12:54.071448Z","shell.execute_reply.started":"2024-11-05T22:12:54.05569Z","shell.execute_reply":"2024-11-05T22:12:54.070187Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#os.environ[\"GRPC_VERBOSITY\"] = \"NONE\"\n# Now we want to know which hyper parameter produced the best model\n# Once we know this we can load that model from the models folder\nC = len(channels)\nmetrics = {}\ntest_subjects = [1,2,3,4,5,6,7,8,9,\n                 10,11,12,13,14,15,16,17,18,19,\n                 20,21,22,24,25,26,27,28,\n                 30,31,33,35,36,37,38,39,\n                 40,41,42,43,44,45,47,48,\n                 50,51,52]# [49,46,34,32,29]#\n\nfor sbj in test_subjects:\n    print(f'Sbj: {sbj}')\n    start_time = time.time()\n    \n    X_train, y_train = load_GIGA(sbj=sbj, **load_args)\n    X_train = np.expand_dims(X_train, -1)\n\n    SSS = StratifiedShuffleSplit(n_splits = 5, test_size=0.2, random_state = 23)\n    partitions = list(SSS.split(X_train, y_train))\n            \n    y_train = tf.keras.utils.to_categorical(y_train, 2)\n    for fold in range(5):\n        print(f'Fold {fold+1}/5')\n        X_fold = X_train[partitions[fold][0]]\n        y_fold = y_train[partitions[fold][0]]\n        X_test = X_train[partitions[fold][1]]\n        y_test = np.argmax(y_train[partitions[fold][1]], axis=1)\n        \n        try:\n            os.mkdir(f'./{model_}_CAMs_Channels_{len(channels)}/Fold_{fold}/Sbj{sbj}')\n        except Exception as e:\n            print(str(e))\n        \n        reduce_lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 30, verbose = 0, mode = 'min', min_delta = 0.01, min_lr = 0)\n        terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n        callbacks = [reduce_lr_on_plateau, terminate_on_nan]\n\n        model = get_model(model_)\n        \n        model.compile(loss = 'binary_crossentropy')\n\n#         model.fit(X_fold, y_fold,\n#                  epochs = 500,\n#                  verbose = 0,\n#                  batch_size= X_fold.shape[0],\n#                  callbacks = callbacks,\n#                  )\n        \n        model.load_weights(f'/kaggle/input/tcnet-fusion-8-channels-all/sbj{sbj}.h5')\n        \n        no_softmax_model = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n        \n\n        lc = layercam.Layercam(model, model_modifier=ReplaceToLinear(), clone=False)\n        \n        true_cam = lc(score = [CategoricalScore(list(y_test)),],\n                            seed_input = X_test,\n                            penultimate_layer = Penultimate_layer,\n                            seek_penultimate_conv_layer = True,\n                            normalize_cam = False,\n                            expand_cam = True\n                            )\n        false_cam = lc(score = [CategoricalScore(list(np.abs(y_test-1))),],\n                            seed_input = X_test,\n                            penultimate_layer = Penultimate_layer,\n                            seek_penultimate_conv_layer = True,\n                            normalize_cam = False,\n                            expand_cam = True\n                            )\n        np.savez(f'{model_}_CAMs_Channels_{len(channels)}/Fold_{fold}/Sbj{sbj}/Sbj{sbj}_TrueCams',true_cam)\n        np.savez(f'{model_}_CAMs_Channels_{len(channels)}/Fold_{fold}/Sbj{sbj}/Sbj{sbj}_FalseCams',false_cam)\n        \n        v_true_cam = np.mean(np.sum(np.abs(true_cam),axis=-1),axis=0)\n        v_false_cam = np.mean(np.sum(np.abs(false_cam),axis=-1),axis=0)\n        print(v_true_cam.shape)\n        print(v_false_cam.shape)\n        \n        fig, ax = plt.subplots()\n        topoplot(v_true_cam,channels,show=True,names=channels,cmap='viridis')\n        fig.suptitle('True CAM Subject ' + str(sbj))\n        fig.savefig(f'{model_}_CAMs_Channels_{len(channels)}/Fold_{fold}/Sbj{sbj}/True_CAM_{model_}_Subject_{sbj}.svg')\n        \n        fig, ax = plt.subplots()\n        topoplot(v_false_cam,channels,show=True,names=channels,cmap='viridis')\n        fig.suptitle('False CAM Subject ' + str(sbj))\n        fig.savefig(f'{model_}_CAMs_Channels_{len(channels)}/Fold_{fold}/Sbj{sbj}/False_CAM_{model_}_Subject_{sbj}.svg')\n\n        #max_val_cams = np.max(np.concatenate((true_cam[...,np.newaxis],\n        #                                      false_cam[...,np.newaxis]), axis=-1),\n        #                      axis=(1,2,3))[:,np.newaxis,np.newaxis]\n        \n        #norm_cam_pos = true_cam / max_val_cams\n        #norm_cam_neg = false_cam / max_val_cams\n        \n        #x_feedback_pos = X_test*(norm_cam_pos[...,np.newaxis]*2+1)\n        #x_feedback_neg = X_test*(norm_cam_neg[...,np.newaxis]*2+1)\n        \n        #score_cam_pos = no_softmax_model.predict(x_feedback_pos, verbose = 0) # Trials x Clases\n        #score_cam_neg = no_softmax_model.predict(x_feedback_neg, verbose = 0) # Trials x Clases\n        \n        #joint_cams = np.append(score_cam_pos[...,np.newaxis], score_cam_neg[...,np.newaxis], axis=-1)\n        #activation_cam = np.zeros(score_cam_pos.shape)\n        #max_cam_list = []\n        #for i in range(activation_cam.shape[0]):\n        #    max_output = int(np.argmax(joint_cams[i].T)/2)\n        #    max_cam_list += [max_output]\n        #    activation_cam[i] = joint_cams[i,:,max_output]\n        \n        #y_pred_original = model.predict(X_test)\n        #y_pred_feedback = tf.nn.softmax(activation_cam)\n        #sparse_acc_original = tf.keras.metrics.SparseCategoricalAccuracy()\n        #sparse_acc_feedback = tf.keras.metrics.SparseCategoricalAccuracy()\n\n        #sparse_acc_original.update_state(y_test, y_pred_original)\n        #sparse_acc_feedback.update_state(y_test, y_pred_feedback)\n        \n        #metrics['acc_before'] = sparse_acc_original.result()\n        #metrics['auc_before'] = roc_auc_score(y_test, np.argmax(y_pred_original, axis=1))\n        #metrics['kappa_before'] = kappa(y_test, y_pred_original)\n        #metrics['acc_after'] = sparse_acc_feedback.result()\n        #metrics['auc_after'] = roc_auc_score(y_test, np.argmax(y_pred_feedback, axis=1))\n        #metrics['kappa_after'] = kappa(y_test, y_pred_feedback)\n        #metrics['cams_used'] = max_cam_list\n        \n        #with open(f'{model_}_CAMs/Fold_{fold}/Sbj{sbj}/Sbj{sbj}_metrics.pkl', 'wb') as f:\n        #    pkl.dump(metrics, f)\n\n        #print(f'Before: {sparse_acc_original.result():0.2f}; After:{sparse_acc_feedback.result():0.2f}; Occlusion: {0.0}')\nprint(f'Final time: {time.time()-start_time}')","metadata":{"execution":{"iopub.status.busy":"2024-11-05T22:12:54.073493Z","iopub.execute_input":"2024-11-05T22:12:54.074058Z"},"trusted":true},"outputs":[],"execution_count":null}]}