{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7474407f",
   "metadata": {
    "id": "x9LNzEYERaH2",
    "papermill": {
     "duration": 0.00501,
     "end_time": "2024-12-12T16:11:15.533739",
     "exception": false,
     "start_time": "2024-12-12T16:11:15.528729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d156f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:15.543141Z",
     "iopub.status.busy": "2024-12-12T16:11:15.542716Z",
     "iopub.status.idle": "2024-12-12T16:11:16.715570Z",
     "shell.execute_reply": "2024-12-12T16:11:16.714064Z"
    },
    "papermill": {
     "duration": 1.180598,
     "end_time": "2024-12-12T16:11:16.718331",
     "exception": false,
     "start_time": "2024-12-12T16:11:15.537733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12214ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:16.728243Z",
     "iopub.status.busy": "2024-12-12T16:11:16.727824Z",
     "iopub.status.idle": "2024-12-12T16:12:41.770077Z",
     "shell.execute_reply": "2024-12-12T16:12:41.768479Z"
    },
    "id": "K0oS6IH7VTZX",
    "papermill": {
     "duration": 85.050644,
     "end_time": "2024-12-12T16:12:41.773079",
     "exception": false,
     "start_time": "2024-12-12T16:11:16.722435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n",
    "!pip install mne #The MNE Package is installed\n",
    "FILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip MI_EEG_ClassMeth.zip #Package with useful functions for motor imagery classification based in EEG.\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5707fb32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:12:41.783205Z",
     "iopub.status.busy": "2024-12-12T16:12:41.782769Z",
     "iopub.status.idle": "2024-12-12T16:14:14.736194Z",
     "shell.execute_reply": "2024-12-12T16:14:14.733836Z"
    },
    "papermill": {
     "duration": 92.96204,
     "end_time": "2024-12-12T16:14:14.739342",
     "exception": false,
     "start_time": "2024-12-12T16:12:41.777302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "E: Unable to locate package libcudnn8\r\n",
      "Collecting tensorflow==2.8.2\r\n",
      "  Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (24.3.25)\r\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.11.0)\r\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.2)\r\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (18.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.3.0)\r\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.8.2)\r\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.16.0)\r\n",
      "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow==2.8.2)\r\n",
      "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.2)\r\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.37.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.64.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.2) (0.43.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.30.0)\r\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.6)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.32.3)\r\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.0.4)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2024.8.30)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.5)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.6.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.2)\r\n",
      "Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl (498.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\r\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tensorflow-estimator, tensorboard-plugin-wit, keras, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\r\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "  Attempting uninstall: tensorboard-data-server\r\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\r\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\r\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: google-auth-oauthlib\r\n",
      "    Found existing installation: google-auth-oauthlib 1.2.0\r\n",
      "    Uninstalling google-auth-oauthlib-1.2.0:\r\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.0\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.16.2\r\n",
      "    Uninstalling tensorboard-2.16.2:\r\n",
      "      Successfully uninstalled tensorboard-2.16.2\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.16.1\r\n",
      "    Uninstalling tensorflow-2.16.1:\r\n",
      "      Successfully uninstalled tensorflow-2.16.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-language 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-videointelligence 2.13.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "onnx 1.17.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.8.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.2 tensorflow-estimator-2.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 -y\n",
    "!pip install tensorflow==2.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097bb8da",
   "metadata": {
    "papermill": {
     "duration": 0.014452,
     "end_time": "2024-12-12T16:14:14.771523",
     "exception": false,
     "start_time": "2024-12-12T16:14:14.757071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe05adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:14:14.805995Z",
     "iopub.status.busy": "2024-12-12T16:14:14.804760Z",
     "iopub.status.idle": "2024-12-12T16:14:25.387652Z",
     "shell.execute_reply": "2024-12-12T16:14:25.386555Z"
    },
    "id": "yE1sbHYQVbBq",
    "papermill": {
     "duration": 10.604143,
     "end_time": "2024-12-12T16:14:25.390274",
     "exception": false,
     "start_time": "2024-12-12T16:14:14.786131",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gcpds.databases.BCI_Competition_IV import Dataset_2a\n",
    "from typing import Sequence, Tuple\n",
    "from MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "\n",
    "def load_BCICIV2a(db: Dataset_2a,\n",
    "               sbj: int,\n",
    "               mode: str,\n",
    "               fs: float, \n",
    "               f_bank: np.ndarray, \n",
    "               vwt: np.ndarray, \n",
    "               new_fs: float) -> np.ndarray:\n",
    "\n",
    "  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
    "\n",
    "  db.load_subject(sbj, mode = mode)\n",
    "    \n",
    "  X, y = db.get_data() #Load all classes, all channels {EEG, EOG}, reject bad trials\n",
    "\n",
    "  X = X[:,:-3,:] # pick EEG channels\n",
    "  X = X*1e6 #uV\n",
    "  X = np.squeeze(tf_repr.transform(X))\n",
    "  #Resampling\n",
    "  if new_fs == fs:\n",
    "    print('No resampling, since new sampling rate same.')\n",
    "  else:\n",
    "    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
    "    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
    "    \n",
    "  return X, y\n",
    "\n",
    "\n",
    "from gcpds.databases import GIGA_MI_ME\n",
    "\n",
    "def load_GIGA_MI_ME(db: GIGA_MI_ME,\n",
    "              sbj: int,\n",
    "              eeg_ch_names: Sequence[str],\n",
    "              fs: float, \n",
    "              f_bank: np.ndarray, \n",
    "              vwt: np.ndarray, \n",
    "              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    index_eeg_chs = db.format_channels_selectors(channels=eeg_ch_names) - 1\n",
    "\n",
    "    tf_repr = TimeFrequencyRpr(sfreq=fs, f_bank=f_bank, vwt=vwt)\n",
    "\n",
    "    # Load subject data\n",
    "    db.load_subject(sbj)\n",
    "    X, y = db.get_data(classes=['left hand mi', 'right hand mi'])\n",
    "    \n",
    "    # Debugging total trials\n",
    "    print(f\"Total trials loaded: {X.shape[0]}\")\n",
    "    print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
    "\n",
    "    # Spatial rearrangement\n",
    "    X = X[:, index_eeg_chs, :]  \n",
    "    X = np.squeeze(tf_repr.transform(X))\n",
    "\n",
    "    # Resampling\n",
    "    if new_fs == fs:\n",
    "        print('No resampling, since new sampling rate is the same.')\n",
    "    else:\n",
    "        print(f\"Resampling from {fs} to {new_fs} Hz.\")\n",
    "        X = resample(X, int((X.shape[-1] / fs) * new_fs), axis=-1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def load_DB(db_name, **load_args):\n",
    "  if db_name == 'BCICIV2a':\n",
    "    X_train, y_train = load_BCICIV2a(**load_args, mode = 'training')\n",
    "    X_test, y_test = load_BCICIV2a(**load_args, mode = 'evaluation')\n",
    "\n",
    "    X_train = np.concatenate([X_train, X_test], axis = 0)\n",
    "    y_train = np.concatenate([y_train, y_test], axis = 0)\n",
    "\n",
    "  elif db_name == 'GIGA_MI_ME':\n",
    "    X_train, y_train = load_GIGA_MI_ME(**load_args)\n",
    "    \n",
    "  else:\n",
    "    raise ValueError('No valid database name')\n",
    "\n",
    "  return X_train, y_train\n",
    "\n",
    "\n",
    "from EEG_Tensorflow_models.Models import DeepConvNet, ShallowConvNet, EEGNet, DMTL_BCI, TCNet_fusion, PST_attention\n",
    "\n",
    "\n",
    "def get_model(model_name, nb_classes):\n",
    "  if model_name == 'DeepConvNet':\n",
    "    model = DeepConvNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5, version='2018')\n",
    "    \n",
    "  elif model_name == 'ShallowConvNet':\n",
    "    model = ShallowConvNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      version = '2018')\n",
    "    \n",
    "  elif model_name == 'EEGNet':\n",
    "    model = EEGNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      kernLength = 32,\n",
    "                      F1 = 8,\n",
    "                      D = 2,\n",
    "                      F2 = 16,\n",
    "                      norm_rate = 0.25, \n",
    "                      dropoutType = 'Dropout')\n",
    "    \n",
    "  elif model_name == 'DMTL_BCI':\n",
    "    model = DMTL_BCI\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      l1 = 0,\n",
    "                      l2 = 0)\n",
    "    \n",
    "  elif model_name == 'TCNet_fusion':\n",
    "    model = TCNet_fusion\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      layers = 2,\n",
    "                      kernel_s = 4,\n",
    "                      filt = 12,\n",
    "                      dropout = 0.3,\n",
    "                      activation = 'relu',\n",
    "                      F1 = 24,\n",
    "                      D = 2,\n",
    "                      kernLength = 32,\n",
    "                      N_residuals = 2)\n",
    "    \n",
    "  elif model_name == 'PST_attention':\n",
    "    model = PST_attention\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      last_layer = 'Dense')\n",
    "    \n",
    "  else:\n",
    "    raise ValueError('No valid model name')\n",
    "    \n",
    "  return model, model_params\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score,\\\n",
    "                            f1_score, recall_score, precision_score\n",
    "\n",
    "def train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed):\n",
    "    X_train, y_train = load_DB(db_name, **load_args)\n",
    "    X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    \n",
    "    cv_results = {'params': [],\n",
    "                  'mean_acc': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_kappa': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_auc': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_f1_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_f1_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_recall_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_recall_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_precision_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_precision_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'all_folds': []}\n",
    "    \n",
    "    k = 0\n",
    "    max_acc = -np.inf\n",
    "\n",
    "    # Loop through folds\n",
    "    for train_index, val_index in cv_args['cv'].split(X_train, y_train):\n",
    "        print(f\"Running fold {k} with {len(train_index)} training samples and {len(val_index)} validation samples\")\n",
    "        print(f\"Fold {k}: train indices: {train_index[:5]}, val indices: {val_index[:5]}\")  # Print first indices\n",
    "        \n",
    "        X, X_val = X_train[train_index], X_train[val_index]\n",
    "        y, y_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        if model_args['autoencoder']:\n",
    "            y = [X, y]\n",
    "        \n",
    "        print(f\"Training data shape: {X.shape}, Validation data shape: {X_val.shape}\")\n",
    "        \n",
    "        batch_size, C, T = X.shape[:-1]\n",
    "        clear_session()\n",
    "        set_seed(seed)\n",
    "\n",
    "        model_cll, model_params = get_model(model_args['model_name'], model_args['nb_classes'])\n",
    "        model = model_cll(**model_params, Chans=64, Samples=T)\n",
    "        model.compile(loss=compile_args['loss'], optimizer=Adam(compile_args['init_lr']))\n",
    "\n",
    "        history = model.fit(X, y, batch_size=batch_size, **fit_args)\n",
    "        print(f\"Fold {k} training loss: {history.history['loss'][-1]}\")  # Print final loss\n",
    "\n",
    "        if model_args['autoencoder']:\n",
    "            y_prob = model.predict(X_val)[-1]\n",
    "        else:\n",
    "            y_prob = model.predict(X_val)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "        print(f\"y_true (val): {y_val[:5]}\")\n",
    "        print(f\"y_pred: {y_pred[:5]}\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        kappa = cohen_kappa_score(y_val, y_pred)\n",
    "        auc = roc_auc_score(y_val, y_prob[:, 1], average='macro') if model_args['nb_classes'] == 2 else None\n",
    "        \n",
    "        # Save metrics for this fold\n",
    "        fold_result = {\n",
    "            'fold_index': k,\n",
    "            'train_indices': train_index.tolist(),\n",
    "            'val_indices': val_index.tolist(),\n",
    "            'accuracy': acc,\n",
    "            'kappa': kappa,\n",
    "            'auc': auc\n",
    "        }\n",
    "        print(f\"Appending results for fold {k}: {fold_result}\")\n",
    "        cv_results['all_folds'].append(fold_result)\n",
    "\n",
    "        # Update overall fold metrics\n",
    "        cv_results['mean_acc'][k] = acc\n",
    "        cv_results['mean_kappa'][k] = kappa\n",
    "        if auc is not None:\n",
    "            cv_results['mean_auc'][k] = auc\n",
    "        \n",
    "        # Save the best model weights\n",
    "        if acc > max_acc:\n",
    "            print('New Max Found!')\n",
    "            max_acc = acc\n",
    "            model.save_weights(f'sbj{load_args[\"sbj\"]}.h5')\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    # Calculate mean and std metrics\n",
    "    cv_results['std_acc'] = round(cv_results['mean_acc'].std(), 3)\n",
    "    cv_results['mean_acc'] = round(cv_results['mean_acc'].mean(), 3)\n",
    "    cv_results['std_kappa'] = round(cv_results['mean_kappa'].std(), 3)\n",
    "    cv_results['mean_kappa'] = round(cv_results['mean_kappa'].mean(), 3)\n",
    "    cv_results['std_auc'] = round(cv_results['mean_auc'].std(), 3)\n",
    "    cv_results['mean_auc'] = round(cv_results['mean_auc'].mean(), 3)\n",
    "    \n",
    "    print(f\"Final cross-validation results: {cv_results}\")\n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00fc1b",
   "metadata": {
    "id": "uBAeW6J5S68g",
    "papermill": {
     "duration": 0.014573,
     "end_time": "2024-12-12T16:14:25.420012",
     "exception": false,
     "start_time": "2024-12-12T16:14:25.405439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44040653",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:14:25.452654Z",
     "iopub.status.busy": "2024-12-12T16:14:25.451894Z",
     "iopub.status.idle": "2024-12-12T16:14:25.458078Z",
     "shell.execute_reply": "2024-12-12T16:14:25.456849Z"
    },
    "id": "2I3IQnNSS9-a",
    "papermill": {
     "duration": 0.02507,
     "end_time": "2024-12-12T16:14:25.460200",
     "exception": false,
     "start_time": "2024-12-12T16:14:25.435130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Marcos, use these two variables to run the state of the art. First, for BCICIV2a run all the models.\n",
    "# Remeber that this network DMTL_BCI is an autoencoder. Set the nb_classses parameter depending of the database.\n",
    "# set autoencoder based on the model\n",
    "# We need to run all these tests again. Do not forget to add the recall, preci, and f1 for each class (bci 4, giga 2)\n",
    "db_name = 'GIGA_MI_ME'\n",
    "model_args = dict(model_name = 'EEGNet',\n",
    "                  nb_classes = 2,\n",
    "                  autoencoder = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9847ff53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:14:25.491111Z",
     "iopub.status.busy": "2024-12-12T16:14:25.490671Z",
     "iopub.status.idle": "2024-12-12T16:14:25.507628Z",
     "shell.execute_reply": "2024-12-12T16:14:25.506526Z"
    },
    "id": "tqMhUFoBIc3B",
    "outputId": "1405fd59-1374-4d5d-8e3a-5e7a45c79bba",
    "papermill": {
     "duration": 0.03552,
     "end_time": "2024-12-12T16:14:25.510072",
     "exception": false,
     "start_time": "2024-12-12T16:14:25.474552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TerminateOnNaN\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "if db_name == 'BCICIV2a':\n",
    "  db = Dataset_2a('/kaggle/input/dataset-2a')\n",
    "  fs = db.metadata['sampling_rate']\n",
    "  load_args = dict(db = db,\n",
    "                 fs = fs,\n",
    "                 f_bank = np.asarray([[4., 40.]]),\n",
    "                 vwt = np.asarray([[2.5, 6]]),\n",
    "                 new_fs = 128.)\n",
    "  subjects = np.arange(db.metadata['subjects']) + 1\n",
    "  \n",
    "elif db_name == 'GIGA_MI_ME':\n",
    "  db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n",
    "  fs = db.metadata['sampling_rate']\n",
    "  \n",
    "    \n",
    "  eeg_ch_names = ['Fp1','Fpz','Fp2',\n",
    "                 'AF7','AF3','AFz','AF4','AF8',\n",
    "                'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
    "               'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n",
    "                'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
    "               'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n",
    "                'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n",
    "                'PO7','PO3','POz','PO4','PO8',\n",
    "                'O1','Oz','O2',\n",
    "                'Iz']\n",
    "\n",
    " # eeg_ch_names = ['Fp1','Fp2',\n",
    " #                'T7','C3','C4','T8',\n",
    " #                'O1','O2']\n",
    "\n",
    " # eeg_ch_names = ['Fp1','Fp2',\n",
    " #               'F7','F3','F4','F8',\n",
    " #               'T7','C3','C4','T8',\n",
    " #               'P7','P3','P4','P8',\n",
    " #               'O1','O2']\n",
    "\n",
    " # eeg_ch_names = ['Fp1','Fp2',\n",
    " #                'AF3','AF4',\n",
    " #                'F7','F3','Fz','F4','F8',\n",
    " #                'FC5','FC1','FC2','FC6',\n",
    " #                'T7','C3','Cz','C4','T8',\n",
    " #                'CP5','CP1','CP2','CP6',\n",
    " #                'P7','P3','Pz','P4','P8',\n",
    " #                'PO3','PO4',\n",
    " #                'O1','Oz','O2']\n",
    "\n",
    "\n",
    "  load_args = dict(db = db,\n",
    "                  eeg_ch_names = eeg_ch_names,\n",
    "                  fs = fs,\n",
    "                  f_bank = np.asarray([[4., 40.]]),\n",
    "                  vwt = np.asarray([[2.5, 5]]),\n",
    "                  new_fs = 128.)\n",
    "  subjects = np.arange(db.metadata['subjects']) + 1\n",
    "  subjects = np.delete(subjects, [28,33])\n",
    "  \n",
    "else:\n",
    "  raise ValueError('No valid database name')\n",
    "\n",
    "verbose = 0\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 30, verbose = verbose, mode = 'min', min_delta = 0.01, min_lr = 0)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "callbacks = [reduce_lr_on_plateau, terminate_on_nan]\n",
    "seed = 23\n",
    "\n",
    "cv_args = dict(cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.2, random_state = seed))\n",
    "\n",
    "compile_args = dict(loss = SparseCategoricalCrossentropy(), #['mse' , SparseCategoricalCrossentropy()]\n",
    "                    init_lr = 1e-2)\n",
    "                      \n",
    "fit_args = dict(epochs = 500,\n",
    "                verbose = verbose,\n",
    "                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3605abb7",
   "metadata": {
    "id": "ukhXifxzTaj9",
    "papermill": {
     "duration": 0.013961,
     "end_time": "2024-12-12T16:14:25.538618",
     "exception": false,
     "start_time": "2024-12-12T16:14:25.524657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd722fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:14:25.568740Z",
     "iopub.status.busy": "2024-12-12T16:14:25.568336Z",
     "iopub.status.idle": "2024-12-12T19:57:37.691227Z",
     "shell.execute_reply": "2024-12-12T19:57:37.688023Z"
    },
    "id": "Ymqd_W21y3NK",
    "outputId": "5ca97a2f-f57c-46ee-8f53-f00181ccea90",
    "papermill": {
     "duration": 13392.142784,
     "end_time": "2024-12-12T19:57:37.695445",
     "exception": false,
     "start_time": "2024-12-12T16:14:25.552661",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbj =  47\n",
      "Total trials loaded: 192\n",
      "Shape of X: (192, 64, 3584), Shape of y: (192,)\n",
      "Resampling from 512 to 128.0 Hz.\n",
      "X_train shape: (192, 64, 320, 1), y_train shape: (192,)\n",
      "Running fold 0 with 153 training samples and 39 validation samples\n",
      "Fold 0: train indices: [177 163  46 143  13], val indices: [135  40 148  49  31]\n",
      "Training data shape: (153, 64, 320, 1), Validation data shape: (39, 64, 320, 1)\n",
      "Fold 0 training loss: 0.1380750685930252\n",
      "y_true (val): [1 0 1 0 0]\n",
      "y_pred: [1 0 1 0 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [177, 163, 46, 143, 13, 11, 80, 65, 56, 14, 88, 113, 15, 4, 7, 79, 41, 67, 42, 154, 74, 18, 93, 159, 111, 138, 162, 184, 99, 170, 68, 133, 36, 178, 30, 0, 48, 72, 155, 175, 19, 47, 171, 181, 86, 24, 141, 55, 137, 109, 173, 23, 34, 145, 37, 183, 185, 166, 1, 103, 28, 146, 167, 153, 102, 77, 16, 100, 27, 29, 97, 52, 176, 59, 186, 124, 182, 140, 78, 120, 101, 125, 149, 17, 81, 91, 60, 84, 110, 115, 71, 8, 33, 160, 188, 62, 26, 106, 32, 5, 187, 20, 38, 44, 165, 122, 70, 2, 104, 108, 35, 130, 189, 89, 85, 57, 43, 168, 61, 96, 158, 116, 53, 9, 114, 119, 150, 157, 87, 22, 112, 63, 151, 139, 131, 95, 180, 152, 90, 142, 107, 58, 3, 169, 10, 118, 174, 92, 161, 134, 50, 190, 164], 'val_indices': [135, 40, 148, 49, 31, 191, 105, 123, 128, 45, 75, 94, 21, 73, 54, 117, 127, 136, 39, 83, 121, 12, 172, 126, 144, 51, 6, 132, 156, 129, 69, 25, 82, 66, 179, 147, 64, 76, 98], 'accuracy': 0.8974358974358975, 'kappa': 0.7952755905511811, 'auc': 0.9789473684210527}\n",
      "New Max Found!\n",
      "Running fold 1 with 153 training samples and 39 validation samples\n",
      "Fold 1: train indices: [113 162 181  56 147], val indices: [130 176  21 111  18]\n",
      "Training data shape: (153, 64, 320, 1), Validation data shape: (39, 64, 320, 1)\n",
      "Fold 1 training loss: 0.09760107100009918\n",
      "y_true (val): [1 1 0 1 0]\n",
      "y_pred: [1 0 0 0 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [113, 162, 181, 56, 147, 51, 17, 126, 44, 37, 77, 46, 91, 104, 102, 20, 158, 129, 70, 116, 184, 128, 95, 35, 120, 25, 121, 145, 81, 110, 6, 163, 93, 52, 59, 185, 114, 123, 107, 174, 73, 179, 109, 10, 167, 28, 92, 71, 39, 27, 33, 175, 122, 178, 170, 132, 34, 148, 48, 98, 30, 74, 164, 65, 133, 45, 5, 4, 12, 139, 166, 173, 151, 82, 62, 142, 124, 84, 119, 118, 115, 40, 106, 75, 101, 36, 66, 186, 8, 0, 1, 160, 141, 89, 156, 29, 97, 149, 15, 26, 41, 11, 152, 177, 103, 85, 64, 23, 171, 68, 108, 136, 58, 83, 24, 146, 60, 157, 140, 99, 168, 159, 72, 189, 125, 50, 190, 9, 144, 79, 134, 55, 53, 183, 96, 188, 63, 76, 100, 49, 14, 19, 135, 69, 153, 47, 42, 117, 180, 137, 31, 43, 3], 'val_indices': [130, 176, 21, 111, 18, 87, 112, 80, 172, 54, 150, 67, 155, 61, 16, 13, 182, 131, 165, 57, 127, 94, 105, 90, 191, 22, 86, 138, 187, 7, 2, 154, 169, 143, 78, 88, 161, 38, 32], 'accuracy': 0.717948717948718, 'kappa': 0.4347826086956521, 'auc': 0.8289473684210527}\n",
      "Running fold 2 with 153 training samples and 39 validation samples\n",
      "Fold 2: train indices: [190  72  89 149  79], val indices: [  3  15  12 106  22]\n",
      "Training data shape: (153, 64, 320, 1), Validation data shape: (39, 64, 320, 1)\n",
      "Fold 2 training loss: 0.04947523772716522\n",
      "y_true (val): [0 0 0 1 0]\n",
      "y_pred: [0 0 0 1 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [190, 72, 89, 149, 79, 4, 173, 36, 135, 185, 122, 1, 27, 51, 174, 133, 37, 139, 33, 155, 109, 76, 144, 161, 80, 105, 108, 73, 43, 179, 115, 184, 58, 116, 156, 19, 66, 55, 183, 17, 95, 25, 157, 9, 120, 88, 146, 151, 143, 31, 90, 181, 112, 142, 87, 91, 145, 169, 153, 134, 56, 96, 107, 35, 104, 162, 63, 32, 124, 49, 41, 137, 165, 82, 2, 102, 118, 129, 20, 172, 132, 85, 6, 42, 10, 103, 140, 44, 64, 170, 154, 99, 39, 53, 13, 117, 77, 8, 101, 159, 57, 114, 119, 30, 11, 62, 128, 48, 67, 187, 158, 75, 141, 23, 138, 130, 97, 24, 131, 83, 147, 168, 34, 178, 60, 98, 28, 46, 0, 123, 78, 54, 94, 186, 164, 110, 191, 166, 150, 21, 16, 71, 65, 113, 167, 81, 93, 38, 86, 84, 18, 7, 14], 'val_indices': [3, 15, 12, 106, 22, 45, 68, 189, 176, 26, 136, 29, 111, 92, 163, 171, 50, 175, 188, 125, 182, 70, 152, 69, 5, 160, 126, 61, 74, 177, 121, 52, 40, 47, 100, 148, 127, 180, 59], 'accuracy': 0.8205128205128205, 'kappa': 0.6393659180977542, 'auc': 0.918421052631579}\n",
      "Running fold 3 with 153 training samples and 39 validation samples\n",
      "Fold 3: train indices: [145  75 130 115  20], val indices: [120  97  28  35 107]\n",
      "Training data shape: (153, 64, 320, 1), Validation data shape: (39, 64, 320, 1)\n",
      "Fold 3 training loss: 0.13480854034423828\n",
      "y_true (val): [1 1 0 0 1]\n",
      "y_pred: [1 1 0 1 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [145, 75, 130, 115, 20, 50, 22, 4, 104, 137, 153, 1, 118, 119, 185, 164, 8, 0, 29, 177, 74, 176, 19, 87, 76, 129, 44, 165, 26, 89, 24, 16, 90, 48, 162, 136, 68, 57, 139, 126, 109, 105, 9, 82, 173, 88, 144, 174, 71, 181, 128, 168, 81, 37, 112, 61, 92, 122, 95, 63, 25, 10, 189, 123, 59, 53, 62, 34, 138, 131, 56, 55, 178, 65, 77, 39, 155, 166, 160, 110, 101, 116, 106, 175, 14, 47, 11, 33, 161, 121, 100, 72, 99, 158, 134, 159, 157, 41, 146, 140, 27, 111, 135, 54, 133, 85, 182, 154, 94, 171, 70, 184, 6, 152, 142, 125, 169, 79, 147, 52, 124, 113, 180, 42, 43, 12, 18, 58, 179, 69, 64, 66, 132, 149, 83, 93, 36, 167, 143, 80, 32, 84, 127, 96, 5, 7, 98, 2, 51, 21, 191, 156, 40], 'val_indices': [120, 97, 28, 35, 107, 23, 78, 183, 46, 67, 187, 114, 188, 117, 49, 3, 102, 15, 30, 170, 141, 13, 172, 60, 150, 38, 103, 31, 86, 186, 108, 73, 148, 163, 190, 45, 17, 91, 151], 'accuracy': 0.7692307692307693, 'kappa': 0.5363276089828268, 'auc': 0.9263157894736842}\n",
      "Running fold 4 with 153 training samples and 39 validation samples\n",
      "Fold 4: train indices: [ 18 171 160  85  15], val indices: [ 34  63 156 134  73]\n",
      "Training data shape: (153, 64, 320, 1), Validation data shape: (39, 64, 320, 1)\n",
      "Fold 4 training loss: 0.08303196728229523\n",
      "y_true (val): [0 0 1 1 0]\n",
      "y_pred: [1 0 1 1 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [18, 171, 160, 85, 15, 167, 8, 122, 112, 93, 88, 145, 173, 11, 100, 13, 185, 17, 123, 149, 62, 177, 25, 118, 51, 153, 99, 116, 190, 53, 89, 147, 187, 133, 32, 10, 111, 9, 119, 77, 52, 79, 74, 98, 64, 67, 126, 71, 24, 41, 81, 158, 163, 159, 110, 54, 140, 170, 14, 27, 132, 12, 28, 102, 146, 60, 16, 5, 68, 56, 175, 105, 38, 19, 161, 61, 87, 58, 176, 108, 59, 1, 130, 0, 50, 152, 107, 157, 92, 80, 23, 142, 139, 84, 109, 191, 101, 106, 138, 86, 45, 21, 165, 135, 44, 181, 69, 2, 78, 4, 155, 7, 83, 180, 31, 121, 42, 162, 46, 96, 182, 150, 104, 33, 172, 125, 90, 39, 120, 128, 36, 183, 91, 188, 3, 131, 94, 103, 30, 26, 137, 141, 166, 174, 75, 65, 72, 168, 127, 169, 55, 114, 97], 'val_indices': [34, 63, 156, 134, 73, 48, 35, 29, 95, 66, 113, 70, 20, 154, 148, 49, 129, 57, 151, 186, 117, 76, 82, 143, 164, 179, 124, 144, 136, 40, 22, 6, 189, 184, 37, 178, 115, 43, 47], 'accuracy': 0.7435897435897436, 'kappa': 0.4841269841269841, 'auc': 0.8815789473684211}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.79, 'mean_kappa': 0.578, 'mean_auc': 0.907, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [177, 163, 46, 143, 13, 11, 80, 65, 56, 14, 88, 113, 15, 4, 7, 79, 41, 67, 42, 154, 74, 18, 93, 159, 111, 138, 162, 184, 99, 170, 68, 133, 36, 178, 30, 0, 48, 72, 155, 175, 19, 47, 171, 181, 86, 24, 141, 55, 137, 109, 173, 23, 34, 145, 37, 183, 185, 166, 1, 103, 28, 146, 167, 153, 102, 77, 16, 100, 27, 29, 97, 52, 176, 59, 186, 124, 182, 140, 78, 120, 101, 125, 149, 17, 81, 91, 60, 84, 110, 115, 71, 8, 33, 160, 188, 62, 26, 106, 32, 5, 187, 20, 38, 44, 165, 122, 70, 2, 104, 108, 35, 130, 189, 89, 85, 57, 43, 168, 61, 96, 158, 116, 53, 9, 114, 119, 150, 157, 87, 22, 112, 63, 151, 139, 131, 95, 180, 152, 90, 142, 107, 58, 3, 169, 10, 118, 174, 92, 161, 134, 50, 190, 164], 'val_indices': [135, 40, 148, 49, 31, 191, 105, 123, 128, 45, 75, 94, 21, 73, 54, 117, 127, 136, 39, 83, 121, 12, 172, 126, 144, 51, 6, 132, 156, 129, 69, 25, 82, 66, 179, 147, 64, 76, 98], 'accuracy': 0.8974358974358975, 'kappa': 0.7952755905511811, 'auc': 0.9789473684210527}, {'fold_index': 1, 'train_indices': [113, 162, 181, 56, 147, 51, 17, 126, 44, 37, 77, 46, 91, 104, 102, 20, 158, 129, 70, 116, 184, 128, 95, 35, 120, 25, 121, 145, 81, 110, 6, 163, 93, 52, 59, 185, 114, 123, 107, 174, 73, 179, 109, 10, 167, 28, 92, 71, 39, 27, 33, 175, 122, 178, 170, 132, 34, 148, 48, 98, 30, 74, 164, 65, 133, 45, 5, 4, 12, 139, 166, 173, 151, 82, 62, 142, 124, 84, 119, 118, 115, 40, 106, 75, 101, 36, 66, 186, 8, 0, 1, 160, 141, 89, 156, 29, 97, 149, 15, 26, 41, 11, 152, 177, 103, 85, 64, 23, 171, 68, 108, 136, 58, 83, 24, 146, 60, 157, 140, 99, 168, 159, 72, 189, 125, 50, 190, 9, 144, 79, 134, 55, 53, 183, 96, 188, 63, 76, 100, 49, 14, 19, 135, 69, 153, 47, 42, 117, 180, 137, 31, 43, 3], 'val_indices': [130, 176, 21, 111, 18, 87, 112, 80, 172, 54, 150, 67, 155, 61, 16, 13, 182, 131, 165, 57, 127, 94, 105, 90, 191, 22, 86, 138, 187, 7, 2, 154, 169, 143, 78, 88, 161, 38, 32], 'accuracy': 0.717948717948718, 'kappa': 0.4347826086956521, 'auc': 0.8289473684210527}, {'fold_index': 2, 'train_indices': [190, 72, 89, 149, 79, 4, 173, 36, 135, 185, 122, 1, 27, 51, 174, 133, 37, 139, 33, 155, 109, 76, 144, 161, 80, 105, 108, 73, 43, 179, 115, 184, 58, 116, 156, 19, 66, 55, 183, 17, 95, 25, 157, 9, 120, 88, 146, 151, 143, 31, 90, 181, 112, 142, 87, 91, 145, 169, 153, 134, 56, 96, 107, 35, 104, 162, 63, 32, 124, 49, 41, 137, 165, 82, 2, 102, 118, 129, 20, 172, 132, 85, 6, 42, 10, 103, 140, 44, 64, 170, 154, 99, 39, 53, 13, 117, 77, 8, 101, 159, 57, 114, 119, 30, 11, 62, 128, 48, 67, 187, 158, 75, 141, 23, 138, 130, 97, 24, 131, 83, 147, 168, 34, 178, 60, 98, 28, 46, 0, 123, 78, 54, 94, 186, 164, 110, 191, 166, 150, 21, 16, 71, 65, 113, 167, 81, 93, 38, 86, 84, 18, 7, 14], 'val_indices': [3, 15, 12, 106, 22, 45, 68, 189, 176, 26, 136, 29, 111, 92, 163, 171, 50, 175, 188, 125, 182, 70, 152, 69, 5, 160, 126, 61, 74, 177, 121, 52, 40, 47, 100, 148, 127, 180, 59], 'accuracy': 0.8205128205128205, 'kappa': 0.6393659180977542, 'auc': 0.918421052631579}, {'fold_index': 3, 'train_indices': [145, 75, 130, 115, 20, 50, 22, 4, 104, 137, 153, 1, 118, 119, 185, 164, 8, 0, 29, 177, 74, 176, 19, 87, 76, 129, 44, 165, 26, 89, 24, 16, 90, 48, 162, 136, 68, 57, 139, 126, 109, 105, 9, 82, 173, 88, 144, 174, 71, 181, 128, 168, 81, 37, 112, 61, 92, 122, 95, 63, 25, 10, 189, 123, 59, 53, 62, 34, 138, 131, 56, 55, 178, 65, 77, 39, 155, 166, 160, 110, 101, 116, 106, 175, 14, 47, 11, 33, 161, 121, 100, 72, 99, 158, 134, 159, 157, 41, 146, 140, 27, 111, 135, 54, 133, 85, 182, 154, 94, 171, 70, 184, 6, 152, 142, 125, 169, 79, 147, 52, 124, 113, 180, 42, 43, 12, 18, 58, 179, 69, 64, 66, 132, 149, 83, 93, 36, 167, 143, 80, 32, 84, 127, 96, 5, 7, 98, 2, 51, 21, 191, 156, 40], 'val_indices': [120, 97, 28, 35, 107, 23, 78, 183, 46, 67, 187, 114, 188, 117, 49, 3, 102, 15, 30, 170, 141, 13, 172, 60, 150, 38, 103, 31, 86, 186, 108, 73, 148, 163, 190, 45, 17, 91, 151], 'accuracy': 0.7692307692307693, 'kappa': 0.5363276089828268, 'auc': 0.9263157894736842}, {'fold_index': 4, 'train_indices': [18, 171, 160, 85, 15, 167, 8, 122, 112, 93, 88, 145, 173, 11, 100, 13, 185, 17, 123, 149, 62, 177, 25, 118, 51, 153, 99, 116, 190, 53, 89, 147, 187, 133, 32, 10, 111, 9, 119, 77, 52, 79, 74, 98, 64, 67, 126, 71, 24, 41, 81, 158, 163, 159, 110, 54, 140, 170, 14, 27, 132, 12, 28, 102, 146, 60, 16, 5, 68, 56, 175, 105, 38, 19, 161, 61, 87, 58, 176, 108, 59, 1, 130, 0, 50, 152, 107, 157, 92, 80, 23, 142, 139, 84, 109, 191, 101, 106, 138, 86, 45, 21, 165, 135, 44, 181, 69, 2, 78, 4, 155, 7, 83, 180, 31, 121, 42, 162, 46, 96, 182, 150, 104, 33, 172, 125, 90, 39, 120, 128, 36, 183, 91, 188, 3, 131, 94, 103, 30, 26, 137, 141, 166, 174, 75, 65, 72, 168, 127, 169, 55, 114, 97], 'val_indices': [34, 63, 156, 134, 73, 48, 35, 29, 95, 66, 113, 70, 20, 154, 148, 49, 129, 57, 151, 186, 117, 76, 82, 143, 164, 179, 124, 144, 136, 40, 22, 6, 189, 184, 37, 178, 115, 43, 47], 'accuracy': 0.7435897435897436, 'kappa': 0.4841269841269841, 'auc': 0.8815789473684211}], 'std_acc': 0.064, 'std_kappa': 0.128, 'std_auc': 0.05}\n",
      "sbj =  10\n",
      "Total trials loaded: 200\n",
      "Shape of X: (200, 64, 3584), Shape of y: (200,)\n",
      "Resampling from 512 to 128.0 Hz.\n",
      "X_train shape: (200, 64, 320, 1), y_train shape: (200,)\n",
      "Running fold 0 with 160 training samples and 40 validation samples\n",
      "Fold 0: train indices: [  4 142 183  71  50], val indices: [ 25 107  31 188  83]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 0 training loss: 0.08960026502609253\n",
      "y_true (val): [0 1 0 1 0]\n",
      "y_pred: [0 1 0 1 1]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [4, 142, 183, 71, 50, 179, 125, 131, 117, 60, 82, 55, 89, 21, 157, 47, 5, 42, 11, 19, 23, 172, 148, 99, 140, 34, 146, 115, 48, 147, 93, 2, 182, 138, 43, 57, 158, 187, 128, 18, 160, 33, 97, 14, 44, 177, 196, 61, 56, 174, 46, 67, 8, 101, 7, 41, 129, 184, 198, 98, 190, 74, 169, 24, 159, 173, 15, 70, 163, 58, 186, 72, 27, 87, 81, 26, 122, 96, 120, 65, 119, 102, 123, 167, 94, 130, 135, 77, 192, 175, 20, 37, 16, 0, 180, 144, 52, 145, 106, 139, 63, 9, 36, 153, 126, 17, 59, 29, 164, 30, 85, 156, 53, 79, 38, 118, 124, 193, 171, 35, 13, 151, 110, 95, 149, 136, 165, 168, 109, 88, 84, 92, 3, 121, 114, 143, 1, 10, 195, 28, 197, 103, 137, 152, 113, 112, 32, 189, 62, 199, 78, 68, 176, 161, 22, 155, 108, 80, 181, 166], 'val_indices': [25, 107, 31, 188, 83, 86, 111, 75, 191, 170, 76, 12, 100, 154, 73, 6, 66, 54, 104, 162, 91, 51, 132, 39, 105, 40, 134, 141, 45, 116, 185, 178, 127, 150, 194, 69, 133, 90, 64, 49], 'accuracy': 0.825, 'kappa': 0.65, 'auc': 0.905}\n",
      "New Max Found!\n",
      "Running fold 1 with 160 training samples and 40 validation samples\n",
      "Fold 1: train indices: [162  56 128 110  84], val indices: [175 156   7 191  76]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 1 training loss: 0.04606496915221214\n",
      "y_true (val): [1 1 0 1 0]\n",
      "y_pred: [1 1 0 1 0]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [162, 56, 128, 110, 84, 70, 139, 147, 115, 155, 50, 165, 142, 109, 159, 194, 60, 15, 140, 195, 55, 86, 87, 130, 38, 79, 177, 92, 145, 47, 39, 135, 94, 197, 164, 104, 108, 88, 14, 21, 154, 17, 49, 11, 187, 114, 181, 158, 19, 77, 185, 123, 34, 25, 4, 12, 65, 30, 40, 129, 81, 189, 102, 141, 170, 68, 24, 71, 132, 107, 36, 27, 96, 66, 138, 63, 193, 113, 124, 99, 10, 150, 103, 5, 143, 146, 153, 122, 148, 9, 183, 105, 53, 166, 75, 52, 169, 43, 188, 59, 35, 186, 199, 93, 106, 3, 184, 33, 125, 74, 37, 1, 48, 180, 126, 121, 72, 62, 0, 173, 83, 119, 152, 23, 95, 73, 179, 44, 58, 120, 127, 157, 20, 163, 69, 190, 26, 112, 6, 134, 29, 64, 192, 172, 174, 28, 45, 168, 8, 46, 31, 116, 85, 131, 51, 32, 176, 198, 151, 42], 'val_indices': [175, 156, 7, 191, 76, 117, 54, 16, 2, 80, 41, 118, 78, 90, 100, 160, 149, 161, 171, 18, 82, 182, 101, 61, 91, 167, 144, 133, 196, 67, 22, 57, 137, 136, 98, 111, 89, 13, 178, 97], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.9199999999999999}\n",
      "New Max Found!\n",
      "Running fold 2 with 160 training samples and 40 validation samples\n",
      "Fold 2: train indices: [  3 109 165  70  15], val indices: [ 58 152 153  54 171]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 2 training loss: 0.05569954961538315\n",
      "y_true (val): [0 1 1 0 1]\n",
      "y_pred: [0 1 1 0 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [3, 109, 165, 70, 15, 172, 19, 5, 38, 146, 77, 11, 147, 198, 92, 18, 174, 2, 176, 168, 118, 199, 63, 100, 158, 17, 134, 86, 105, 24, 34, 175, 61, 166, 125, 97, 39, 108, 78, 79, 80, 31, 46, 180, 60, 113, 127, 87, 186, 144, 124, 67, 13, 136, 74, 65, 115, 167, 123, 72, 191, 182, 82, 23, 110, 40, 119, 183, 148, 128, 143, 85, 142, 107, 189, 30, 130, 145, 103, 96, 164, 151, 98, 64, 101, 43, 81, 49, 75, 69, 89, 106, 66, 162, 154, 161, 122, 188, 121, 10, 20, 91, 52, 111, 137, 57, 93, 178, 102, 138, 55, 47, 133, 42, 12, 196, 99, 177, 44, 169, 37, 193, 157, 1, 190, 0, 26, 141, 155, 173, 28, 27, 16, 32, 7, 195, 131, 197, 14, 156, 185, 36, 95, 71, 51, 160, 194, 117, 56, 68, 126, 41, 59, 135, 129, 4, 53, 90, 94, 179], 'val_indices': [58, 152, 153, 54, 171, 88, 170, 45, 21, 84, 181, 73, 150, 22, 29, 184, 25, 120, 159, 114, 116, 187, 6, 149, 83, 33, 50, 139, 104, 9, 48, 132, 112, 35, 76, 163, 8, 140, 192, 62], 'accuracy': 0.75, 'kappa': 0.5, 'auc': 0.8975}\n",
      "Running fold 3 with 160 training samples and 40 validation samples\n",
      "Fold 3: train indices: [66 43 45 22 69], val indices: [ 20  14 169 144 196]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 3 training loss: 0.06841930001974106\n",
      "y_true (val): [0 0 1 1 1]\n",
      "y_pred: [0 0 1 1 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [66, 43, 45, 22, 69, 48, 44, 60, 123, 74, 179, 25, 150, 171, 132, 28, 165, 96, 73, 113, 127, 72, 135, 52, 38, 23, 122, 100, 177, 92, 137, 148, 12, 8, 91, 159, 172, 125, 187, 32, 29, 173, 40, 108, 4, 151, 37, 186, 34, 21, 1, 33, 190, 176, 35, 146, 143, 68, 160, 136, 107, 103, 53, 49, 141, 131, 15, 50, 54, 199, 126, 154, 7, 193, 0, 89, 55, 56, 10, 98, 134, 106, 161, 168, 138, 112, 63, 88, 83, 174, 121, 81, 65, 61, 109, 78, 26, 47, 104, 9, 153, 180, 31, 94, 71, 77, 18, 195, 167, 75, 164, 162, 86, 85, 157, 119, 3, 84, 149, 142, 82, 95, 175, 191, 139, 133, 117, 24, 76, 41, 62, 198, 6, 111, 183, 110, 30, 11, 99, 178, 93, 87, 13, 166, 189, 170, 185, 118, 130, 197, 120, 128, 158, 140, 16, 59, 145, 101, 17, 181], 'val_indices': [20, 14, 169, 144, 196, 105, 67, 182, 36, 39, 97, 57, 64, 58, 79, 90, 188, 194, 155, 129, 102, 192, 27, 5, 124, 116, 80, 184, 152, 163, 46, 156, 114, 147, 115, 70, 19, 2, 51, 42], 'accuracy': 0.775, 'kappa': 0.55, 'auc': 0.87}\n",
      "Running fold 4 with 160 training samples and 40 validation samples\n",
      "Fold 4: train indices: [ 52   4 194  64  46], val indices: [123  35  89 183   0]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 4 training loss: 0.12369497120380402\n",
      "y_true (val): [1 0 0 1 0]\n",
      "y_pred: [0 0 0 1 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [52, 4, 194, 64, 46, 59, 38, 21, 193, 157, 28, 57, 17, 154, 184, 97, 139, 125, 102, 182, 30, 143, 180, 50, 126, 13, 161, 100, 15, 135, 45, 74, 153, 51, 115, 189, 181, 187, 37, 133, 118, 168, 16, 136, 66, 73, 19, 174, 22, 24, 71, 192, 63, 144, 122, 72, 54, 175, 147, 155, 85, 107, 149, 103, 69, 31, 27, 145, 7, 84, 77, 191, 88, 79, 114, 49, 90, 124, 5, 111, 36, 172, 131, 61, 32, 185, 173, 2, 166, 39, 148, 110, 34, 199, 65, 186, 23, 91, 159, 170, 93, 119, 195, 116, 129, 76, 53, 158, 101, 130, 178, 156, 6, 94, 138, 167, 96, 68, 132, 165, 92, 140, 12, 137, 44, 188, 160, 83, 47, 60, 98, 81, 105, 78, 58, 11, 25, 26, 82, 141, 171, 196, 62, 48, 1, 177, 70, 121, 8, 163, 109, 95, 104, 43, 117, 150, 14, 197, 127, 33], 'val_indices': [123, 35, 89, 183, 0, 80, 75, 134, 10, 87, 120, 40, 151, 67, 86, 99, 152, 42, 20, 176, 162, 169, 41, 190, 56, 9, 142, 146, 112, 108, 3, 128, 198, 106, 55, 29, 18, 164, 113, 179], 'accuracy': 0.75, 'kappa': 0.5, 'auc': 0.8999999999999999}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.8, 'mean_kappa': 0.6, 'mean_auc': 0.898, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [4, 142, 183, 71, 50, 179, 125, 131, 117, 60, 82, 55, 89, 21, 157, 47, 5, 42, 11, 19, 23, 172, 148, 99, 140, 34, 146, 115, 48, 147, 93, 2, 182, 138, 43, 57, 158, 187, 128, 18, 160, 33, 97, 14, 44, 177, 196, 61, 56, 174, 46, 67, 8, 101, 7, 41, 129, 184, 198, 98, 190, 74, 169, 24, 159, 173, 15, 70, 163, 58, 186, 72, 27, 87, 81, 26, 122, 96, 120, 65, 119, 102, 123, 167, 94, 130, 135, 77, 192, 175, 20, 37, 16, 0, 180, 144, 52, 145, 106, 139, 63, 9, 36, 153, 126, 17, 59, 29, 164, 30, 85, 156, 53, 79, 38, 118, 124, 193, 171, 35, 13, 151, 110, 95, 149, 136, 165, 168, 109, 88, 84, 92, 3, 121, 114, 143, 1, 10, 195, 28, 197, 103, 137, 152, 113, 112, 32, 189, 62, 199, 78, 68, 176, 161, 22, 155, 108, 80, 181, 166], 'val_indices': [25, 107, 31, 188, 83, 86, 111, 75, 191, 170, 76, 12, 100, 154, 73, 6, 66, 54, 104, 162, 91, 51, 132, 39, 105, 40, 134, 141, 45, 116, 185, 178, 127, 150, 194, 69, 133, 90, 64, 49], 'accuracy': 0.825, 'kappa': 0.65, 'auc': 0.905}, {'fold_index': 1, 'train_indices': [162, 56, 128, 110, 84, 70, 139, 147, 115, 155, 50, 165, 142, 109, 159, 194, 60, 15, 140, 195, 55, 86, 87, 130, 38, 79, 177, 92, 145, 47, 39, 135, 94, 197, 164, 104, 108, 88, 14, 21, 154, 17, 49, 11, 187, 114, 181, 158, 19, 77, 185, 123, 34, 25, 4, 12, 65, 30, 40, 129, 81, 189, 102, 141, 170, 68, 24, 71, 132, 107, 36, 27, 96, 66, 138, 63, 193, 113, 124, 99, 10, 150, 103, 5, 143, 146, 153, 122, 148, 9, 183, 105, 53, 166, 75, 52, 169, 43, 188, 59, 35, 186, 199, 93, 106, 3, 184, 33, 125, 74, 37, 1, 48, 180, 126, 121, 72, 62, 0, 173, 83, 119, 152, 23, 95, 73, 179, 44, 58, 120, 127, 157, 20, 163, 69, 190, 26, 112, 6, 134, 29, 64, 192, 172, 174, 28, 45, 168, 8, 46, 31, 116, 85, 131, 51, 32, 176, 198, 151, 42], 'val_indices': [175, 156, 7, 191, 76, 117, 54, 16, 2, 80, 41, 118, 78, 90, 100, 160, 149, 161, 171, 18, 82, 182, 101, 61, 91, 167, 144, 133, 196, 67, 22, 57, 137, 136, 98, 111, 89, 13, 178, 97], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.9199999999999999}, {'fold_index': 2, 'train_indices': [3, 109, 165, 70, 15, 172, 19, 5, 38, 146, 77, 11, 147, 198, 92, 18, 174, 2, 176, 168, 118, 199, 63, 100, 158, 17, 134, 86, 105, 24, 34, 175, 61, 166, 125, 97, 39, 108, 78, 79, 80, 31, 46, 180, 60, 113, 127, 87, 186, 144, 124, 67, 13, 136, 74, 65, 115, 167, 123, 72, 191, 182, 82, 23, 110, 40, 119, 183, 148, 128, 143, 85, 142, 107, 189, 30, 130, 145, 103, 96, 164, 151, 98, 64, 101, 43, 81, 49, 75, 69, 89, 106, 66, 162, 154, 161, 122, 188, 121, 10, 20, 91, 52, 111, 137, 57, 93, 178, 102, 138, 55, 47, 133, 42, 12, 196, 99, 177, 44, 169, 37, 193, 157, 1, 190, 0, 26, 141, 155, 173, 28, 27, 16, 32, 7, 195, 131, 197, 14, 156, 185, 36, 95, 71, 51, 160, 194, 117, 56, 68, 126, 41, 59, 135, 129, 4, 53, 90, 94, 179], 'val_indices': [58, 152, 153, 54, 171, 88, 170, 45, 21, 84, 181, 73, 150, 22, 29, 184, 25, 120, 159, 114, 116, 187, 6, 149, 83, 33, 50, 139, 104, 9, 48, 132, 112, 35, 76, 163, 8, 140, 192, 62], 'accuracy': 0.75, 'kappa': 0.5, 'auc': 0.8975}, {'fold_index': 3, 'train_indices': [66, 43, 45, 22, 69, 48, 44, 60, 123, 74, 179, 25, 150, 171, 132, 28, 165, 96, 73, 113, 127, 72, 135, 52, 38, 23, 122, 100, 177, 92, 137, 148, 12, 8, 91, 159, 172, 125, 187, 32, 29, 173, 40, 108, 4, 151, 37, 186, 34, 21, 1, 33, 190, 176, 35, 146, 143, 68, 160, 136, 107, 103, 53, 49, 141, 131, 15, 50, 54, 199, 126, 154, 7, 193, 0, 89, 55, 56, 10, 98, 134, 106, 161, 168, 138, 112, 63, 88, 83, 174, 121, 81, 65, 61, 109, 78, 26, 47, 104, 9, 153, 180, 31, 94, 71, 77, 18, 195, 167, 75, 164, 162, 86, 85, 157, 119, 3, 84, 149, 142, 82, 95, 175, 191, 139, 133, 117, 24, 76, 41, 62, 198, 6, 111, 183, 110, 30, 11, 99, 178, 93, 87, 13, 166, 189, 170, 185, 118, 130, 197, 120, 128, 158, 140, 16, 59, 145, 101, 17, 181], 'val_indices': [20, 14, 169, 144, 196, 105, 67, 182, 36, 39, 97, 57, 64, 58, 79, 90, 188, 194, 155, 129, 102, 192, 27, 5, 124, 116, 80, 184, 152, 163, 46, 156, 114, 147, 115, 70, 19, 2, 51, 42], 'accuracy': 0.775, 'kappa': 0.55, 'auc': 0.87}, {'fold_index': 4, 'train_indices': [52, 4, 194, 64, 46, 59, 38, 21, 193, 157, 28, 57, 17, 154, 184, 97, 139, 125, 102, 182, 30, 143, 180, 50, 126, 13, 161, 100, 15, 135, 45, 74, 153, 51, 115, 189, 181, 187, 37, 133, 118, 168, 16, 136, 66, 73, 19, 174, 22, 24, 71, 192, 63, 144, 122, 72, 54, 175, 147, 155, 85, 107, 149, 103, 69, 31, 27, 145, 7, 84, 77, 191, 88, 79, 114, 49, 90, 124, 5, 111, 36, 172, 131, 61, 32, 185, 173, 2, 166, 39, 148, 110, 34, 199, 65, 186, 23, 91, 159, 170, 93, 119, 195, 116, 129, 76, 53, 158, 101, 130, 178, 156, 6, 94, 138, 167, 96, 68, 132, 165, 92, 140, 12, 137, 44, 188, 160, 83, 47, 60, 98, 81, 105, 78, 58, 11, 25, 26, 82, 141, 171, 196, 62, 48, 1, 177, 70, 121, 8, 163, 109, 95, 104, 43, 117, 150, 14, 197, 127, 33], 'val_indices': [123, 35, 89, 183, 0, 80, 75, 134, 10, 87, 120, 40, 151, 67, 86, 99, 152, 42, 20, 176, 162, 169, 41, 190, 56, 9, 142, 146, 112, 108, 3, 128, 198, 106, 55, 29, 18, 164, 113, 179], 'accuracy': 0.75, 'kappa': 0.5, 'auc': 0.8999999999999999}], 'std_acc': 0.057, 'std_kappa': 0.114, 'std_auc': 0.016}\n",
      "sbj =  46\n",
      "Total trials loaded: 239\n",
      "Shape of X: (239, 64, 3584), Shape of y: (239,)\n",
      "Resampling from 512 to 128.0 Hz.\n",
      "X_train shape: (239, 64, 320, 1), y_train shape: (239,)\n",
      "Running fold 0 with 191 training samples and 48 validation samples\n",
      "Fold 0: train indices: [ 62 220   0 186 205], val indices: [119  76 189 223  85]\n",
      "Training data shape: (191, 64, 320, 1), Validation data shape: (48, 64, 320, 1)\n",
      "Fold 0 training loss: 0.06955486536026001\n",
      "y_true (val): [1 0 1 1 0]\n",
      "y_pred: [0 0 1 1 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [62, 220, 0, 186, 205, 44, 61, 21, 20, 115, 160, 234, 197, 106, 158, 212, 70, 59, 5, 146, 36, 50, 34, 201, 152, 144, 14, 22, 159, 78, 214, 192, 2, 190, 32, 166, 9, 52, 210, 131, 129, 155, 53, 206, 30, 80, 77, 149, 125, 147, 203, 118, 35, 235, 24, 13, 79, 196, 92, 27, 95, 33, 237, 148, 57, 93, 232, 60, 188, 238, 218, 132, 215, 207, 29, 101, 87, 19, 178, 16, 28, 198, 185, 23, 133, 171, 98, 86, 120, 11, 233, 1, 26, 37, 103, 72, 174, 17, 164, 74, 213, 163, 43, 209, 202, 110, 140, 195, 194, 184, 139, 42, 168, 63, 82, 193, 58, 99, 67, 68, 154, 48, 156, 4, 165, 138, 217, 173, 107, 105, 204, 122, 100, 108, 96, 130, 97, 182, 71, 224, 136, 179, 116, 94, 208, 84, 113, 142, 55, 236, 3, 216, 15, 177, 38, 145, 200, 127, 137, 228, 187, 157, 56, 211, 88, 18, 219, 47, 229, 8, 111, 226, 176, 114, 7, 41, 46, 222, 112, 170, 143, 81, 89, 199, 169, 10, 227, 191, 183, 65, 172], 'val_indices': [119, 76, 189, 223, 85, 117, 31, 231, 102, 123, 153, 135, 167, 225, 75, 49, 45, 69, 181, 73, 124, 83, 51, 121, 6, 91, 175, 104, 230, 66, 12, 128, 40, 162, 90, 134, 151, 54, 25, 221, 109, 180, 141, 39, 161, 126, 64, 150], 'accuracy': 0.8333333333333334, 'kappa': 0.6666666666666667, 'auc': 0.9027777777777778}\n",
      "New Max Found!\n",
      "Running fold 1 with 191 training samples and 48 validation samples\n",
      "Fold 1: train indices: [194  31  72 117 177], val indices: [166   1  35  99 208]\n",
      "Training data shape: (191, 64, 320, 1), Validation data shape: (48, 64, 320, 1)\n",
      "Fold 1 training loss: 0.10329318791627884\n",
      "y_true (val): [1 0 0 0 1]\n",
      "y_pred: [0 0 0 0 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [194, 31, 72, 117, 177, 152, 176, 179, 116, 39, 157, 98, 73, 58, 107, 193, 162, 210, 94, 173, 68, 223, 186, 22, 138, 145, 63, 88, 213, 215, 217, 161, 109, 2, 158, 76, 160, 230, 141, 236, 5, 37, 97, 237, 195, 23, 43, 142, 119, 67, 115, 124, 105, 219, 169, 188, 175, 12, 111, 112, 174, 135, 212, 16, 184, 235, 180, 14, 120, 122, 25, 226, 8, 218, 57, 87, 46, 59, 96, 66, 216, 181, 203, 65, 47, 17, 202, 80, 234, 7, 95, 229, 91, 38, 32, 133, 209, 82, 134, 79, 221, 30, 70, 231, 62, 75, 19, 93, 40, 74, 147, 205, 220, 207, 199, 165, 225, 127, 4, 136, 21, 149, 103, 150, 69, 49, 182, 204, 129, 131, 146, 89, 153, 36, 90, 196, 29, 3, 214, 26, 110, 20, 198, 0, 52, 101, 64, 197, 190, 143, 45, 83, 222, 144, 27, 55, 81, 54, 238, 123, 140, 10, 187, 118, 159, 232, 6, 148, 114, 137, 189, 60, 164, 13, 28, 163, 130, 192, 78, 121, 125, 50, 34, 92, 128, 113, 201, 85, 42, 18, 178], 'val_indices': [166, 1, 35, 99, 208, 183, 206, 154, 155, 167, 185, 200, 48, 151, 84, 44, 77, 71, 11, 227, 86, 33, 104, 24, 53, 9, 61, 228, 15, 139, 172, 156, 211, 224, 171, 108, 102, 132, 51, 56, 191, 233, 170, 106, 100, 168, 41, 126], 'accuracy': 0.7916666666666666, 'kappa': 0.5833333333333333, 'auc': 0.8784722222222222}\n",
      "Running fold 2 with 191 training samples and 48 validation samples\n",
      "Fold 2: train indices: [108 191 184   3 190], val indices: [152  43 159 133  37]\n",
      "Training data shape: (191, 64, 320, 1), Validation data shape: (48, 64, 320, 1)\n",
      "Fold 2 training loss: 0.04096398875117302\n",
      "y_true (val): [1 0 1 1 0]\n",
      "y_pred: [1 0 1 1 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [108, 191, 184, 3, 190, 90, 5, 165, 25, 172, 35, 136, 81, 178, 33, 110, 29, 114, 69, 223, 13, 229, 109, 91, 97, 205, 141, 128, 237, 93, 231, 104, 83, 148, 201, 228, 214, 212, 181, 236, 84, 119, 151, 23, 118, 179, 78, 11, 166, 10, 57, 66, 125, 162, 71, 19, 197, 221, 44, 80, 210, 16, 220, 209, 139, 222, 213, 186, 234, 59, 12, 74, 40, 24, 206, 26, 79, 20, 76, 101, 153, 51, 161, 0, 218, 45, 63, 146, 42, 126, 100, 149, 144, 70, 123, 130, 175, 169, 137, 18, 177, 156, 217, 142, 188, 199, 41, 53, 102, 160, 9, 31, 196, 187, 115, 85, 2, 232, 132, 143, 27, 95, 56, 15, 155, 117, 49, 127, 92, 208, 215, 168, 47, 203, 227, 60, 122, 164, 50, 226, 75, 180, 195, 103, 182, 116, 167, 55, 72, 171, 46, 211, 189, 140, 135, 87, 120, 28, 163, 68, 235, 185, 48, 105, 4, 204, 7, 170, 62, 64, 8, 202, 111, 216, 154, 107, 77, 194, 145, 99, 89, 32, 207, 198, 22, 98, 96, 174, 39, 61, 121], 'val_indices': [152, 43, 159, 133, 37, 52, 21, 6, 134, 30, 65, 157, 94, 106, 233, 129, 147, 131, 1, 34, 17, 173, 230, 38, 193, 183, 224, 200, 238, 192, 176, 138, 219, 54, 88, 86, 225, 150, 113, 14, 82, 124, 73, 112, 158, 67, 58, 36], 'accuracy': 0.8958333333333334, 'kappa': 0.7916666666666666, 'auc': 0.921875}\n",
      "New Max Found!\n",
      "Running fold 3 with 191 training samples and 48 validation samples\n",
      "Fold 3: train indices: [164 165 195 125 229], val indices: [174 114 236  59 215]\n",
      "Training data shape: (191, 64, 320, 1), Validation data shape: (48, 64, 320, 1)\n",
      "Fold 3 training loss: 0.11469389498233795\n",
      "y_true (val): [1 0 1 0 1]\n",
      "y_pred: [1 0 1 0 0]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [164, 165, 195, 125, 229, 81, 202, 106, 196, 221, 64, 10, 66, 151, 141, 29, 209, 78, 52, 63, 28, 183, 210, 23, 214, 157, 219, 199, 208, 12, 4, 230, 21, 102, 95, 55, 97, 216, 3, 98, 19, 83, 53, 122, 116, 84, 144, 193, 188, 2, 58, 205, 129, 94, 120, 51, 223, 42, 211, 225, 145, 124, 107, 117, 43, 200, 35, 155, 135, 192, 27, 87, 217, 161, 194, 62, 140, 220, 181, 47, 190, 88, 163, 69, 169, 26, 80, 232, 71, 175, 15, 191, 16, 0, 17, 235, 197, 73, 176, 32, 201, 41, 25, 13, 206, 60, 218, 92, 11, 222, 46, 77, 121, 110, 93, 123, 44, 142, 237, 128, 150, 167, 203, 70, 189, 118, 132, 113, 56, 143, 111, 45, 119, 30, 126, 185, 105, 39, 9, 5, 24, 204, 138, 74, 108, 170, 162, 187, 72, 127, 22, 130, 228, 20, 65, 148, 8, 99, 177, 207, 96, 149, 100, 172, 90, 233, 57, 152, 159, 137, 7, 61, 134, 213, 103, 198, 160, 38, 173, 136, 91, 40, 54, 6, 37, 131, 31, 227, 184, 178, 36], 'val_indices': [174, 114, 236, 59, 215, 224, 75, 171, 82, 79, 76, 109, 18, 133, 14, 146, 231, 68, 168, 186, 48, 238, 234, 49, 147, 166, 104, 85, 179, 226, 33, 153, 112, 182, 67, 154, 158, 50, 212, 86, 139, 101, 89, 115, 156, 180, 34, 1], 'accuracy': 0.8541666666666666, 'kappa': 0.7083333333333333, 'auc': 0.9166666666666666}\n",
      "Running fold 4 with 191 training samples and 48 validation samples\n",
      "Fold 4: train indices: [193 150 196  99 164], val indices: [143  66  63  73 205]\n",
      "Training data shape: (191, 64, 320, 1), Validation data shape: (48, 64, 320, 1)\n",
      "Fold 4 training loss: 0.11692555248737335\n",
      "y_true (val): [1 0 0 0 1]\n",
      "y_pred: [1 0 0 1 1]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [193, 150, 196, 99, 164, 32, 105, 65, 231, 87, 27, 56, 96, 139, 80, 51, 140, 57, 218, 22, 59, 6, 18, 114, 7, 145, 50, 85, 25, 125, 112, 55, 216, 45, 91, 26, 30, 161, 98, 153, 70, 198, 47, 199, 154, 168, 92, 68, 203, 233, 77, 78, 33, 130, 159, 16, 43, 197, 234, 71, 214, 10, 221, 165, 106, 184, 171, 44, 238, 54, 123, 237, 24, 42, 102, 88, 31, 176, 104, 136, 211, 20, 135, 72, 115, 1, 38, 117, 230, 0, 108, 119, 82, 235, 37, 170, 110, 121, 13, 132, 156, 155, 226, 204, 35, 79, 147, 116, 81, 148, 89, 94, 137, 133, 188, 75, 225, 11, 228, 129, 60, 220, 162, 192, 29, 95, 15, 14, 186, 19, 3, 17, 182, 49, 109, 76, 177, 223, 207, 173, 134, 232, 122, 149, 90, 138, 39, 152, 118, 229, 97, 141, 181, 236, 187, 201, 100, 190, 83, 195, 179, 107, 227, 146, 120, 53, 124, 86, 202, 69, 9, 178, 126, 175, 64, 166, 167, 163, 103, 127, 209, 144, 157, 183, 41, 219, 28, 34, 200, 158, 61], 'val_indices': [143, 66, 63, 73, 205, 74, 191, 2, 212, 128, 131, 151, 84, 93, 172, 194, 101, 4, 213, 5, 222, 217, 210, 36, 21, 169, 23, 113, 111, 67, 174, 40, 189, 206, 180, 8, 12, 62, 160, 142, 48, 46, 185, 224, 208, 215, 58, 52], 'accuracy': 0.6875, 'kappa': 0.375, 'auc': 0.8298611111111112}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.812, 'mean_kappa': 0.625, 'mean_auc': 0.89, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [62, 220, 0, 186, 205, 44, 61, 21, 20, 115, 160, 234, 197, 106, 158, 212, 70, 59, 5, 146, 36, 50, 34, 201, 152, 144, 14, 22, 159, 78, 214, 192, 2, 190, 32, 166, 9, 52, 210, 131, 129, 155, 53, 206, 30, 80, 77, 149, 125, 147, 203, 118, 35, 235, 24, 13, 79, 196, 92, 27, 95, 33, 237, 148, 57, 93, 232, 60, 188, 238, 218, 132, 215, 207, 29, 101, 87, 19, 178, 16, 28, 198, 185, 23, 133, 171, 98, 86, 120, 11, 233, 1, 26, 37, 103, 72, 174, 17, 164, 74, 213, 163, 43, 209, 202, 110, 140, 195, 194, 184, 139, 42, 168, 63, 82, 193, 58, 99, 67, 68, 154, 48, 156, 4, 165, 138, 217, 173, 107, 105, 204, 122, 100, 108, 96, 130, 97, 182, 71, 224, 136, 179, 116, 94, 208, 84, 113, 142, 55, 236, 3, 216, 15, 177, 38, 145, 200, 127, 137, 228, 187, 157, 56, 211, 88, 18, 219, 47, 229, 8, 111, 226, 176, 114, 7, 41, 46, 222, 112, 170, 143, 81, 89, 199, 169, 10, 227, 191, 183, 65, 172], 'val_indices': [119, 76, 189, 223, 85, 117, 31, 231, 102, 123, 153, 135, 167, 225, 75, 49, 45, 69, 181, 73, 124, 83, 51, 121, 6, 91, 175, 104, 230, 66, 12, 128, 40, 162, 90, 134, 151, 54, 25, 221, 109, 180, 141, 39, 161, 126, 64, 150], 'accuracy': 0.8333333333333334, 'kappa': 0.6666666666666667, 'auc': 0.9027777777777778}, {'fold_index': 1, 'train_indices': [194, 31, 72, 117, 177, 152, 176, 179, 116, 39, 157, 98, 73, 58, 107, 193, 162, 210, 94, 173, 68, 223, 186, 22, 138, 145, 63, 88, 213, 215, 217, 161, 109, 2, 158, 76, 160, 230, 141, 236, 5, 37, 97, 237, 195, 23, 43, 142, 119, 67, 115, 124, 105, 219, 169, 188, 175, 12, 111, 112, 174, 135, 212, 16, 184, 235, 180, 14, 120, 122, 25, 226, 8, 218, 57, 87, 46, 59, 96, 66, 216, 181, 203, 65, 47, 17, 202, 80, 234, 7, 95, 229, 91, 38, 32, 133, 209, 82, 134, 79, 221, 30, 70, 231, 62, 75, 19, 93, 40, 74, 147, 205, 220, 207, 199, 165, 225, 127, 4, 136, 21, 149, 103, 150, 69, 49, 182, 204, 129, 131, 146, 89, 153, 36, 90, 196, 29, 3, 214, 26, 110, 20, 198, 0, 52, 101, 64, 197, 190, 143, 45, 83, 222, 144, 27, 55, 81, 54, 238, 123, 140, 10, 187, 118, 159, 232, 6, 148, 114, 137, 189, 60, 164, 13, 28, 163, 130, 192, 78, 121, 125, 50, 34, 92, 128, 113, 201, 85, 42, 18, 178], 'val_indices': [166, 1, 35, 99, 208, 183, 206, 154, 155, 167, 185, 200, 48, 151, 84, 44, 77, 71, 11, 227, 86, 33, 104, 24, 53, 9, 61, 228, 15, 139, 172, 156, 211, 224, 171, 108, 102, 132, 51, 56, 191, 233, 170, 106, 100, 168, 41, 126], 'accuracy': 0.7916666666666666, 'kappa': 0.5833333333333333, 'auc': 0.8784722222222222}, {'fold_index': 2, 'train_indices': [108, 191, 184, 3, 190, 90, 5, 165, 25, 172, 35, 136, 81, 178, 33, 110, 29, 114, 69, 223, 13, 229, 109, 91, 97, 205, 141, 128, 237, 93, 231, 104, 83, 148, 201, 228, 214, 212, 181, 236, 84, 119, 151, 23, 118, 179, 78, 11, 166, 10, 57, 66, 125, 162, 71, 19, 197, 221, 44, 80, 210, 16, 220, 209, 139, 222, 213, 186, 234, 59, 12, 74, 40, 24, 206, 26, 79, 20, 76, 101, 153, 51, 161, 0, 218, 45, 63, 146, 42, 126, 100, 149, 144, 70, 123, 130, 175, 169, 137, 18, 177, 156, 217, 142, 188, 199, 41, 53, 102, 160, 9, 31, 196, 187, 115, 85, 2, 232, 132, 143, 27, 95, 56, 15, 155, 117, 49, 127, 92, 208, 215, 168, 47, 203, 227, 60, 122, 164, 50, 226, 75, 180, 195, 103, 182, 116, 167, 55, 72, 171, 46, 211, 189, 140, 135, 87, 120, 28, 163, 68, 235, 185, 48, 105, 4, 204, 7, 170, 62, 64, 8, 202, 111, 216, 154, 107, 77, 194, 145, 99, 89, 32, 207, 198, 22, 98, 96, 174, 39, 61, 121], 'val_indices': [152, 43, 159, 133, 37, 52, 21, 6, 134, 30, 65, 157, 94, 106, 233, 129, 147, 131, 1, 34, 17, 173, 230, 38, 193, 183, 224, 200, 238, 192, 176, 138, 219, 54, 88, 86, 225, 150, 113, 14, 82, 124, 73, 112, 158, 67, 58, 36], 'accuracy': 0.8958333333333334, 'kappa': 0.7916666666666666, 'auc': 0.921875}, {'fold_index': 3, 'train_indices': [164, 165, 195, 125, 229, 81, 202, 106, 196, 221, 64, 10, 66, 151, 141, 29, 209, 78, 52, 63, 28, 183, 210, 23, 214, 157, 219, 199, 208, 12, 4, 230, 21, 102, 95, 55, 97, 216, 3, 98, 19, 83, 53, 122, 116, 84, 144, 193, 188, 2, 58, 205, 129, 94, 120, 51, 223, 42, 211, 225, 145, 124, 107, 117, 43, 200, 35, 155, 135, 192, 27, 87, 217, 161, 194, 62, 140, 220, 181, 47, 190, 88, 163, 69, 169, 26, 80, 232, 71, 175, 15, 191, 16, 0, 17, 235, 197, 73, 176, 32, 201, 41, 25, 13, 206, 60, 218, 92, 11, 222, 46, 77, 121, 110, 93, 123, 44, 142, 237, 128, 150, 167, 203, 70, 189, 118, 132, 113, 56, 143, 111, 45, 119, 30, 126, 185, 105, 39, 9, 5, 24, 204, 138, 74, 108, 170, 162, 187, 72, 127, 22, 130, 228, 20, 65, 148, 8, 99, 177, 207, 96, 149, 100, 172, 90, 233, 57, 152, 159, 137, 7, 61, 134, 213, 103, 198, 160, 38, 173, 136, 91, 40, 54, 6, 37, 131, 31, 227, 184, 178, 36], 'val_indices': [174, 114, 236, 59, 215, 224, 75, 171, 82, 79, 76, 109, 18, 133, 14, 146, 231, 68, 168, 186, 48, 238, 234, 49, 147, 166, 104, 85, 179, 226, 33, 153, 112, 182, 67, 154, 158, 50, 212, 86, 139, 101, 89, 115, 156, 180, 34, 1], 'accuracy': 0.8541666666666666, 'kappa': 0.7083333333333333, 'auc': 0.9166666666666666}, {'fold_index': 4, 'train_indices': [193, 150, 196, 99, 164, 32, 105, 65, 231, 87, 27, 56, 96, 139, 80, 51, 140, 57, 218, 22, 59, 6, 18, 114, 7, 145, 50, 85, 25, 125, 112, 55, 216, 45, 91, 26, 30, 161, 98, 153, 70, 198, 47, 199, 154, 168, 92, 68, 203, 233, 77, 78, 33, 130, 159, 16, 43, 197, 234, 71, 214, 10, 221, 165, 106, 184, 171, 44, 238, 54, 123, 237, 24, 42, 102, 88, 31, 176, 104, 136, 211, 20, 135, 72, 115, 1, 38, 117, 230, 0, 108, 119, 82, 235, 37, 170, 110, 121, 13, 132, 156, 155, 226, 204, 35, 79, 147, 116, 81, 148, 89, 94, 137, 133, 188, 75, 225, 11, 228, 129, 60, 220, 162, 192, 29, 95, 15, 14, 186, 19, 3, 17, 182, 49, 109, 76, 177, 223, 207, 173, 134, 232, 122, 149, 90, 138, 39, 152, 118, 229, 97, 141, 181, 236, 187, 201, 100, 190, 83, 195, 179, 107, 227, 146, 120, 53, 124, 86, 202, 69, 9, 178, 126, 175, 64, 166, 167, 163, 103, 127, 209, 144, 157, 183, 41, 219, 28, 34, 200, 158, 61], 'val_indices': [143, 66, 63, 73, 205, 74, 191, 2, 212, 128, 131, 151, 84, 93, 172, 194, 101, 4, 213, 5, 222, 217, 210, 36, 21, 169, 23, 113, 111, 67, 174, 40, 189, 206, 180, 8, 12, 62, 160, 142, 48, 46, 185, 224, 208, 215, 58, 52], 'accuracy': 0.6875, 'kappa': 0.375, 'auc': 0.8298611111111112}], 'std_acc': 0.071, 'std_kappa': 0.142, 'std_auc': 0.034}\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "\n",
    "subjects = [47,10,46]\n",
    "\n",
    "for sbj in subjects[:]:\n",
    "  print('sbj = ', sbj)\n",
    "  load_args['sbj'] = sbj\n",
    "  results = train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed)\n",
    "  with open('sbj' + str(load_args['sbj']) + '.txt', 'wb') as f:\n",
    "    dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a500251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T19:57:37.737529Z",
     "iopub.status.busy": "2024-12-12T19:57:37.736959Z",
     "iopub.status.idle": "2024-12-12T19:57:40.313469Z",
     "shell.execute_reply": "2024-12-12T19:57:40.311915Z"
    },
    "id": "V7-P0xjwzXVX",
    "outputId": "270dceef-351d-48d1-f71e-2c3367c7fdac",
    "papermill": {
     "duration": 2.602642,
     "end_time": "2024-12-12T19:57:40.316325",
     "exception": false,
     "start_time": "2024-12-12T19:57:37.713683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: sbj10.h5 (deflated 75%)\r\n",
      "  adding: sbj46.h5 (deflated 75%)\r\n",
      "  adding: sbj47.h5 (deflated 75%)\r\n",
      "  adding: sbj10.txt (deflated 42%)\r\n",
      "  adding: sbj46.txt (deflated 40%)\r\n",
      "  adding: sbj47.txt (deflated 40%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip Models_64ch_EEGNet.zip ./*.h5 \n",
    "!zip Results_64ch_EEGNet.zip ./*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a15c6e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T19:57:40.354563Z",
     "iopub.status.busy": "2024-12-12T19:57:40.354096Z",
     "iopub.status.idle": "2024-12-12T19:57:40.360165Z",
     "shell.execute_reply": "2024-12-12T19:57:40.358705Z"
    },
    "papermill": {
     "duration": 0.028307,
     "end_time": "2024-12-12T19:57:40.362563",
     "exception": false,
     "start_time": "2024-12-12T19:57:40.334256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle as pkl\n",
    "\n",
    "#with open(file= '/kaggle/working/sbj14.txt', mode = 'rb' ) as f:\n",
    "#    results_64ch_ShallowConvNet = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea943f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T19:57:40.400059Z",
     "iopub.status.busy": "2024-12-12T19:57:40.399534Z",
     "iopub.status.idle": "2024-12-12T19:57:40.406205Z",
     "shell.execute_reply": "2024-12-12T19:57:40.405057Z"
    },
    "papermill": {
     "duration": 0.028739,
     "end_time": "2024-12-12T19:57:40.408497",
     "exception": false,
     "start_time": "2024-12-12T19:57:40.379758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_64ch_ShallowConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e615d01e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T19:57:40.446838Z",
     "iopub.status.busy": "2024-12-12T19:57:40.445731Z",
     "iopub.status.idle": "2024-12-12T19:57:40.450978Z",
     "shell.execute_reply": "2024-12-12T19:57:40.449831Z"
    },
    "papermill": {
     "duration": 0.026631,
     "end_time": "2024-12-12T19:57:40.453230",
     "exception": false,
     "start_time": "2024-12-12T19:57:40.426599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(file= '/kaggle/working/sbj2.txt', mode = 'rb' ) as f:\n",
    " #   results_64ch_ShallowConvNet = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "893938a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T19:57:40.492540Z",
     "iopub.status.busy": "2024-12-12T19:57:40.492043Z",
     "iopub.status.idle": "2024-12-12T19:57:40.498492Z",
     "shell.execute_reply": "2024-12-12T19:57:40.496949Z"
    },
    "papermill": {
     "duration": 0.031114,
     "end_time": "2024-12-12T19:57:40.501831",
     "exception": false,
     "start_time": "2024-12-12T19:57:40.470717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_64ch_ShallowConvNet"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1645904,
     "sourceId": 2702213,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1269900,
     "sourceId": 2702226,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2984453,
     "sourceId": 5137200,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3008205,
     "sourceId": 5175158,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13590.761488,
   "end_time": "2024-12-12T19:57:43.350133",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-12T16:11:12.588645",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
