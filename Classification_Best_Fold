{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7d2c57",
   "metadata": {
    "id": "x9LNzEYERaH2",
    "papermill": {
     "duration": 0.003817,
     "end_time": "2025-08-17T03:24:50.498034",
     "exception": false,
     "start_time": "2025-08-17T03:24:50.494217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0789854e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:24:50.505460Z",
     "iopub.status.busy": "2025-08-17T03:24:50.505095Z",
     "iopub.status.idle": "2025-08-17T03:24:51.582256Z",
     "shell.execute_reply": "2025-08-17T03:24:51.581331Z"
    },
    "papermill": {
     "duration": 1.082975,
     "end_time": "2025-08-17T03:24:51.584179",
     "exception": false,
     "start_time": "2025-08-17T03:24:50.501204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-492f16a7-25cb-92de-e175-34ac22971b12)\r\n",
      "GPU 1: Tesla T4 (UUID: GPU-c63c4b85-1822-2363-3d94-de0e217fa318)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2b4025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:24:51.592017Z",
     "iopub.status.busy": "2025-08-17T03:24:51.591703Z",
     "iopub.status.idle": "2025-08-17T03:25:39.624432Z",
     "shell.execute_reply": "2025-08-17T03:25:39.623409Z"
    },
    "id": "K0oS6IH7VTZX",
    "papermill": {
     "duration": 48.039042,
     "end_time": "2025-08-17T03:25:39.626568",
     "exception": false,
     "start_time": "2025-08-17T03:24:51.587526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n",
    "!pip install mne #The MNE Package is installed\n",
    "FILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip MI_EEG_ClassMeth.zip #Package with useful functions for motor imagery classification based in EEG.\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2be7ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:25:39.634489Z",
     "iopub.status.busy": "2025-08-17T03:25:39.634173Z",
     "iopub.status.idle": "2025-08-17T03:27:10.324988Z",
     "shell.execute_reply": "2025-08-17T03:27:10.323476Z"
    },
    "papermill": {
     "duration": 90.697433,
     "end_time": "2025-08-17T03:27:10.327457",
     "exception": false,
     "start_time": "2025-08-17T03:25:39.630024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "Package libcudnn8 is not available, but is referred to by another package.\r\n",
      "This may mean that the package is missing, has been obsoleted, or\r\n",
      "is only available from another source\r\n",
      "\r\n",
      "E: Version '8.1.0.77-1+cuda11.2' for 'libcudnn8' was not found\r\n",
      "Collecting tensorflow==2.8.2\r\n",
      "  Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (24.3.25)\r\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.11.0)\r\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.2)\r\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (18.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.3.0)\r\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.8.2)\r\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.16.0)\r\n",
      "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow==2.8.2)\r\n",
      "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.2)\r\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.37.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.62.2)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.2) (0.43.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.30.0)\r\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.6)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.32.3)\r\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.0.4)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2024.8.30)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.5)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.6.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.2)\r\n",
      "Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl (498.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\r\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tensorflow-estimator, tensorboard-plugin-wit, keras, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\r\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "  Attempting uninstall: tensorboard-data-server\r\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\r\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\r\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: google-auth-oauthlib\r\n",
      "    Found existing installation: google-auth-oauthlib 1.2.0\r\n",
      "    Uninstalling google-auth-oauthlib-1.2.0:\r\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.0\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.16.2\r\n",
      "    Uninstalling tensorboard-2.16.2:\r\n",
      "      Successfully uninstalled tensorboard-2.16.2\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.16.1\r\n",
      "    Uninstalling tensorflow-2.16.1:\r\n",
      "      Successfully uninstalled tensorflow-2.16.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-datastore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-language 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-videointelligence 2.13.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "onnx 1.17.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.8.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.2 tensorflow-estimator-2.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 -y\n",
    "!pip install tensorflow==2.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef27d8",
   "metadata": {
    "papermill": {
     "duration": 0.014005,
     "end_time": "2025-08-17T03:27:10.360119",
     "exception": false,
     "start_time": "2025-08-17T03:27:10.346114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996668e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:27:10.386260Z",
     "iopub.status.busy": "2025-08-17T03:27:10.385939Z",
     "iopub.status.idle": "2025-08-17T03:27:21.855243Z",
     "shell.execute_reply": "2025-08-17T03:27:21.854244Z"
    },
    "id": "yE1sbHYQVbBq",
    "papermill": {
     "duration": 11.485378,
     "end_time": "2025-08-17T03:27:21.857651",
     "exception": false,
     "start_time": "2025-08-17T03:27:10.372273",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gcpds.databases.BCI_Competition_IV import Dataset_2a\n",
    "from typing import Sequence, Tuple\n",
    "from MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "\n",
    "def load_BCICIV2a(db: Dataset_2a,\n",
    "               sbj: int,\n",
    "               mode: str,\n",
    "               fs: float, \n",
    "               f_bank: np.ndarray, \n",
    "               vwt: np.ndarray, \n",
    "               new_fs: float) -> np.ndarray:\n",
    "\n",
    "  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
    "\n",
    "  db.load_subject(sbj, mode = mode)\n",
    "\n",
    "    \n",
    "  X_all, y_all = db.get_data()  #Load all classes, all channels {EEG, EOG}, reject bad trials\n",
    "\n",
    "  indices_to_keep = np.where((y_all == 0) | (y_all == 1))[0]\n",
    "  X = X_all[indices_to_keep]\n",
    "  y = y_all[indices_to_keep]\n",
    "  print(f\"Filtered from {len(y_all)} trials to {len(y)} trials (classes 0 and 1 only).\")\n",
    "\n",
    "    \n",
    "  X = X[:,:-3,:] # pick EEG channels\n",
    "  X = X*1e6 #uV\n",
    "  X = np.squeeze(tf_repr.transform(X))\n",
    "  #Resampling\n",
    "  if new_fs == fs:\n",
    "    print('No resampling, since new sampling rate same.')\n",
    "  else:\n",
    "    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
    "    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
    "    \n",
    "  return X, y\n",
    "\n",
    "\n",
    "from gcpds.databases import GIGA_MI_ME\n",
    "\n",
    "def load_GIGA_MI_ME(db: GIGA_MI_ME,\n",
    "              sbj: int,\n",
    "              eeg_ch_names: Sequence[str],\n",
    "              fs: float, \n",
    "              f_bank: np.ndarray, \n",
    "              vwt: np.ndarray, \n",
    "              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    index_eeg_chs = db.format_channels_selectors(channels=eeg_ch_names) - 1\n",
    "\n",
    "    tf_repr = TimeFrequencyRpr(sfreq=fs, f_bank=f_bank, vwt=vwt)\n",
    "\n",
    "    # Load subject data\n",
    "    db.load_subject(sbj)\n",
    "    X, y = db.get_data(classes=['left hand mi', 'right hand mi'])\n",
    "    \n",
    "    # Debugging total trials\n",
    "    print(f\"Total trials loaded: {X.shape[0]}\")\n",
    "    print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
    "\n",
    "    # Spatial rearrangement\n",
    "    X = X[:, index_eeg_chs, :]  \n",
    "    X = np.squeeze(tf_repr.transform(X))\n",
    "\n",
    "    # Resampling\n",
    "    if new_fs == fs:\n",
    "        print('No resampling, since new sampling rate is the same.')\n",
    "    else:\n",
    "        print(f\"Resampling from {fs} to {new_fs} Hz.\")\n",
    "        X = resample(X, int((X.shape[-1] / fs) * new_fs), axis=-1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def load_DB(db_name, **load_args):\n",
    "  if db_name == 'BCICIV2a':\n",
    "    X_train, y_train = load_BCICIV2a(**load_args, mode = 'training')\n",
    "    X_test, y_test = load_BCICIV2a(**load_args, mode = 'evaluation')\n",
    "\n",
    "    X_train = np.concatenate([X_train, X_test], axis = 0)\n",
    "    y_train = np.concatenate([y_train, y_test], axis = 0)\n",
    "\n",
    "  elif db_name == 'GIGA_MI_ME':\n",
    "    X_train, y_train = load_GIGA_MI_ME(**load_args)\n",
    "    \n",
    "  else:\n",
    "    raise ValueError('No valid database name')\n",
    "\n",
    "  return X_train, y_train\n",
    "\n",
    "\n",
    "from EEG_Tensorflow_models.Models import DeepConvNet, ShallowConvNet, EEGNet, DMTL_BCI, TCNet_fusion, PST_attention\n",
    "\n",
    "\n",
    "def get_model(model_name, nb_classes):\n",
    "  if model_name == 'DeepConvNet':\n",
    "    model = DeepConvNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5, version='2018')\n",
    "    \n",
    "  elif model_name == 'ShallowConvNet':\n",
    "    model = ShallowConvNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      version = '2018')\n",
    "    \n",
    "  elif model_name == 'EEGNet':\n",
    "    model = EEGNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      kernLength = 32,\n",
    "                      F1 = 8,\n",
    "                      D = 2,\n",
    "                      F2 = 16,\n",
    "                      norm_rate = 0.25, \n",
    "                      dropoutType = 'Dropout')\n",
    "    \n",
    "  elif model_name == 'DMTL_BCI':\n",
    "    model = DMTL_BCI\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      l1 = 0,\n",
    "                      l2 = 0)\n",
    "    \n",
    "  elif model_name == 'TCNet_fusion':\n",
    "    model = TCNet_fusion\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      layers = 2,\n",
    "                      kernel_s = 4,\n",
    "                      filt = 12,\n",
    "                      dropout = 0.3,\n",
    "                      activation = 'relu',\n",
    "                      F1 = 24,\n",
    "                      D = 2,\n",
    "                      kernLength = 32,\n",
    "                      N_residuals = 2)\n",
    "    \n",
    "  elif model_name == 'PST_attention':\n",
    "    model = PST_attention\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      last_layer = 'Dense')\n",
    "    \n",
    "  else:\n",
    "    raise ValueError('No valid model name')\n",
    "    \n",
    "  return model, model_params\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score,\\\n",
    "                            f1_score, recall_score, precision_score\n",
    "\n",
    "def train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed):\n",
    "    X_train, y_train = load_DB(db_name, **load_args)\n",
    "    X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    \n",
    "    cv_results = {'params': [],\n",
    "                  'mean_acc': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_kappa': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_auc': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_f1_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_f1_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_recall_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_recall_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_precision_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_precision_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'all_folds': []}\n",
    "    \n",
    "    k = 0\n",
    "    max_acc = -np.inf\n",
    "\n",
    "    # Loop through folds\n",
    "    for train_index, val_index in cv_args['cv'].split(X_train, y_train):\n",
    "        print(f\"Running fold {k} with {len(train_index)} training samples and {len(val_index)} validation samples\")\n",
    "        print(f\"Fold {k}: train indices: {train_index[:5]}, val indices: {val_index[:5]}\")  # Print first indices\n",
    "        \n",
    "        X, X_val = X_train[train_index], X_train[val_index]\n",
    "        y, y_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        if model_args['autoencoder']:\n",
    "            y = [X, y]\n",
    "        \n",
    "        print(f\"Training data shape: {X.shape}, Validation data shape: {X_val.shape}\")\n",
    "        \n",
    "        batch_size, C, T = X.shape[:-1]\n",
    "        clear_session()\n",
    "        set_seed(seed)\n",
    "\n",
    "        model_cll, model_params = get_model(model_args['model_name'], model_args['nb_classes'])\n",
    "        model = model_cll(**model_params, Chans=22, Samples=T)\n",
    "        model.compile(loss=compile_args['loss'], optimizer=Adam(compile_args['init_lr']))\n",
    "\n",
    "        history = model.fit(X, y, batch_size=batch_size, **fit_args)\n",
    "        print(f\"Fold {k} training loss: {history.history['loss'][-1]}\")  # Print final loss\n",
    "\n",
    "        if model_args['autoencoder']:\n",
    "            y_prob = model.predict(X_val)[-1]\n",
    "        else:\n",
    "            y_prob = model.predict(X_val)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "        print(f\"y_true (val): {y_val[:5]}\")\n",
    "        print(f\"y_pred: {y_pred[:5]}\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        kappa = cohen_kappa_score(y_val, y_pred)\n",
    "        auc = roc_auc_score(y_val, y_prob[:, 1], average='macro') if model_args['nb_classes'] == 2 else None\n",
    "        \n",
    "        # Save metrics for this fold\n",
    "        fold_result = {\n",
    "            'fold_index': k,\n",
    "            'train_indices': train_index.tolist(),\n",
    "            'val_indices': val_index.tolist(),\n",
    "            'accuracy': acc,\n",
    "            'kappa': kappa,\n",
    "            'auc': auc\n",
    "        }\n",
    "        print(f\"Appending results for fold {k}: {fold_result}\")\n",
    "        cv_results['all_folds'].append(fold_result)\n",
    "\n",
    "        # Update overall fold metrics\n",
    "        cv_results['mean_acc'][k] = acc\n",
    "        cv_results['mean_kappa'][k] = kappa\n",
    "        if auc is not None:\n",
    "            cv_results['mean_auc'][k] = auc\n",
    "        \n",
    "        # Save the best model weights\n",
    "        if acc > max_acc:\n",
    "            print('New Max Found!')\n",
    "            max_acc = acc\n",
    "            model.save_weights(f'sbj{load_args[\"sbj\"]}.h5')\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    # Calculate mean and std metrics\n",
    "    cv_results['std_acc'] = round(cv_results['mean_acc'].std(), 3)\n",
    "    cv_results['mean_acc'] = round(cv_results['mean_acc'].mean(), 3)\n",
    "    cv_results['std_kappa'] = round(cv_results['mean_kappa'].std(), 3)\n",
    "    cv_results['mean_kappa'] = round(cv_results['mean_kappa'].mean(), 3)\n",
    "    cv_results['std_auc'] = round(cv_results['mean_auc'].std(), 3)\n",
    "    cv_results['mean_auc'] = round(cv_results['mean_auc'].mean(), 3)\n",
    "    \n",
    "    print(f\"Final cross-validation results: {cv_results}\")\n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37395591",
   "metadata": {
    "id": "uBAeW6J5S68g",
    "papermill": {
     "duration": 0.011682,
     "end_time": "2025-08-17T03:27:21.882099",
     "exception": false,
     "start_time": "2025-08-17T03:27:21.870417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff834452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:27:21.907259Z",
     "iopub.status.busy": "2025-08-17T03:27:21.906636Z",
     "iopub.status.idle": "2025-08-17T03:27:21.911336Z",
     "shell.execute_reply": "2025-08-17T03:27:21.910486Z"
    },
    "id": "2I3IQnNSS9-a",
    "papermill": {
     "duration": 0.018967,
     "end_time": "2025-08-17T03:27:21.912882",
     "exception": false,
     "start_time": "2025-08-17T03:27:21.893915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Marcos, use these two variables to run the state of the art. First, for BCICIV2a run all the models.\n",
    "# Remeber that this network DMTL_BCI is an autoencoder. Set the nb_classses parameter depending of the database.\n",
    "# set autoencoder based on the model\n",
    "# We need to run all these tests again. Do not forget to add the recall, preci, and f1 for each class (bci 4, giga 2)\n",
    "db_name = 'BCICIV2a'\n",
    "model_args = dict(model_name = 'ShallowConvNet',\n",
    "                  nb_classes = 2,\n",
    "                  autoencoder = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd04235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:27:21.938134Z",
     "iopub.status.busy": "2025-08-17T03:27:21.937545Z",
     "iopub.status.idle": "2025-08-17T03:27:21.949372Z",
     "shell.execute_reply": "2025-08-17T03:27:21.948695Z"
    },
    "id": "tqMhUFoBIc3B",
    "outputId": "1405fd59-1374-4d5d-8e3a-5e7a45c79bba",
    "papermill": {
     "duration": 0.026294,
     "end_time": "2025-08-17T03:27:21.950986",
     "exception": false,
     "start_time": "2025-08-17T03:27:21.924692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TerminateOnNaN\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "if db_name == 'BCICIV2a':\n",
    "  db = Dataset_2a('/kaggle/input/bciiv2a-gcpds/BCI_CIV_2a')\n",
    "  fs = db.metadata['sampling_rate']\n",
    "  load_args = dict(db = db,\n",
    "                 fs = fs,\n",
    "                 f_bank = np.asarray([[4., 40.]]),\n",
    "                 vwt = np.asarray([[2.5, 6]]),\n",
    "                 new_fs = 128.)\n",
    "  subjects = np.arange(db.metadata['subjects']) + 1\n",
    "  \n",
    "elif db_name == 'GIGA_MI_ME':\n",
    "  db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n",
    "  fs = db.metadata['sampling_rate']\n",
    "\n",
    "  # eeg_ch_names = ['Fp1','Fpz','Fp2',\n",
    "  #                    'AF7','AF3','AFz','AF4','AF8',\n",
    "  #                   'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
    "  #                  'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n",
    "  #                   'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
    "  #                  'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n",
    "  #                   'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n",
    "  #                   'PO7','PO3','POz','PO4','PO8',\n",
    "  #                   'O1','Oz','O2',\n",
    "  #                   'Iz']\n",
    "\n",
    "  # eeg_ch_names = ['Fp1','Fp2',\n",
    "  #                  'AF3','AF4',\n",
    "  #                  'F7','F3','Fz','F4','F8',\n",
    "  #                  'FC5','FC1','FC2','FC6',\n",
    "  #                  'T7','C3','Cz','C4','T8',\n",
    "  #                  'CP5','CP1','CP2','CP6',\n",
    "  #                  'P7','P3','Pz','P4','P8',\n",
    "  #                  'PO3','PO4',\n",
    "  #                  'O1','Oz','O2']\n",
    "\n",
    "  # eeg_ch_names = ['Fp1','Fp2',\n",
    "  #                 'F7','F3','F4','F8',\n",
    "  #                 'T7','C3','C4','T8',\n",
    "  #                 'P7','P3','P4','P8',\n",
    "  #                 'O1','O2']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  eeg_ch_names = ['Fp1','Fp2',\n",
    "               'T7','C3','C4','T8',\n",
    "               'O1','O2']\n",
    "    \n",
    "\n",
    "\n",
    "  load_args = dict(db = db,\n",
    "                  eeg_ch_names = eeg_ch_names,\n",
    "                  fs = fs,\n",
    "                  f_bank = np.asarray([[4., 40.]]),\n",
    "                  vwt = np.asarray([[2.5, 5]]),\n",
    "                  new_fs = 128.)\n",
    "  subjects = np.arange(db.metadata['subjects']) + 1\n",
    "  subjects = np.delete(subjects, [28,33])\n",
    "  \n",
    "else:\n",
    "  raise ValueError('No valid database name')\n",
    "\n",
    "verbose = 0\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 30, verbose = verbose, mode = 'min', min_delta = 0.01, min_lr = 0)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "callbacks = [reduce_lr_on_plateau, terminate_on_nan]\n",
    "seed = 23\n",
    "\n",
    "cv_args = dict(cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.2, random_state = seed))\n",
    "\n",
    "compile_args = dict(loss = SparseCategoricalCrossentropy(), #['mse' , SparseCategoricalCrossentropy()]\n",
    "                    init_lr = 1e-2)\n",
    "                      \n",
    "fit_args = dict(epochs = 500,\n",
    "                verbose = verbose,\n",
    "                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9511c73",
   "metadata": {
    "id": "ukhXifxzTaj9",
    "papermill": {
     "duration": 0.011512,
     "end_time": "2025-08-17T03:27:21.974291",
     "exception": false,
     "start_time": "2025-08-17T03:27:21.962779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "271082bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:27:21.999718Z",
     "iopub.status.busy": "2025-08-17T03:27:21.999466Z",
     "iopub.status.idle": "2025-08-17T08:39:31.633245Z",
     "shell.execute_reply": "2025-08-17T08:39:31.632240Z"
    },
    "id": "Ymqd_W21y3NK",
    "outputId": "5ca97a2f-f57c-46ee-8f53-f00181ccea90",
    "papermill": {
     "duration": 18729.667301,
     "end_time": "2025-08-17T08:39:31.653933",
     "exception": false,
     "start_time": "2025-08-17T03:27:21.986632",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbj =  1\n",
      "Filtered from 273 trials to 138 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 281 trials to 141 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (279, 22, 448, 1), y_train shape: (279,)\n",
      "Running fold 0 with 223 training samples and 56 validation samples\n",
      "Fold 0: train indices: [126 183 141 159 207], val indices: [ 75  15  26 253 111]\n",
      "Training data shape: (223, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 0 training loss: 0.008732094429433346\n",
      "y_true (val): [0 1 0 1 1]\n",
      "y_pred: [1 1 0 1 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [126, 183, 141, 159, 207, 72, 81, 16, 80, 202, 71, 149, 110, 219, 231, 192, 174, 20, 37, 91, 225, 113, 167, 132, 157, 229, 270, 160, 242, 201, 84, 267, 33, 185, 190, 119, 60, 31, 191, 78, 98, 36, 245, 22, 218, 96, 97, 27, 89, 87, 205, 17, 255, 50, 224, 249, 0, 109, 187, 161, 244, 128, 142, 197, 63, 268, 189, 66, 12, 130, 45, 18, 154, 206, 116, 188, 254, 243, 83, 199, 277, 108, 256, 228, 25, 138, 86, 155, 127, 250, 241, 90, 102, 265, 156, 7, 100, 104, 186, 135, 239, 136, 67, 216, 54, 49, 204, 178, 42, 272, 88, 48, 143, 122, 278, 68, 61, 237, 124, 93, 46, 212, 257, 14, 162, 227, 121, 166, 194, 118, 114, 221, 10, 41, 230, 8, 140, 51, 56, 195, 85, 5, 43, 198, 38, 182, 59, 260, 133, 39, 3, 223, 28, 252, 35, 125, 236, 264, 144, 275, 9, 226, 137, 233, 145, 165, 175, 47, 234, 79, 29, 147, 106, 184, 19, 259, 112, 251, 34, 168, 69, 196, 266, 64, 200, 213, 208, 211, 193, 210, 153, 58, 24, 263, 146, 40, 235, 13, 76, 139, 99, 52, 115, 164, 240, 2, 152, 151, 4, 215, 11, 101, 92, 248, 217, 274, 82, 214, 105, 62, 169, 271, 209], 'val_indices': [75, 15, 26, 253, 111, 163, 180, 179, 170, 150, 57, 53, 65, 148, 23, 44, 220, 171, 269, 238, 30, 6, 21, 70, 103, 261, 203, 134, 262, 94, 172, 173, 158, 1, 181, 74, 55, 247, 273, 32, 276, 177, 129, 131, 77, 246, 95, 123, 232, 258, 107, 73, 176, 117, 222, 120], 'accuracy': 0.8392857142857143, 'kappa': 0.6785714285714286, 'auc': 0.9298469387755102}\n",
      "New Max Found!\n",
      "Running fold 1 with 223 training samples and 56 validation samples\n",
      "Fold 1: train indices: [197 174  81 179  32], val indices: [251 200  66 263  29]\n",
      "Training data shape: (223, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 1 training loss: 0.009567438624799252\n",
      "y_true (val): [1 1 1 0 0]\n",
      "y_pred: [1 0 1 0 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [197, 174, 81, 179, 32, 209, 47, 204, 97, 117, 10, 252, 205, 243, 31, 127, 11, 155, 273, 271, 26, 166, 115, 130, 36, 274, 17, 122, 34, 91, 232, 181, 270, 213, 45, 260, 240, 224, 0, 53, 134, 57, 186, 167, 157, 165, 160, 227, 264, 137, 99, 151, 69, 40, 78, 65, 105, 265, 59, 222, 140, 118, 35, 9, 87, 152, 190, 219, 237, 276, 233, 136, 16, 210, 253, 193, 51, 147, 121, 231, 173, 164, 255, 196, 154, 229, 228, 28, 133, 77, 89, 90, 64, 148, 199, 220, 37, 54, 63, 76, 107, 278, 44, 150, 144, 14, 102, 100, 41, 60, 146, 12, 218, 52, 119, 141, 201, 22, 249, 101, 170, 247, 7, 142, 15, 171, 214, 68, 248, 131, 216, 103, 203, 169, 139, 13, 33, 269, 42, 21, 126, 72, 43, 143, 262, 212, 191, 55, 46, 108, 5, 275, 94, 71, 207, 128, 48, 58, 202, 159, 267, 80, 153, 112, 161, 6, 56, 215, 168, 189, 30, 106, 261, 1, 20, 125, 67, 256, 18, 74, 254, 226, 272, 84, 113, 194, 241, 245, 79, 132, 111, 156, 93, 242, 211, 238, 277, 3, 176, 172, 109, 25, 192, 75, 221, 129, 19, 2, 49, 120, 162, 138, 223, 24, 175, 184, 180, 88, 236, 239, 123, 124, 177], 'val_indices': [251, 200, 66, 263, 29, 183, 187, 110, 206, 250, 259, 246, 4, 230, 195, 96, 208, 95, 145, 38, 27, 149, 178, 217, 83, 158, 50, 185, 98, 70, 188, 225, 23, 198, 244, 163, 92, 116, 235, 266, 62, 104, 73, 8, 114, 135, 86, 234, 39, 182, 82, 61, 258, 268, 85, 257], 'accuracy': 0.8035714285714286, 'kappa': 0.6071428571428572, 'auc': 0.9234693877551019}\n",
      "Running fold 2 with 223 training samples and 56 validation samples\n",
      "Fold 2: train indices: [ 86 178 215 238  75], val indices: [278 270 119 260 214]\n",
      "Training data shape: (223, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 2 training loss: 0.009936308488249779\n",
      "y_true (val): [1 1 0 0 0]\n",
      "y_pred: [1 1 0 0 0]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [86, 178, 215, 238, 75, 57, 230, 4, 213, 31, 13, 22, 77, 128, 1, 132, 168, 190, 39, 55, 150, 209, 189, 234, 236, 155, 66, 254, 109, 115, 16, 135, 151, 81, 218, 49, 130, 76, 136, 0, 63, 67, 188, 56, 205, 34, 184, 87, 133, 145, 40, 24, 207, 167, 240, 84, 204, 117, 221, 131, 147, 183, 237, 263, 11, 247, 80, 141, 170, 223, 225, 106, 111, 129, 206, 48, 197, 226, 83, 171, 169, 72, 251, 6, 79, 23, 64, 30, 245, 157, 82, 88, 219, 92, 253, 198, 97, 256, 224, 231, 100, 104, 252, 210, 217, 146, 51, 176, 203, 159, 193, 139, 7, 14, 211, 27, 124, 85, 103, 107, 235, 28, 102, 160, 59, 164, 140, 233, 120, 192, 101, 274, 89, 242, 121, 2, 137, 73, 93, 58, 47, 69, 19, 25, 177, 248, 152, 179, 12, 259, 116, 74, 62, 166, 174, 208, 262, 52, 18, 17, 239, 44, 249, 180, 187, 161, 42, 241, 232, 265, 266, 71, 46, 125, 194, 277, 26, 229, 216, 68, 244, 144, 148, 94, 61, 45, 91, 154, 108, 227, 255, 172, 173, 228, 165, 38, 98, 200, 90, 96, 9, 273, 199, 134, 35, 142, 195, 275, 212, 3, 243, 54, 112, 70, 250, 41, 201, 127, 153, 246, 162, 175, 276], 'val_indices': [278, 270, 119, 260, 214, 65, 158, 10, 114, 21, 257, 123, 143, 163, 15, 269, 185, 196, 33, 149, 113, 78, 202, 5, 36, 182, 261, 268, 95, 20, 110, 37, 8, 32, 99, 126, 220, 272, 181, 264, 60, 186, 105, 43, 222, 271, 122, 191, 118, 50, 29, 267, 156, 138, 258, 53], 'accuracy': 0.9107142857142857, 'kappa': 0.8214285714285714, 'auc': 0.9846938775510204}\n",
      "New Max Found!\n",
      "Running fold 3 with 223 training samples and 56 validation samples\n",
      "Fold 3: train indices: [239 266  18  42 210], val indices: [214 242 270 150 153]\n",
      "Training data shape: (223, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 3 training loss: 0.008161116391420364\n",
      "y_true (val): [0 0 1 1 1]\n",
      "y_pred: [0 0 0 1 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [239, 266, 18, 42, 210, 27, 51, 191, 62, 17, 67, 142, 232, 38, 264, 250, 15, 5, 188, 84, 20, 108, 159, 71, 174, 193, 25, 217, 43, 56, 40, 176, 65, 273, 47, 139, 136, 265, 73, 109, 130, 220, 29, 107, 39, 208, 195, 3, 53, 178, 41, 227, 95, 103, 235, 187, 75, 77, 10, 123, 48, 128, 14, 255, 200, 184, 216, 72, 170, 135, 52, 211, 96, 21, 63, 213, 126, 69, 219, 87, 121, 169, 6, 189, 247, 137, 26, 156, 57, 104, 9, 251, 166, 243, 202, 58, 54, 16, 204, 138, 70, 85, 149, 36, 161, 94, 50, 106, 83, 81, 272, 82, 116, 134, 111, 117, 112, 257, 277, 91, 186, 238, 263, 260, 185, 240, 271, 45, 49, 182, 231, 120, 259, 131, 22, 129, 261, 148, 146, 113, 100, 144, 228, 218, 97, 115, 122, 105, 92, 249, 276, 177, 212, 35, 125, 44, 225, 2, 133, 224, 152, 215, 198, 203, 164, 13, 119, 32, 196, 244, 158, 168, 246, 221, 34, 4, 28, 145, 267, 46, 80, 78, 256, 76, 86, 33, 12, 209, 37, 175, 132, 199, 110, 181, 66, 30, 278, 222, 147, 24, 61, 179, 274, 183, 163, 172, 64, 8, 245, 197, 262, 223, 74, 0, 236, 233, 165, 102, 162, 127, 171, 234, 60], 'val_indices': [214, 242, 270, 150, 153, 205, 173, 190, 98, 143, 268, 31, 1, 59, 229, 118, 241, 258, 154, 68, 124, 194, 237, 207, 99, 254, 141, 167, 201, 101, 23, 230, 19, 157, 248, 275, 226, 7, 160, 114, 89, 90, 180, 206, 192, 88, 140, 11, 253, 151, 55, 252, 155, 79, 93, 269], 'accuracy': 0.8571428571428571, 'kappa': 0.7142857142857143, 'auc': 0.9260204081632653}\n",
      "Running fold 4 with 223 training samples and 56 validation samples\n",
      "Fold 4: train indices: [ 34 167 248 121 187], val indices: [215  94 190 240 162]\n",
      "Training data shape: (223, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 4 training loss: 0.0076571013778448105\n",
      "y_true (val): [0 0 0 0 0]\n",
      "y_pred: [0 1 0 0 1]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [34, 167, 248, 121, 187, 21, 237, 111, 262, 132, 186, 158, 151, 38, 157, 264, 19, 160, 136, 192, 18, 1, 85, 142, 183, 226, 42, 50, 115, 45, 25, 6, 84, 258, 257, 278, 107, 86, 46, 211, 138, 93, 103, 57, 139, 33, 276, 252, 59, 40, 243, 71, 134, 150, 228, 149, 105, 214, 199, 182, 154, 198, 207, 235, 26, 13, 203, 177, 109, 232, 98, 147, 112, 169, 3, 30, 213, 164, 67, 68, 236, 100, 64, 80, 69, 95, 206, 230, 23, 188, 48, 66, 39, 209, 102, 17, 7, 275, 219, 227, 8, 194, 41, 5, 81, 253, 12, 31, 91, 144, 56, 146, 14, 254, 77, 116, 9, 101, 73, 145, 196, 229, 43, 220, 4, 24, 141, 2, 32, 241, 119, 245, 114, 61, 216, 97, 195, 259, 131, 15, 205, 51, 106, 0, 179, 148, 218, 89, 63, 99, 11, 163, 78, 53, 104, 267, 172, 92, 269, 224, 261, 270, 52, 65, 225, 233, 231, 277, 123, 82, 184, 251, 152, 263, 250, 36, 126, 28, 242, 54, 159, 175, 10, 44, 49, 181, 266, 113, 27, 143, 185, 137, 20, 118, 274, 22, 110, 122, 273, 193, 58, 88, 87, 120, 255, 16, 191, 217, 200, 96, 208, 178, 223, 180, 265, 108, 246, 161, 55, 125, 249, 234, 127], 'val_indices': [215, 94, 190, 240, 162, 239, 129, 60, 202, 70, 168, 117, 171, 74, 72, 62, 247, 135, 170, 128, 155, 133, 174, 244, 272, 165, 210, 75, 37, 130, 156, 268, 197, 153, 47, 201, 166, 76, 212, 238, 29, 271, 260, 204, 221, 35, 173, 140, 222, 124, 256, 79, 189, 176, 83, 90], 'accuracy': 0.8571428571428571, 'kappa': 0.7142857142857143, 'auc': 0.951530612244898}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.854, 'mean_kappa': 0.707, 'mean_auc': 0.943, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [126, 183, 141, 159, 207, 72, 81, 16, 80, 202, 71, 149, 110, 219, 231, 192, 174, 20, 37, 91, 225, 113, 167, 132, 157, 229, 270, 160, 242, 201, 84, 267, 33, 185, 190, 119, 60, 31, 191, 78, 98, 36, 245, 22, 218, 96, 97, 27, 89, 87, 205, 17, 255, 50, 224, 249, 0, 109, 187, 161, 244, 128, 142, 197, 63, 268, 189, 66, 12, 130, 45, 18, 154, 206, 116, 188, 254, 243, 83, 199, 277, 108, 256, 228, 25, 138, 86, 155, 127, 250, 241, 90, 102, 265, 156, 7, 100, 104, 186, 135, 239, 136, 67, 216, 54, 49, 204, 178, 42, 272, 88, 48, 143, 122, 278, 68, 61, 237, 124, 93, 46, 212, 257, 14, 162, 227, 121, 166, 194, 118, 114, 221, 10, 41, 230, 8, 140, 51, 56, 195, 85, 5, 43, 198, 38, 182, 59, 260, 133, 39, 3, 223, 28, 252, 35, 125, 236, 264, 144, 275, 9, 226, 137, 233, 145, 165, 175, 47, 234, 79, 29, 147, 106, 184, 19, 259, 112, 251, 34, 168, 69, 196, 266, 64, 200, 213, 208, 211, 193, 210, 153, 58, 24, 263, 146, 40, 235, 13, 76, 139, 99, 52, 115, 164, 240, 2, 152, 151, 4, 215, 11, 101, 92, 248, 217, 274, 82, 214, 105, 62, 169, 271, 209], 'val_indices': [75, 15, 26, 253, 111, 163, 180, 179, 170, 150, 57, 53, 65, 148, 23, 44, 220, 171, 269, 238, 30, 6, 21, 70, 103, 261, 203, 134, 262, 94, 172, 173, 158, 1, 181, 74, 55, 247, 273, 32, 276, 177, 129, 131, 77, 246, 95, 123, 232, 258, 107, 73, 176, 117, 222, 120], 'accuracy': 0.8392857142857143, 'kappa': 0.6785714285714286, 'auc': 0.9298469387755102}, {'fold_index': 1, 'train_indices': [197, 174, 81, 179, 32, 209, 47, 204, 97, 117, 10, 252, 205, 243, 31, 127, 11, 155, 273, 271, 26, 166, 115, 130, 36, 274, 17, 122, 34, 91, 232, 181, 270, 213, 45, 260, 240, 224, 0, 53, 134, 57, 186, 167, 157, 165, 160, 227, 264, 137, 99, 151, 69, 40, 78, 65, 105, 265, 59, 222, 140, 118, 35, 9, 87, 152, 190, 219, 237, 276, 233, 136, 16, 210, 253, 193, 51, 147, 121, 231, 173, 164, 255, 196, 154, 229, 228, 28, 133, 77, 89, 90, 64, 148, 199, 220, 37, 54, 63, 76, 107, 278, 44, 150, 144, 14, 102, 100, 41, 60, 146, 12, 218, 52, 119, 141, 201, 22, 249, 101, 170, 247, 7, 142, 15, 171, 214, 68, 248, 131, 216, 103, 203, 169, 139, 13, 33, 269, 42, 21, 126, 72, 43, 143, 262, 212, 191, 55, 46, 108, 5, 275, 94, 71, 207, 128, 48, 58, 202, 159, 267, 80, 153, 112, 161, 6, 56, 215, 168, 189, 30, 106, 261, 1, 20, 125, 67, 256, 18, 74, 254, 226, 272, 84, 113, 194, 241, 245, 79, 132, 111, 156, 93, 242, 211, 238, 277, 3, 176, 172, 109, 25, 192, 75, 221, 129, 19, 2, 49, 120, 162, 138, 223, 24, 175, 184, 180, 88, 236, 239, 123, 124, 177], 'val_indices': [251, 200, 66, 263, 29, 183, 187, 110, 206, 250, 259, 246, 4, 230, 195, 96, 208, 95, 145, 38, 27, 149, 178, 217, 83, 158, 50, 185, 98, 70, 188, 225, 23, 198, 244, 163, 92, 116, 235, 266, 62, 104, 73, 8, 114, 135, 86, 234, 39, 182, 82, 61, 258, 268, 85, 257], 'accuracy': 0.8035714285714286, 'kappa': 0.6071428571428572, 'auc': 0.9234693877551019}, {'fold_index': 2, 'train_indices': [86, 178, 215, 238, 75, 57, 230, 4, 213, 31, 13, 22, 77, 128, 1, 132, 168, 190, 39, 55, 150, 209, 189, 234, 236, 155, 66, 254, 109, 115, 16, 135, 151, 81, 218, 49, 130, 76, 136, 0, 63, 67, 188, 56, 205, 34, 184, 87, 133, 145, 40, 24, 207, 167, 240, 84, 204, 117, 221, 131, 147, 183, 237, 263, 11, 247, 80, 141, 170, 223, 225, 106, 111, 129, 206, 48, 197, 226, 83, 171, 169, 72, 251, 6, 79, 23, 64, 30, 245, 157, 82, 88, 219, 92, 253, 198, 97, 256, 224, 231, 100, 104, 252, 210, 217, 146, 51, 176, 203, 159, 193, 139, 7, 14, 211, 27, 124, 85, 103, 107, 235, 28, 102, 160, 59, 164, 140, 233, 120, 192, 101, 274, 89, 242, 121, 2, 137, 73, 93, 58, 47, 69, 19, 25, 177, 248, 152, 179, 12, 259, 116, 74, 62, 166, 174, 208, 262, 52, 18, 17, 239, 44, 249, 180, 187, 161, 42, 241, 232, 265, 266, 71, 46, 125, 194, 277, 26, 229, 216, 68, 244, 144, 148, 94, 61, 45, 91, 154, 108, 227, 255, 172, 173, 228, 165, 38, 98, 200, 90, 96, 9, 273, 199, 134, 35, 142, 195, 275, 212, 3, 243, 54, 112, 70, 250, 41, 201, 127, 153, 246, 162, 175, 276], 'val_indices': [278, 270, 119, 260, 214, 65, 158, 10, 114, 21, 257, 123, 143, 163, 15, 269, 185, 196, 33, 149, 113, 78, 202, 5, 36, 182, 261, 268, 95, 20, 110, 37, 8, 32, 99, 126, 220, 272, 181, 264, 60, 186, 105, 43, 222, 271, 122, 191, 118, 50, 29, 267, 156, 138, 258, 53], 'accuracy': 0.9107142857142857, 'kappa': 0.8214285714285714, 'auc': 0.9846938775510204}, {'fold_index': 3, 'train_indices': [239, 266, 18, 42, 210, 27, 51, 191, 62, 17, 67, 142, 232, 38, 264, 250, 15, 5, 188, 84, 20, 108, 159, 71, 174, 193, 25, 217, 43, 56, 40, 176, 65, 273, 47, 139, 136, 265, 73, 109, 130, 220, 29, 107, 39, 208, 195, 3, 53, 178, 41, 227, 95, 103, 235, 187, 75, 77, 10, 123, 48, 128, 14, 255, 200, 184, 216, 72, 170, 135, 52, 211, 96, 21, 63, 213, 126, 69, 219, 87, 121, 169, 6, 189, 247, 137, 26, 156, 57, 104, 9, 251, 166, 243, 202, 58, 54, 16, 204, 138, 70, 85, 149, 36, 161, 94, 50, 106, 83, 81, 272, 82, 116, 134, 111, 117, 112, 257, 277, 91, 186, 238, 263, 260, 185, 240, 271, 45, 49, 182, 231, 120, 259, 131, 22, 129, 261, 148, 146, 113, 100, 144, 228, 218, 97, 115, 122, 105, 92, 249, 276, 177, 212, 35, 125, 44, 225, 2, 133, 224, 152, 215, 198, 203, 164, 13, 119, 32, 196, 244, 158, 168, 246, 221, 34, 4, 28, 145, 267, 46, 80, 78, 256, 76, 86, 33, 12, 209, 37, 175, 132, 199, 110, 181, 66, 30, 278, 222, 147, 24, 61, 179, 274, 183, 163, 172, 64, 8, 245, 197, 262, 223, 74, 0, 236, 233, 165, 102, 162, 127, 171, 234, 60], 'val_indices': [214, 242, 270, 150, 153, 205, 173, 190, 98, 143, 268, 31, 1, 59, 229, 118, 241, 258, 154, 68, 124, 194, 237, 207, 99, 254, 141, 167, 201, 101, 23, 230, 19, 157, 248, 275, 226, 7, 160, 114, 89, 90, 180, 206, 192, 88, 140, 11, 253, 151, 55, 252, 155, 79, 93, 269], 'accuracy': 0.8571428571428571, 'kappa': 0.7142857142857143, 'auc': 0.9260204081632653}, {'fold_index': 4, 'train_indices': [34, 167, 248, 121, 187, 21, 237, 111, 262, 132, 186, 158, 151, 38, 157, 264, 19, 160, 136, 192, 18, 1, 85, 142, 183, 226, 42, 50, 115, 45, 25, 6, 84, 258, 257, 278, 107, 86, 46, 211, 138, 93, 103, 57, 139, 33, 276, 252, 59, 40, 243, 71, 134, 150, 228, 149, 105, 214, 199, 182, 154, 198, 207, 235, 26, 13, 203, 177, 109, 232, 98, 147, 112, 169, 3, 30, 213, 164, 67, 68, 236, 100, 64, 80, 69, 95, 206, 230, 23, 188, 48, 66, 39, 209, 102, 17, 7, 275, 219, 227, 8, 194, 41, 5, 81, 253, 12, 31, 91, 144, 56, 146, 14, 254, 77, 116, 9, 101, 73, 145, 196, 229, 43, 220, 4, 24, 141, 2, 32, 241, 119, 245, 114, 61, 216, 97, 195, 259, 131, 15, 205, 51, 106, 0, 179, 148, 218, 89, 63, 99, 11, 163, 78, 53, 104, 267, 172, 92, 269, 224, 261, 270, 52, 65, 225, 233, 231, 277, 123, 82, 184, 251, 152, 263, 250, 36, 126, 28, 242, 54, 159, 175, 10, 44, 49, 181, 266, 113, 27, 143, 185, 137, 20, 118, 274, 22, 110, 122, 273, 193, 58, 88, 87, 120, 255, 16, 191, 217, 200, 96, 208, 178, 223, 180, 265, 108, 246, 161, 55, 125, 249, 234, 127], 'val_indices': [215, 94, 190, 240, 162, 239, 129, 60, 202, 70, 168, 117, 171, 74, 72, 62, 247, 135, 170, 128, 155, 133, 174, 244, 272, 165, 210, 75, 37, 130, 156, 268, 197, 153, 47, 201, 166, 76, 212, 238, 29, 271, 260, 204, 221, 35, 173, 140, 222, 124, 256, 79, 189, 176, 83, 90], 'accuracy': 0.8571428571428571, 'kappa': 0.7142857142857143, 'auc': 0.951530612244898}], 'std_acc': 0.035, 'std_kappa': 0.069, 'std_auc': 0.023}\n",
      "sbj =  2\n",
      "Filtered from 270 trials to 136 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 283 trials to 142 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (278, 22, 448, 1), y_train shape: (278,)\n",
      "Running fold 0 with 222 training samples and 56 validation samples\n",
      "Fold 0: train indices: [167  82  90  80 128], val indices: [239 183 163 157 116]\n",
      "Training data shape: (222, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 0 training loss: 0.05107675865292549\n",
      "y_true (val): [0 0 0 1 0]\n",
      "y_pred: [1 0 1 0 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [167, 82, 90, 80, 128, 228, 58, 141, 61, 14, 107, 211, 119, 238, 252, 172, 25, 8, 67, 83, 271, 115, 92, 213, 12, 161, 255, 273, 222, 262, 126, 195, 63, 234, 182, 98, 78, 5, 13, 65, 203, 22, 102, 7, 188, 229, 249, 208, 158, 99, 266, 134, 29, 108, 198, 4, 248, 207, 9, 177, 18, 199, 53, 227, 109, 202, 258, 194, 59, 113, 124, 140, 36, 133, 130, 152, 265, 39, 186, 155, 56, 32, 153, 46, 62, 0, 185, 219, 270, 145, 221, 95, 28, 223, 237, 269, 190, 17, 44, 191, 74, 160, 156, 105, 20, 114, 60, 11, 214, 264, 87, 162, 89, 209, 79, 54, 136, 43, 230, 37, 233, 88, 235, 274, 38, 259, 143, 147, 49, 42, 112, 231, 111, 243, 137, 51, 35, 154, 148, 91, 206, 150, 131, 40, 250, 70, 34, 197, 200, 3, 135, 73, 85, 276, 216, 122, 71, 189, 86, 192, 253, 23, 50, 240, 193, 224, 1, 168, 120, 30, 104, 93, 210, 196, 139, 173, 64, 204, 146, 166, 226, 72, 225, 247, 212, 103, 48, 100, 94, 174, 277, 117, 263, 236, 151, 142, 16, 232, 241, 215, 10, 181, 217, 184, 52, 68, 246, 256, 187, 254, 169, 81, 205, 164, 242, 41, 2, 19, 84, 101, 69, 26], 'val_indices': [239, 183, 163, 157, 116, 220, 47, 275, 123, 24, 170, 179, 6, 171, 127, 272, 129, 31, 96, 257, 149, 178, 121, 165, 45, 268, 77, 118, 180, 55, 21, 244, 76, 159, 201, 132, 144, 110, 245, 66, 106, 261, 251, 97, 57, 267, 125, 15, 75, 175, 260, 176, 218, 27, 138, 33], 'accuracy': 0.6071428571428571, 'kappa': 0.2142857142857143, 'auc': 0.6352040816326531}\n",
      "New Max Found!\n",
      "Running fold 1 with 222 training samples and 56 validation samples\n",
      "Fold 1: train indices: [263  12 238  48 136], val indices: [249 198  67 256 209]\n",
      "Training data shape: (222, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 1 training loss: 0.07252446562051773\n",
      "y_true (val): [1 1 1 0 0]\n",
      "y_pred: [1 0 0 0 0]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [263, 12, 238, 48, 136, 6, 168, 58, 156, 3, 152, 219, 41, 254, 222, 23, 226, 149, 272, 84, 233, 194, 115, 37, 87, 96, 16, 36, 129, 128, 144, 195, 269, 27, 171, 102, 205, 200, 108, 234, 252, 47, 185, 150, 9, 79, 11, 5, 250, 137, 277, 65, 162, 55, 66, 203, 202, 60, 91, 161, 206, 227, 190, 141, 132, 243, 126, 54, 160, 139, 201, 140, 197, 120, 143, 31, 224, 240, 274, 159, 35, 69, 112, 199, 25, 142, 178, 26, 127, 90, 7, 170, 135, 248, 89, 208, 17, 215, 151, 180, 45, 19, 237, 14, 212, 153, 273, 276, 147, 114, 57, 264, 74, 71, 70, 22, 271, 125, 165, 268, 217, 121, 15, 53, 34, 1, 173, 187, 21, 104, 0, 246, 183, 76, 18, 33, 13, 172, 218, 78, 210, 88, 29, 146, 214, 124, 164, 122, 110, 80, 134, 56, 232, 49, 225, 255, 42, 247, 158, 64, 131, 43, 107, 95, 207, 61, 2, 99, 81, 119, 105, 32, 241, 20, 10, 220, 138, 221, 123, 245, 154, 59, 266, 251, 191, 51, 175, 213, 130, 111, 106, 167, 116, 211, 193, 275, 265, 68, 176, 270, 261, 169, 216, 46, 38, 155, 77, 118, 239, 231, 50, 229, 166, 44, 103, 179, 93, 259, 73, 101, 192, 174], 'val_indices': [249, 198, 67, 256, 209, 184, 189, 109, 204, 253, 260, 244, 72, 228, 182, 236, 188, 97, 145, 39, 28, 148, 177, 230, 83, 157, 163, 117, 100, 186, 75, 223, 24, 196, 242, 8, 94, 235, 52, 30, 63, 92, 4, 262, 113, 133, 86, 98, 40, 181, 82, 62, 257, 267, 85, 258], 'accuracy': 0.6071428571428571, 'kappa': 0.2142857142857143, 'auc': 0.6275510204081632}\n",
      "Running fold 2 with 222 training samples and 56 validation samples\n",
      "Fold 2: train indices: [150 134 235 198   1], val indices: [277 268 143 215 120]\n",
      "Training data shape: (222, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 2 training loss: 0.05150299146771431\n",
      "y_true (val): [1 1 0 0 0]\n",
      "y_pred: [0 1 1 0 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [150, 134, 235, 198, 1, 86, 42, 4, 53, 51, 3, 110, 79, 46, 121, 203, 11, 214, 85, 273, 36, 115, 107, 68, 236, 41, 67, 141, 174, 71, 22, 16, 172, 217, 252, 2, 178, 0, 255, 241, 35, 205, 49, 108, 164, 244, 184, 87, 229, 39, 130, 239, 75, 233, 261, 84, 228, 207, 219, 12, 116, 149, 264, 95, 160, 94, 171, 173, 131, 56, 152, 266, 193, 73, 31, 14, 225, 201, 237, 102, 246, 65, 23, 159, 24, 19, 32, 13, 161, 82, 62, 154, 208, 40, 127, 213, 7, 69, 90, 232, 202, 251, 100, 74, 210, 142, 175, 272, 47, 77, 170, 118, 114, 81, 136, 169, 105, 185, 106, 122, 209, 199, 27, 247, 190, 117, 256, 125, 188, 76, 269, 224, 54, 103, 78, 226, 25, 211, 59, 48, 260, 126, 50, 156, 132, 135, 275, 242, 216, 168, 240, 227, 166, 92, 189, 99, 230, 18, 17, 140, 45, 60, 182, 139, 212, 43, 257, 98, 183, 265, 165, 144, 238, 6, 83, 234, 158, 58, 167, 243, 29, 96, 147, 179, 206, 91, 153, 196, 222, 254, 221, 204, 63, 231, 223, 72, 151, 176, 162, 9, 276, 197, 89, 88, 146, 195, 133, 28, 57, 64, 145, 111, 191, 249, 129, 177, 128, 250, 245, 26, 70, 248], 'val_indices': [277, 268, 143, 215, 120, 66, 157, 192, 113, 253, 123, 5, 55, 10, 15, 274, 186, 194, 34, 148, 112, 97, 200, 30, 37, 181, 262, 267, 101, 20, 109, 38, 8, 33, 163, 137, 218, 271, 180, 138, 61, 119, 93, 44, 220, 270, 263, 124, 80, 52, 104, 21, 155, 259, 258, 187], 'accuracy': 0.625, 'kappa': 0.25, 'auc': 0.659438775510204}\n",
      "New Max Found!\n",
      "Running fold 3 with 222 training samples and 56 validation samples\n",
      "Fold 3: train indices: [ 78 139 273 271  82], val indices: [ 88 156 143 224   1]\n",
      "Training data shape: (222, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 3 training loss: 0.05523529648780823\n",
      "y_true (val): [1 1 0 1 0]\n",
      "y_pred: [1 1 0 0 0]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [78, 139, 273, 271, 82, 137, 136, 265, 127, 91, 86, 124, 202, 209, 196, 201, 269, 157, 142, 120, 155, 210, 45, 112, 213, 192, 165, 132, 96, 48, 234, 267, 131, 47, 223, 27, 176, 238, 16, 245, 77, 216, 46, 0, 110, 163, 235, 118, 197, 53, 55, 121, 275, 61, 151, 62, 263, 233, 240, 122, 108, 274, 239, 34, 123, 116, 212, 74, 18, 226, 71, 219, 12, 130, 195, 54, 256, 244, 30, 277, 64, 162, 92, 205, 264, 105, 225, 128, 200, 148, 253, 129, 40, 232, 146, 134, 260, 114, 166, 51, 21, 126, 107, 39, 10, 17, 230, 29, 42, 50, 229, 79, 104, 97, 144, 189, 90, 23, 170, 113, 147, 69, 9, 6, 76, 237, 243, 206, 257, 33, 63, 115, 14, 204, 8, 211, 231, 26, 66, 52, 159, 222, 75, 198, 255, 65, 135, 276, 83, 2, 20, 38, 184, 85, 181, 180, 261, 221, 68, 31, 171, 37, 185, 43, 22, 242, 73, 70, 44, 190, 72, 169, 250, 186, 220, 49, 35, 94, 174, 262, 158, 102, 249, 59, 109, 272, 173, 188, 270, 258, 217, 177, 93, 175, 183, 99, 133, 138, 111, 268, 145, 266, 194, 98, 164, 25, 28, 187, 161, 36, 214, 117, 106, 4, 87, 168, 3, 41, 80, 56, 5, 67], 'val_indices': [88, 156, 143, 224, 1, 259, 178, 252, 141, 100, 119, 149, 251, 191, 58, 179, 19, 207, 236, 208, 101, 254, 103, 24, 182, 13, 199, 247, 32, 246, 7, 227, 89, 150, 248, 153, 193, 154, 140, 11, 15, 152, 81, 95, 172, 160, 218, 60, 167, 203, 125, 84, 215, 57, 228, 241], 'accuracy': 0.44642857142857145, 'kappa': -0.1071428571428572, 'auc': 0.4974489795918367}\n",
      "Running fold 4 with 222 training samples and 56 validation samples\n",
      "Fold 4: train indices: [  4 178 192  23 149], val indices: [128 101 118 265  30]\n",
      "Training data shape: (222, 22, 448, 1), Validation data shape: (56, 22, 448, 1)\n",
      "Fold 4 training loss: 0.05361850559711456\n",
      "y_true (val): [1 0 0 0 0]\n",
      "y_pred: [0 1 1 1 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [4, 178, 192, 23, 149, 246, 22, 106, 119, 111, 64, 58, 9, 120, 25, 252, 236, 165, 210, 209, 137, 13, 103, 228, 274, 239, 150, 19, 131, 197, 185, 16, 109, 93, 82, 264, 198, 94, 124, 63, 108, 28, 2, 43, 201, 99, 26, 218, 176, 69, 156, 102, 85, 80, 0, 100, 56, 276, 223, 186, 187, 244, 146, 112, 243, 259, 50, 32, 249, 11, 35, 31, 8, 212, 59, 155, 189, 196, 7, 214, 231, 62, 12, 60, 206, 151, 24, 272, 47, 132, 145, 179, 238, 96, 115, 97, 144, 222, 262, 113, 177, 79, 261, 3, 117, 88, 160, 174, 204, 84, 18, 66, 141, 254, 5, 163, 182, 138, 245, 71, 225, 255, 53, 37, 235, 68, 258, 224, 77, 98, 129, 75, 127, 14, 83, 122, 275, 256, 273, 188, 57, 180, 91, 240, 73, 263, 260, 104, 44, 17, 15, 161, 229, 253, 147, 194, 167, 42, 171, 116, 48, 205, 6, 153, 33, 87, 21, 232, 158, 46, 54, 208, 10, 139, 92, 130, 193, 110, 123, 227, 142, 20, 135, 1, 237, 40, 148, 184, 181, 107, 277, 241, 67, 169, 70, 134, 221, 29, 164, 173, 136, 159, 267, 143, 52, 250, 242, 65, 215, 268, 45, 217, 51, 27, 203, 55, 89, 220, 207, 41, 270, 34], 'val_indices': [128, 101, 118, 265, 30, 90, 166, 140, 269, 251, 190, 213, 233, 257, 72, 168, 191, 38, 39, 125, 200, 271, 61, 248, 76, 121, 172, 219, 175, 81, 105, 126, 266, 183, 199, 162, 49, 152, 114, 95, 195, 247, 36, 211, 226, 202, 170, 86, 230, 216, 74, 154, 133, 78, 157, 234], 'accuracy': 0.6071428571428571, 'kappa': 0.2142857142857143, 'auc': 0.6301020408163265}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.579, 'mean_kappa': 0.157, 'mean_auc': 0.61, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [167, 82, 90, 80, 128, 228, 58, 141, 61, 14, 107, 211, 119, 238, 252, 172, 25, 8, 67, 83, 271, 115, 92, 213, 12, 161, 255, 273, 222, 262, 126, 195, 63, 234, 182, 98, 78, 5, 13, 65, 203, 22, 102, 7, 188, 229, 249, 208, 158, 99, 266, 134, 29, 108, 198, 4, 248, 207, 9, 177, 18, 199, 53, 227, 109, 202, 258, 194, 59, 113, 124, 140, 36, 133, 130, 152, 265, 39, 186, 155, 56, 32, 153, 46, 62, 0, 185, 219, 270, 145, 221, 95, 28, 223, 237, 269, 190, 17, 44, 191, 74, 160, 156, 105, 20, 114, 60, 11, 214, 264, 87, 162, 89, 209, 79, 54, 136, 43, 230, 37, 233, 88, 235, 274, 38, 259, 143, 147, 49, 42, 112, 231, 111, 243, 137, 51, 35, 154, 148, 91, 206, 150, 131, 40, 250, 70, 34, 197, 200, 3, 135, 73, 85, 276, 216, 122, 71, 189, 86, 192, 253, 23, 50, 240, 193, 224, 1, 168, 120, 30, 104, 93, 210, 196, 139, 173, 64, 204, 146, 166, 226, 72, 225, 247, 212, 103, 48, 100, 94, 174, 277, 117, 263, 236, 151, 142, 16, 232, 241, 215, 10, 181, 217, 184, 52, 68, 246, 256, 187, 254, 169, 81, 205, 164, 242, 41, 2, 19, 84, 101, 69, 26], 'val_indices': [239, 183, 163, 157, 116, 220, 47, 275, 123, 24, 170, 179, 6, 171, 127, 272, 129, 31, 96, 257, 149, 178, 121, 165, 45, 268, 77, 118, 180, 55, 21, 244, 76, 159, 201, 132, 144, 110, 245, 66, 106, 261, 251, 97, 57, 267, 125, 15, 75, 175, 260, 176, 218, 27, 138, 33], 'accuracy': 0.6071428571428571, 'kappa': 0.2142857142857143, 'auc': 0.6352040816326531}, {'fold_index': 1, 'train_indices': [263, 12, 238, 48, 136, 6, 168, 58, 156, 3, 152, 219, 41, 254, 222, 23, 226, 149, 272, 84, 233, 194, 115, 37, 87, 96, 16, 36, 129, 128, 144, 195, 269, 27, 171, 102, 205, 200, 108, 234, 252, 47, 185, 150, 9, 79, 11, 5, 250, 137, 277, 65, 162, 55, 66, 203, 202, 60, 91, 161, 206, 227, 190, 141, 132, 243, 126, 54, 160, 139, 201, 140, 197, 120, 143, 31, 224, 240, 274, 159, 35, 69, 112, 199, 25, 142, 178, 26, 127, 90, 7, 170, 135, 248, 89, 208, 17, 215, 151, 180, 45, 19, 237, 14, 212, 153, 273, 276, 147, 114, 57, 264, 74, 71, 70, 22, 271, 125, 165, 268, 217, 121, 15, 53, 34, 1, 173, 187, 21, 104, 0, 246, 183, 76, 18, 33, 13, 172, 218, 78, 210, 88, 29, 146, 214, 124, 164, 122, 110, 80, 134, 56, 232, 49, 225, 255, 42, 247, 158, 64, 131, 43, 107, 95, 207, 61, 2, 99, 81, 119, 105, 32, 241, 20, 10, 220, 138, 221, 123, 245, 154, 59, 266, 251, 191, 51, 175, 213, 130, 111, 106, 167, 116, 211, 193, 275, 265, 68, 176, 270, 261, 169, 216, 46, 38, 155, 77, 118, 239, 231, 50, 229, 166, 44, 103, 179, 93, 259, 73, 101, 192, 174], 'val_indices': [249, 198, 67, 256, 209, 184, 189, 109, 204, 253, 260, 244, 72, 228, 182, 236, 188, 97, 145, 39, 28, 148, 177, 230, 83, 157, 163, 117, 100, 186, 75, 223, 24, 196, 242, 8, 94, 235, 52, 30, 63, 92, 4, 262, 113, 133, 86, 98, 40, 181, 82, 62, 257, 267, 85, 258], 'accuracy': 0.6071428571428571, 'kappa': 0.2142857142857143, 'auc': 0.6275510204081632}, {'fold_index': 2, 'train_indices': [150, 134, 235, 198, 1, 86, 42, 4, 53, 51, 3, 110, 79, 46, 121, 203, 11, 214, 85, 273, 36, 115, 107, 68, 236, 41, 67, 141, 174, 71, 22, 16, 172, 217, 252, 2, 178, 0, 255, 241, 35, 205, 49, 108, 164, 244, 184, 87, 229, 39, 130, 239, 75, 233, 261, 84, 228, 207, 219, 12, 116, 149, 264, 95, 160, 94, 171, 173, 131, 56, 152, 266, 193, 73, 31, 14, 225, 201, 237, 102, 246, 65, 23, 159, 24, 19, 32, 13, 161, 82, 62, 154, 208, 40, 127, 213, 7, 69, 90, 232, 202, 251, 100, 74, 210, 142, 175, 272, 47, 77, 170, 118, 114, 81, 136, 169, 105, 185, 106, 122, 209, 199, 27, 247, 190, 117, 256, 125, 188, 76, 269, 224, 54, 103, 78, 226, 25, 211, 59, 48, 260, 126, 50, 156, 132, 135, 275, 242, 216, 168, 240, 227, 166, 92, 189, 99, 230, 18, 17, 140, 45, 60, 182, 139, 212, 43, 257, 98, 183, 265, 165, 144, 238, 6, 83, 234, 158, 58, 167, 243, 29, 96, 147, 179, 206, 91, 153, 196, 222, 254, 221, 204, 63, 231, 223, 72, 151, 176, 162, 9, 276, 197, 89, 88, 146, 195, 133, 28, 57, 64, 145, 111, 191, 249, 129, 177, 128, 250, 245, 26, 70, 248], 'val_indices': [277, 268, 143, 215, 120, 66, 157, 192, 113, 253, 123, 5, 55, 10, 15, 274, 186, 194, 34, 148, 112, 97, 200, 30, 37, 181, 262, 267, 101, 20, 109, 38, 8, 33, 163, 137, 218, 271, 180, 138, 61, 119, 93, 44, 220, 270, 263, 124, 80, 52, 104, 21, 155, 259, 258, 187], 'accuracy': 0.625, 'kappa': 0.25, 'auc': 0.659438775510204}, {'fold_index': 3, 'train_indices': [78, 139, 273, 271, 82, 137, 136, 265, 127, 91, 86, 124, 202, 209, 196, 201, 269, 157, 142, 120, 155, 210, 45, 112, 213, 192, 165, 132, 96, 48, 234, 267, 131, 47, 223, 27, 176, 238, 16, 245, 77, 216, 46, 0, 110, 163, 235, 118, 197, 53, 55, 121, 275, 61, 151, 62, 263, 233, 240, 122, 108, 274, 239, 34, 123, 116, 212, 74, 18, 226, 71, 219, 12, 130, 195, 54, 256, 244, 30, 277, 64, 162, 92, 205, 264, 105, 225, 128, 200, 148, 253, 129, 40, 232, 146, 134, 260, 114, 166, 51, 21, 126, 107, 39, 10, 17, 230, 29, 42, 50, 229, 79, 104, 97, 144, 189, 90, 23, 170, 113, 147, 69, 9, 6, 76, 237, 243, 206, 257, 33, 63, 115, 14, 204, 8, 211, 231, 26, 66, 52, 159, 222, 75, 198, 255, 65, 135, 276, 83, 2, 20, 38, 184, 85, 181, 180, 261, 221, 68, 31, 171, 37, 185, 43, 22, 242, 73, 70, 44, 190, 72, 169, 250, 186, 220, 49, 35, 94, 174, 262, 158, 102, 249, 59, 109, 272, 173, 188, 270, 258, 217, 177, 93, 175, 183, 99, 133, 138, 111, 268, 145, 266, 194, 98, 164, 25, 28, 187, 161, 36, 214, 117, 106, 4, 87, 168, 3, 41, 80, 56, 5, 67], 'val_indices': [88, 156, 143, 224, 1, 259, 178, 252, 141, 100, 119, 149, 251, 191, 58, 179, 19, 207, 236, 208, 101, 254, 103, 24, 182, 13, 199, 247, 32, 246, 7, 227, 89, 150, 248, 153, 193, 154, 140, 11, 15, 152, 81, 95, 172, 160, 218, 60, 167, 203, 125, 84, 215, 57, 228, 241], 'accuracy': 0.44642857142857145, 'kappa': -0.1071428571428572, 'auc': 0.4974489795918367}, {'fold_index': 4, 'train_indices': [4, 178, 192, 23, 149, 246, 22, 106, 119, 111, 64, 58, 9, 120, 25, 252, 236, 165, 210, 209, 137, 13, 103, 228, 274, 239, 150, 19, 131, 197, 185, 16, 109, 93, 82, 264, 198, 94, 124, 63, 108, 28, 2, 43, 201, 99, 26, 218, 176, 69, 156, 102, 85, 80, 0, 100, 56, 276, 223, 186, 187, 244, 146, 112, 243, 259, 50, 32, 249, 11, 35, 31, 8, 212, 59, 155, 189, 196, 7, 214, 231, 62, 12, 60, 206, 151, 24, 272, 47, 132, 145, 179, 238, 96, 115, 97, 144, 222, 262, 113, 177, 79, 261, 3, 117, 88, 160, 174, 204, 84, 18, 66, 141, 254, 5, 163, 182, 138, 245, 71, 225, 255, 53, 37, 235, 68, 258, 224, 77, 98, 129, 75, 127, 14, 83, 122, 275, 256, 273, 188, 57, 180, 91, 240, 73, 263, 260, 104, 44, 17, 15, 161, 229, 253, 147, 194, 167, 42, 171, 116, 48, 205, 6, 153, 33, 87, 21, 232, 158, 46, 54, 208, 10, 139, 92, 130, 193, 110, 123, 227, 142, 20, 135, 1, 237, 40, 148, 184, 181, 107, 277, 241, 67, 169, 70, 134, 221, 29, 164, 173, 136, 159, 267, 143, 52, 250, 242, 65, 215, 268, 45, 217, 51, 27, 203, 55, 89, 220, 207, 41, 270, 34], 'val_indices': [128, 101, 118, 265, 30, 90, 166, 140, 269, 251, 190, 213, 233, 257, 72, 168, 191, 38, 39, 125, 200, 271, 61, 248, 76, 121, 172, 219, 175, 81, 105, 126, 266, 183, 199, 162, 49, 152, 114, 95, 195, 247, 36, 211, 226, 202, 170, 86, 230, 216, 74, 154, 133, 78, 157, 234], 'accuracy': 0.6071428571428571, 'kappa': 0.2142857142857143, 'auc': 0.6301020408163265}], 'std_acc': 0.066, 'std_kappa': 0.133, 'std_auc': 0.057}\n",
      "sbj =  3\n",
      "Filtered from 270 trials to 137 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 273 trials to 137 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (274, 22, 448, 1), y_train shape: (274,)\n",
      "Running fold 0 with 219 training samples and 55 validation samples\n",
      "Fold 0: train indices: [126  78  29 142 192], val indices: [ 44 164 205 248 238]\n",
      "Training data shape: (219, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 0 training loss: 0.004812692292034626\n",
      "y_true (val): [1 0 1 1 0]\n",
      "y_pred: [1 0 1 1 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [126, 78, 29, 142, 192, 249, 229, 139, 128, 266, 234, 86, 38, 240, 107, 225, 271, 56, 127, 227, 170, 159, 263, 258, 21, 12, 100, 204, 79, 8, 250, 230, 155, 94, 63, 5, 237, 36, 207, 98, 7, 173, 209, 146, 95, 140, 247, 61, 108, 4, 80, 210, 9, 105, 81, 200, 256, 177, 11, 194, 243, 51, 251, 101, 203, 235, 17, 102, 42, 77, 76, 267, 272, 132, 198, 15, 83, 184, 104, 221, 32, 154, 67, 62, 25, 183, 218, 130, 144, 13, 91, 28, 57, 0, 114, 187, 16, 68, 188, 34, 167, 19, 135, 85, 87, 23, 121, 261, 273, 160, 88, 193, 70, 52, 123, 220, 214, 153, 26, 223, 231, 157, 270, 233, 47, 260, 262, 241, 125, 112, 215, 41, 226, 124, 49, 45, 103, 149, 195, 161, 43, 197, 39, 181, 60, 116, 199, 201, 3, 224, 71, 18, 196, 212, 119, 239, 186, 35, 189, 148, 48, 236, 190, 174, 27, 166, 117, 30, 69, 156, 206, 133, 138, 111, 216, 22, 145, 1, 64, 37, 65, 136, 208, 99, 46, 96, 90, 222, 109, 165, 72, 232, 40, 141, 59, 228, 54, 211, 10, 242, 213, 259, 50, 246, 151, 252, 185, 255, 168, 254, 191, 245, 152, 2, 84, 269, 97, 82, 163], 'val_indices': [44, 164, 205, 248, 238, 264, 172, 20, 169, 110, 175, 171, 268, 178, 257, 219, 118, 253, 137, 131, 73, 147, 122, 53, 58, 33, 31, 265, 74, 150, 162, 6, 92, 66, 134, 93, 176, 244, 202, 106, 55, 129, 217, 113, 158, 24, 14, 182, 75, 179, 180, 115, 143, 120, 89], 'accuracy': 0.9454545454545454, 'kappa': 0.8906560636182903, 'auc': 0.9986772486772487}\n",
      "New Max Found!\n",
      "Running fold 1 with 219 training samples and 55 validation samples\n",
      "Fold 1: train indices: [156 102 203  79 146], val indices: [109 217 222 263 194]\n",
      "Training data shape: (219, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 1 training loss: 0.004250503610819578\n",
      "y_true (val): [1 1 1 1 1]\n",
      "y_pred: [1 1 1 1 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [156, 102, 203, 79, 146, 40, 83, 155, 232, 14, 88, 150, 216, 200, 220, 167, 178, 246, 113, 126, 121, 184, 71, 51, 27, 244, 213, 230, 53, 59, 15, 120, 58, 118, 176, 49, 89, 47, 271, 248, 111, 92, 252, 5, 265, 151, 87, 36, 173, 37, 115, 104, 29, 198, 181, 31, 231, 153, 22, 65, 6, 251, 188, 52, 175, 138, 134, 4, 133, 166, 55, 77, 157, 46, 267, 1, 254, 268, 64, 221, 25, 190, 141, 44, 245, 182, 10, 86, 225, 129, 204, 30, 269, 127, 152, 68, 147, 130, 142, 76, 218, 57, 26, 131, 38, 211, 237, 139, 125, 61, 196, 160, 159, 264, 165, 186, 110, 119, 72, 208, 174, 117, 219, 206, 100, 195, 11, 122, 97, 148, 123, 226, 106, 42, 199, 193, 43, 45, 145, 261, 98, 209, 163, 18, 23, 74, 32, 75, 242, 33, 21, 247, 170, 201, 35, 154, 54, 164, 17, 257, 69, 207, 255, 105, 140, 191, 60, 0, 41, 161, 273, 238, 223, 112, 128, 224, 171, 91, 116, 169, 132, 180, 108, 189, 168, 214, 56, 13, 78, 19, 12, 270, 215, 192, 34, 16, 82, 136, 258, 228, 48, 262, 143, 20, 124, 107, 212, 179, 73, 260, 187, 259, 240, 249, 235, 101, 250, 7, 3], 'val_indices': [109, 217, 222, 263, 194, 241, 137, 81, 84, 39, 9, 94, 183, 103, 210, 135, 266, 239, 253, 162, 114, 50, 272, 233, 236, 99, 227, 24, 63, 96, 229, 80, 185, 205, 158, 8, 93, 85, 66, 90, 177, 243, 172, 202, 28, 70, 67, 256, 62, 149, 144, 197, 95, 2, 234], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}\n",
      "New Max Found!\n",
      "Running fold 2 with 219 training samples and 55 validation samples\n",
      "Fold 2: train indices: [207 271 268 250 204], val indices: [102 116   3 148 227]\n",
      "Training data shape: (219, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 2 training loss: 0.0047071282751858234\n",
      "y_true (val): [1 0 0 1 1]\n",
      "y_pred: [1 0 0 1 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [207, 271, 268, 250, 204, 195, 40, 245, 221, 184, 22, 90, 246, 59, 65, 91, 70, 17, 54, 67, 215, 217, 41, 260, 78, 100, 197, 93, 75, 31, 235, 74, 169, 182, 119, 145, 146, 21, 200, 194, 110, 26, 63, 164, 73, 156, 254, 255, 212, 209, 155, 247, 264, 55, 143, 88, 267, 138, 205, 94, 134, 105, 98, 157, 183, 52, 179, 72, 242, 106, 77, 28, 270, 47, 20, 19, 66, 239, 152, 87, 136, 253, 6, 115, 216, 131, 58, 125, 144, 162, 1, 51, 180, 24, 122, 211, 266, 96, 154, 160, 269, 153, 39, 229, 261, 7, 226, 46, 81, 244, 228, 32, 175, 139, 82, 37, 231, 140, 225, 163, 107, 251, 218, 127, 203, 189, 190, 92, 9, 61, 114, 187, 16, 36, 132, 103, 133, 237, 191, 240, 0, 49, 45, 159, 30, 241, 232, 192, 220, 230, 57, 99, 29, 135, 147, 56, 262, 86, 168, 149, 80, 60, 79, 272, 15, 130, 176, 5, 123, 12, 165, 48, 170, 249, 202, 223, 129, 10, 188, 71, 213, 111, 150, 42, 85, 76, 62, 38, 177, 151, 199, 252, 95, 259, 265, 121, 208, 233, 44, 27, 206, 219, 4, 257, 172, 11, 141, 101, 263, 174, 25, 14, 236, 171, 69, 166, 161, 23, 126], 'val_indices': [102, 116, 3, 148, 227, 35, 222, 224, 113, 108, 196, 118, 18, 68, 193, 109, 234, 89, 186, 214, 43, 167, 83, 2, 120, 117, 97, 210, 256, 198, 112, 173, 181, 158, 273, 201, 34, 238, 258, 53, 128, 64, 124, 104, 13, 142, 50, 243, 33, 137, 185, 178, 8, 84, 248], 'accuracy': 0.9818181818181818, 'kappa': 0.9636002647253474, 'auc': 1.0}\n",
      "Running fold 3 with 219 training samples and 55 validation samples\n",
      "Fold 3: train indices: [241 209 219 263  47], val indices: [207  14 238 240 163]\n",
      "Training data shape: (219, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 3 training loss: 0.00614555599167943\n",
      "y_true (val): [0 1 0 1 0]\n",
      "y_pred: [0 1 0 0 0]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [241, 209, 219, 263, 47, 227, 56, 44, 53, 185, 187, 142, 143, 18, 5, 269, 177, 136, 72, 31, 248, 193, 137, 25, 128, 145, 204, 166, 77, 27, 213, 114, 179, 100, 26, 6, 256, 199, 194, 78, 147, 221, 16, 108, 215, 22, 188, 80, 42, 39, 233, 173, 75, 129, 214, 266, 271, 90, 175, 126, 195, 10, 203, 228, 35, 181, 0, 67, 144, 111, 84, 95, 9, 112, 46, 21, 33, 150, 125, 191, 8, 237, 210, 261, 94, 43, 224, 58, 186, 15, 49, 260, 122, 235, 170, 165, 4, 54, 91, 178, 201, 124, 107, 99, 89, 3, 160, 156, 218, 103, 98, 12, 123, 157, 268, 152, 167, 82, 231, 30, 141, 88, 246, 184, 154, 20, 258, 265, 196, 28, 40, 60, 73, 102, 245, 259, 153, 50, 55, 146, 34, 65, 52, 149, 242, 96, 140, 70, 29, 155, 200, 119, 222, 133, 115, 131, 41, 257, 225, 106, 189, 216, 7, 270, 180, 255, 32, 24, 232, 229, 120, 68, 162, 161, 217, 206, 110, 23, 2, 38, 121, 13, 249, 63, 59, 135, 139, 198, 109, 117, 244, 158, 11, 230, 134, 253, 62, 116, 273, 66, 101, 105, 151, 51, 251, 171, 172, 85, 223, 190, 159, 71, 197, 208, 192, 272, 226, 83, 239], 'val_indices': [207, 14, 238, 240, 163, 48, 37, 113, 236, 138, 61, 19, 57, 243, 169, 1, 36, 92, 81, 234, 97, 69, 205, 79, 211, 76, 182, 74, 174, 132, 127, 252, 264, 17, 254, 118, 148, 87, 130, 104, 267, 176, 86, 212, 45, 262, 220, 183, 202, 164, 250, 247, 64, 168, 93], 'accuracy': 0.9818181818181818, 'kappa': 0.9636483807005949, 'auc': 1.0}\n",
      "Running fold 4 with 219 training samples and 55 validation samples\n",
      "Fold 4: train indices: [264 148 181 152 137], val indices: [252 163  74  50 168]\n",
      "Training data shape: (219, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 4 training loss: 0.006427008658647537\n",
      "y_true (val): [0 0 0 0 0]\n",
      "y_pred: [0 0 0 0 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [264, 148, 181, 152, 137, 106, 219, 183, 98, 1, 76, 18, 263, 235, 90, 81, 147, 180, 259, 176, 99, 121, 114, 116, 146, 8, 268, 120, 125, 196, 267, 86, 135, 124, 95, 233, 33, 211, 84, 122, 243, 237, 133, 48, 221, 64, 22, 246, 240, 208, 4, 239, 105, 63, 2, 10, 71, 45, 182, 234, 145, 100, 139, 112, 140, 115, 197, 177, 56, 53, 210, 109, 232, 35, 220, 36, 21, 174, 144, 228, 179, 24, 143, 199, 227, 155, 198, 0, 249, 93, 94, 169, 131, 134, 107, 82, 11, 69, 204, 195, 73, 213, 200, 236, 119, 224, 226, 247, 27, 43, 44, 87, 251, 58, 161, 272, 171, 258, 7, 72, 231, 108, 212, 203, 253, 110, 54, 77, 149, 28, 66, 91, 60, 184, 78, 38, 142, 31, 29, 158, 193, 89, 123, 96, 194, 162, 173, 160, 40, 153, 216, 151, 189, 215, 83, 57, 256, 47, 49, 130, 16, 244, 97, 192, 269, 156, 70, 164, 159, 101, 241, 67, 9, 92, 166, 118, 255, 68, 136, 214, 273, 3, 17, 157, 242, 170, 206, 65, 75, 141, 138, 222, 202, 175, 132, 42, 218, 154, 205, 217, 20, 23, 52, 117, 266, 257, 250, 5, 191, 13, 178, 25, 238, 128, 111, 103, 223, 51, 261], 'val_indices': [252, 163, 74, 50, 168, 127, 30, 201, 61, 126, 19, 37, 150, 271, 270, 79, 14, 80, 230, 6, 41, 262, 188, 129, 15, 254, 85, 62, 113, 167, 229, 39, 88, 34, 265, 245, 185, 187, 260, 190, 55, 165, 225, 59, 12, 26, 186, 102, 207, 172, 209, 104, 32, 46, 248], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.982, 'mean_kappa': 0.964, 'mean_auc': 1.0, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [126, 78, 29, 142, 192, 249, 229, 139, 128, 266, 234, 86, 38, 240, 107, 225, 271, 56, 127, 227, 170, 159, 263, 258, 21, 12, 100, 204, 79, 8, 250, 230, 155, 94, 63, 5, 237, 36, 207, 98, 7, 173, 209, 146, 95, 140, 247, 61, 108, 4, 80, 210, 9, 105, 81, 200, 256, 177, 11, 194, 243, 51, 251, 101, 203, 235, 17, 102, 42, 77, 76, 267, 272, 132, 198, 15, 83, 184, 104, 221, 32, 154, 67, 62, 25, 183, 218, 130, 144, 13, 91, 28, 57, 0, 114, 187, 16, 68, 188, 34, 167, 19, 135, 85, 87, 23, 121, 261, 273, 160, 88, 193, 70, 52, 123, 220, 214, 153, 26, 223, 231, 157, 270, 233, 47, 260, 262, 241, 125, 112, 215, 41, 226, 124, 49, 45, 103, 149, 195, 161, 43, 197, 39, 181, 60, 116, 199, 201, 3, 224, 71, 18, 196, 212, 119, 239, 186, 35, 189, 148, 48, 236, 190, 174, 27, 166, 117, 30, 69, 156, 206, 133, 138, 111, 216, 22, 145, 1, 64, 37, 65, 136, 208, 99, 46, 96, 90, 222, 109, 165, 72, 232, 40, 141, 59, 228, 54, 211, 10, 242, 213, 259, 50, 246, 151, 252, 185, 255, 168, 254, 191, 245, 152, 2, 84, 269, 97, 82, 163], 'val_indices': [44, 164, 205, 248, 238, 264, 172, 20, 169, 110, 175, 171, 268, 178, 257, 219, 118, 253, 137, 131, 73, 147, 122, 53, 58, 33, 31, 265, 74, 150, 162, 6, 92, 66, 134, 93, 176, 244, 202, 106, 55, 129, 217, 113, 158, 24, 14, 182, 75, 179, 180, 115, 143, 120, 89], 'accuracy': 0.9454545454545454, 'kappa': 0.8906560636182903, 'auc': 0.9986772486772487}, {'fold_index': 1, 'train_indices': [156, 102, 203, 79, 146, 40, 83, 155, 232, 14, 88, 150, 216, 200, 220, 167, 178, 246, 113, 126, 121, 184, 71, 51, 27, 244, 213, 230, 53, 59, 15, 120, 58, 118, 176, 49, 89, 47, 271, 248, 111, 92, 252, 5, 265, 151, 87, 36, 173, 37, 115, 104, 29, 198, 181, 31, 231, 153, 22, 65, 6, 251, 188, 52, 175, 138, 134, 4, 133, 166, 55, 77, 157, 46, 267, 1, 254, 268, 64, 221, 25, 190, 141, 44, 245, 182, 10, 86, 225, 129, 204, 30, 269, 127, 152, 68, 147, 130, 142, 76, 218, 57, 26, 131, 38, 211, 237, 139, 125, 61, 196, 160, 159, 264, 165, 186, 110, 119, 72, 208, 174, 117, 219, 206, 100, 195, 11, 122, 97, 148, 123, 226, 106, 42, 199, 193, 43, 45, 145, 261, 98, 209, 163, 18, 23, 74, 32, 75, 242, 33, 21, 247, 170, 201, 35, 154, 54, 164, 17, 257, 69, 207, 255, 105, 140, 191, 60, 0, 41, 161, 273, 238, 223, 112, 128, 224, 171, 91, 116, 169, 132, 180, 108, 189, 168, 214, 56, 13, 78, 19, 12, 270, 215, 192, 34, 16, 82, 136, 258, 228, 48, 262, 143, 20, 124, 107, 212, 179, 73, 260, 187, 259, 240, 249, 235, 101, 250, 7, 3], 'val_indices': [109, 217, 222, 263, 194, 241, 137, 81, 84, 39, 9, 94, 183, 103, 210, 135, 266, 239, 253, 162, 114, 50, 272, 233, 236, 99, 227, 24, 63, 96, 229, 80, 185, 205, 158, 8, 93, 85, 66, 90, 177, 243, 172, 202, 28, 70, 67, 256, 62, 149, 144, 197, 95, 2, 234], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}, {'fold_index': 2, 'train_indices': [207, 271, 268, 250, 204, 195, 40, 245, 221, 184, 22, 90, 246, 59, 65, 91, 70, 17, 54, 67, 215, 217, 41, 260, 78, 100, 197, 93, 75, 31, 235, 74, 169, 182, 119, 145, 146, 21, 200, 194, 110, 26, 63, 164, 73, 156, 254, 255, 212, 209, 155, 247, 264, 55, 143, 88, 267, 138, 205, 94, 134, 105, 98, 157, 183, 52, 179, 72, 242, 106, 77, 28, 270, 47, 20, 19, 66, 239, 152, 87, 136, 253, 6, 115, 216, 131, 58, 125, 144, 162, 1, 51, 180, 24, 122, 211, 266, 96, 154, 160, 269, 153, 39, 229, 261, 7, 226, 46, 81, 244, 228, 32, 175, 139, 82, 37, 231, 140, 225, 163, 107, 251, 218, 127, 203, 189, 190, 92, 9, 61, 114, 187, 16, 36, 132, 103, 133, 237, 191, 240, 0, 49, 45, 159, 30, 241, 232, 192, 220, 230, 57, 99, 29, 135, 147, 56, 262, 86, 168, 149, 80, 60, 79, 272, 15, 130, 176, 5, 123, 12, 165, 48, 170, 249, 202, 223, 129, 10, 188, 71, 213, 111, 150, 42, 85, 76, 62, 38, 177, 151, 199, 252, 95, 259, 265, 121, 208, 233, 44, 27, 206, 219, 4, 257, 172, 11, 141, 101, 263, 174, 25, 14, 236, 171, 69, 166, 161, 23, 126], 'val_indices': [102, 116, 3, 148, 227, 35, 222, 224, 113, 108, 196, 118, 18, 68, 193, 109, 234, 89, 186, 214, 43, 167, 83, 2, 120, 117, 97, 210, 256, 198, 112, 173, 181, 158, 273, 201, 34, 238, 258, 53, 128, 64, 124, 104, 13, 142, 50, 243, 33, 137, 185, 178, 8, 84, 248], 'accuracy': 0.9818181818181818, 'kappa': 0.9636002647253474, 'auc': 1.0}, {'fold_index': 3, 'train_indices': [241, 209, 219, 263, 47, 227, 56, 44, 53, 185, 187, 142, 143, 18, 5, 269, 177, 136, 72, 31, 248, 193, 137, 25, 128, 145, 204, 166, 77, 27, 213, 114, 179, 100, 26, 6, 256, 199, 194, 78, 147, 221, 16, 108, 215, 22, 188, 80, 42, 39, 233, 173, 75, 129, 214, 266, 271, 90, 175, 126, 195, 10, 203, 228, 35, 181, 0, 67, 144, 111, 84, 95, 9, 112, 46, 21, 33, 150, 125, 191, 8, 237, 210, 261, 94, 43, 224, 58, 186, 15, 49, 260, 122, 235, 170, 165, 4, 54, 91, 178, 201, 124, 107, 99, 89, 3, 160, 156, 218, 103, 98, 12, 123, 157, 268, 152, 167, 82, 231, 30, 141, 88, 246, 184, 154, 20, 258, 265, 196, 28, 40, 60, 73, 102, 245, 259, 153, 50, 55, 146, 34, 65, 52, 149, 242, 96, 140, 70, 29, 155, 200, 119, 222, 133, 115, 131, 41, 257, 225, 106, 189, 216, 7, 270, 180, 255, 32, 24, 232, 229, 120, 68, 162, 161, 217, 206, 110, 23, 2, 38, 121, 13, 249, 63, 59, 135, 139, 198, 109, 117, 244, 158, 11, 230, 134, 253, 62, 116, 273, 66, 101, 105, 151, 51, 251, 171, 172, 85, 223, 190, 159, 71, 197, 208, 192, 272, 226, 83, 239], 'val_indices': [207, 14, 238, 240, 163, 48, 37, 113, 236, 138, 61, 19, 57, 243, 169, 1, 36, 92, 81, 234, 97, 69, 205, 79, 211, 76, 182, 74, 174, 132, 127, 252, 264, 17, 254, 118, 148, 87, 130, 104, 267, 176, 86, 212, 45, 262, 220, 183, 202, 164, 250, 247, 64, 168, 93], 'accuracy': 0.9818181818181818, 'kappa': 0.9636483807005949, 'auc': 1.0}, {'fold_index': 4, 'train_indices': [264, 148, 181, 152, 137, 106, 219, 183, 98, 1, 76, 18, 263, 235, 90, 81, 147, 180, 259, 176, 99, 121, 114, 116, 146, 8, 268, 120, 125, 196, 267, 86, 135, 124, 95, 233, 33, 211, 84, 122, 243, 237, 133, 48, 221, 64, 22, 246, 240, 208, 4, 239, 105, 63, 2, 10, 71, 45, 182, 234, 145, 100, 139, 112, 140, 115, 197, 177, 56, 53, 210, 109, 232, 35, 220, 36, 21, 174, 144, 228, 179, 24, 143, 199, 227, 155, 198, 0, 249, 93, 94, 169, 131, 134, 107, 82, 11, 69, 204, 195, 73, 213, 200, 236, 119, 224, 226, 247, 27, 43, 44, 87, 251, 58, 161, 272, 171, 258, 7, 72, 231, 108, 212, 203, 253, 110, 54, 77, 149, 28, 66, 91, 60, 184, 78, 38, 142, 31, 29, 158, 193, 89, 123, 96, 194, 162, 173, 160, 40, 153, 216, 151, 189, 215, 83, 57, 256, 47, 49, 130, 16, 244, 97, 192, 269, 156, 70, 164, 159, 101, 241, 67, 9, 92, 166, 118, 255, 68, 136, 214, 273, 3, 17, 157, 242, 170, 206, 65, 75, 141, 138, 222, 202, 175, 132, 42, 218, 154, 205, 217, 20, 23, 52, 117, 266, 257, 250, 5, 191, 13, 178, 25, 238, 128, 111, 103, 223, 51, 261], 'val_indices': [252, 163, 74, 50, 168, 127, 30, 201, 61, 126, 19, 37, 150, 271, 270, 79, 14, 80, 230, 6, 41, 262, 188, 129, 15, 254, 85, 62, 113, 167, 229, 39, 88, 34, 265, 245, 185, 187, 260, 190, 55, 165, 225, 59, 12, 26, 186, 102, 207, 172, 209, 104, 32, 46, 248], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}], 'std_acc': 0.02, 'std_kappa': 0.04, 'std_auc': 0.001}\n",
      "sbj =  4\n",
      "Filtered from 262 trials to 129 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 228 trials to 116 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (245, 22, 448, 1), y_train shape: (245,)\n",
      "Running fold 0 with 196 training samples and 49 validation samples\n",
      "Fold 0: train indices: [119 220  87 147 159], val indices: [ 63 136  95  64  74]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (49, 22, 448, 1)\n",
      "Fold 0 training loss: 0.012564602307975292\n",
      "y_true (val): [1 0 0 1 0]\n",
      "y_pred: [1 1 0 1 1]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [119, 220, 87, 147, 159, 45, 148, 200, 9, 60, 109, 26, 224, 141, 122, 195, 197, 129, 163, 232, 193, 72, 83, 16, 32, 186, 19, 20, 120, 231, 225, 206, 61, 92, 202, 78, 107, 44, 121, 25, 38, 69, 106, 171, 177, 73, 151, 221, 185, 5, 58, 238, 146, 130, 156, 76, 216, 68, 214, 23, 40, 230, 116, 51, 182, 21, 82, 28, 65, 203, 80, 41, 96, 228, 144, 7, 59, 102, 188, 212, 93, 27, 34, 37, 57, 235, 167, 218, 33, 173, 53, 30, 98, 217, 1, 134, 172, 174, 166, 55, 226, 187, 103, 31, 2, 213, 237, 18, 101, 29, 127, 194, 46, 138, 189, 178, 94, 62, 52, 179, 113, 143, 241, 115, 17, 199, 3, 219, 105, 180, 165, 198, 49, 233, 211, 154, 90, 79, 86, 114, 4, 201, 124, 70, 71, 50, 22, 192, 77, 157, 15, 239, 100, 118, 67, 89, 110, 234, 243, 191, 126, 135, 97, 132, 85, 0, 139, 35, 81, 161, 42, 140, 184, 117, 208, 47, 158, 145, 155, 204, 169, 88, 14, 236, 8, 112, 227, 209, 39, 190, 222, 223, 10, 137, 149, 56], 'val_indices': [63, 136, 95, 64, 74, 75, 48, 84, 229, 162, 215, 170, 12, 99, 196, 164, 6, 131, 153, 152, 142, 36, 210, 43, 66, 183, 125, 168, 160, 128, 54, 108, 242, 244, 181, 91, 111, 207, 150, 123, 175, 240, 176, 104, 13, 205, 11, 133, 24], 'accuracy': 0.6938775510204082, 'kappa': 0.38596491228070173, 'auc': 0.7616666666666666}\n",
      "New Max Found!\n",
      "Running fold 1 with 196 training samples and 49 validation samples\n",
      "Fold 1: train indices: [220 115 218 112   2], val indices: [212 146  68  72  15]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (49, 22, 448, 1)\n",
      "Fold 1 training loss: 0.01119585894048214\n",
      "y_true (val): [0 1 0 0 1]\n",
      "y_pred: [0 0 0 0 0]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [220, 115, 218, 112, 2, 50, 9, 76, 160, 92, 169, 185, 75, 123, 77, 174, 36, 3, 238, 235, 59, 103, 236, 145, 27, 139, 202, 108, 244, 225, 157, 118, 34, 101, 35, 211, 224, 142, 161, 137, 122, 178, 243, 164, 175, 43, 32, 106, 10, 239, 69, 217, 237, 226, 70, 127, 56, 231, 28, 19, 204, 162, 61, 222, 11, 193, 13, 96, 242, 74, 136, 104, 177, 60, 223, 47, 197, 48, 24, 82, 140, 213, 85, 94, 168, 45, 121, 189, 21, 171, 126, 151, 79, 190, 98, 38, 173, 20, 57, 147, 133, 46, 154, 83, 198, 97, 73, 44, 58, 214, 181, 135, 119, 166, 128, 194, 205, 80, 41, 234, 33, 67, 167, 4, 199, 53, 179, 105, 109, 150, 7, 206, 170, 54, 88, 132, 141, 176, 51, 5, 156, 78, 129, 163, 26, 87, 110, 158, 6, 63, 114, 203, 148, 188, 229, 125, 210, 40, 207, 102, 14, 182, 201, 93, 191, 230, 143, 131, 216, 91, 49, 39, 89, 215, 25, 42, 149, 111, 153, 65, 228, 219, 107, 81, 52, 186, 196, 221, 116, 86, 8, 195, 233, 31, 84, 16], 'val_indices': [212, 146, 68, 72, 15, 29, 113, 0, 232, 22, 241, 18, 90, 180, 64, 200, 240, 144, 192, 134, 159, 37, 117, 12, 95, 208, 62, 187, 183, 71, 172, 1, 30, 184, 23, 100, 120, 17, 66, 227, 130, 209, 152, 99, 155, 55, 124, 165, 138], 'accuracy': 0.7142857142857143, 'kappa': 0.42928452579034937, 'auc': 0.795}\n",
      "New Max Found!\n",
      "Running fold 2 with 196 training samples and 49 validation samples\n",
      "Fold 2: train indices: [  6 109 150  31 184], val indices: [111  86 100 241 198]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (49, 22, 448, 1)\n",
      "Fold 2 training loss: 0.01400457601994276\n",
      "y_true (val): [0 1 1 1 1]\n",
      "y_pred: [1 1 0 1 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [6, 109, 150, 31, 184, 58, 97, 11, 96, 200, 186, 98, 62, 210, 105, 75, 26, 30, 43, 40, 41, 34, 112, 131, 74, 71, 46, 67, 133, 59, 113, 95, 218, 179, 158, 216, 90, 102, 38, 22, 93, 1, 234, 80, 178, 172, 181, 233, 103, 35, 170, 32, 230, 50, 5, 87, 209, 88, 91, 143, 205, 65, 17, 194, 29, 206, 188, 78, 53, 237, 224, 232, 0, 54, 157, 239, 197, 180, 108, 15, 23, 226, 219, 69, 202, 139, 211, 118, 3, 174, 175, 235, 44, 79, 101, 81, 161, 130, 135, 94, 120, 61, 225, 169, 244, 8, 119, 57, 142, 7, 110, 125, 83, 55, 107, 222, 240, 162, 208, 165, 99, 229, 106, 9, 166, 60, 20, 149, 2, 215, 56, 153, 177, 183, 116, 37, 199, 84, 207, 195, 214, 24, 77, 220, 70, 148, 217, 49, 164, 68, 187, 213, 114, 121, 136, 160, 168, 36, 33, 147, 129, 163, 191, 10, 82, 42, 25, 18, 201, 76, 228, 145, 48, 85, 64, 16, 115, 12, 212, 185, 151, 176, 223, 190, 227, 45, 128, 152, 51, 39, 243, 189, 192, 144, 204, 66], 'val_indices': [111, 86, 100, 241, 198, 123, 72, 92, 193, 140, 236, 126, 19, 182, 231, 127, 167, 21, 242, 171, 28, 132, 138, 124, 141, 89, 73, 196, 159, 221, 14, 173, 238, 122, 47, 117, 156, 13, 155, 154, 137, 146, 4, 52, 203, 104, 63, 134, 27], 'accuracy': 0.6530612244897959, 'kappa': 0.30409356725146197, 'auc': 0.7166666666666667}\n",
      "Running fold 3 with 196 training samples and 49 validation samples\n",
      "Fold 3: train indices: [ 38  44 123   5  92], val indices: [ 17 107 132  26 225]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (49, 22, 448, 1)\n",
      "Fold 3 training loss: 0.013402075506746769\n",
      "y_true (val): [1 1 0 0 0]\n",
      "y_pred: [1 0 1 0 0]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [38, 44, 123, 5, 92, 54, 158, 228, 108, 155, 185, 147, 28, 135, 110, 221, 143, 229, 142, 51, 103, 217, 137, 74, 33, 55, 57, 100, 215, 53, 82, 84, 240, 90, 232, 187, 24, 121, 2, 214, 182, 191, 203, 154, 190, 218, 27, 146, 174, 104, 80, 196, 76, 48, 46, 94, 32, 62, 164, 200, 87, 189, 184, 235, 116, 139, 91, 29, 13, 125, 169, 138, 11, 175, 149, 56, 0, 3, 15, 106, 71, 234, 37, 151, 152, 199, 7, 178, 195, 68, 122, 96, 6, 239, 109, 209, 134, 45, 50, 181, 202, 177, 8, 193, 102, 98, 63, 192, 22, 216, 78, 126, 19, 161, 213, 10, 230, 93, 119, 58, 194, 207, 183, 231, 130, 4, 39, 222, 115, 227, 47, 65, 237, 81, 77, 206, 111, 179, 210, 243, 219, 70, 34, 241, 79, 118, 35, 236, 186, 208, 75, 224, 145, 140, 114, 117, 20, 170, 72, 242, 141, 220, 9, 99, 18, 144, 223, 43, 86, 52, 133, 61, 112, 36, 105, 129, 136, 180, 95, 167, 153, 83, 1, 120, 198, 66, 131, 233, 21, 69, 14, 172, 101, 204, 211, 148], 'val_indices': [17, 107, 132, 26, 225, 165, 188, 42, 41, 128, 226, 16, 176, 197, 205, 163, 12, 171, 127, 124, 49, 60, 159, 97, 160, 113, 64, 40, 173, 25, 23, 157, 201, 162, 31, 67, 85, 73, 150, 238, 212, 89, 166, 30, 168, 59, 156, 244, 88], 'accuracy': 0.7551020408163265, 'kappa': 0.5091819699499165, 'auc': 0.8266666666666667}\n",
      "New Max Found!\n",
      "Running fold 4 with 196 training samples and 49 validation samples\n",
      "Fold 4: train indices: [ 74  72 212 176 171], val indices: [214  65 159 190  29]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (49, 22, 448, 1)\n",
      "Fold 4 training loss: 0.01767633482813835\n",
      "y_true (val): [0 1 0 0 0]\n",
      "y_pred: [0 1 0 1 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [74, 72, 212, 176, 171, 132, 127, 228, 110, 81, 46, 184, 198, 229, 49, 32, 4, 134, 60, 23, 56, 79, 192, 99, 71, 150, 131, 223, 90, 136, 215, 177, 236, 178, 120, 10, 244, 30, 156, 67, 62, 84, 206, 238, 163, 172, 37, 24, 109, 92, 8, 53, 5, 170, 187, 76, 55, 208, 33, 117, 98, 103, 0, 174, 45, 147, 153, 51, 66, 19, 78, 21, 105, 227, 36, 104, 209, 15, 14, 16, 146, 64, 193, 195, 69, 88, 181, 101, 217, 166, 40, 9, 167, 80, 210, 17, 89, 57, 130, 113, 111, 94, 63, 75, 224, 13, 180, 158, 219, 137, 28, 44, 218, 133, 139, 207, 91, 68, 86, 157, 34, 168, 201, 233, 73, 25, 194, 189, 199, 59, 160, 216, 242, 87, 126, 173, 188, 93, 151, 38, 240, 3, 179, 115, 202, 77, 125, 96, 123, 2, 230, 54, 107, 48, 155, 124, 7, 58, 128, 196, 52, 43, 31, 239, 41, 141, 232, 97, 61, 70, 162, 20, 140, 221, 143, 200, 12, 241, 197, 1, 144, 112, 205, 149, 226, 154, 182, 102, 183, 82, 39, 122, 145, 211, 164, 231], 'val_indices': [214, 65, 159, 190, 29, 138, 234, 114, 152, 118, 85, 106, 27, 50, 35, 26, 220, 6, 47, 203, 42, 243, 186, 142, 175, 83, 22, 95, 100, 119, 213, 148, 121, 237, 161, 235, 108, 129, 225, 135, 165, 222, 191, 185, 169, 18, 11, 116, 204], 'accuracy': 0.7551020408163265, 'kappa': 0.5116279069767442, 'auc': 0.8033333333333333}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.714, 'mean_kappa': 0.428, 'mean_auc': 0.781, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [119, 220, 87, 147, 159, 45, 148, 200, 9, 60, 109, 26, 224, 141, 122, 195, 197, 129, 163, 232, 193, 72, 83, 16, 32, 186, 19, 20, 120, 231, 225, 206, 61, 92, 202, 78, 107, 44, 121, 25, 38, 69, 106, 171, 177, 73, 151, 221, 185, 5, 58, 238, 146, 130, 156, 76, 216, 68, 214, 23, 40, 230, 116, 51, 182, 21, 82, 28, 65, 203, 80, 41, 96, 228, 144, 7, 59, 102, 188, 212, 93, 27, 34, 37, 57, 235, 167, 218, 33, 173, 53, 30, 98, 217, 1, 134, 172, 174, 166, 55, 226, 187, 103, 31, 2, 213, 237, 18, 101, 29, 127, 194, 46, 138, 189, 178, 94, 62, 52, 179, 113, 143, 241, 115, 17, 199, 3, 219, 105, 180, 165, 198, 49, 233, 211, 154, 90, 79, 86, 114, 4, 201, 124, 70, 71, 50, 22, 192, 77, 157, 15, 239, 100, 118, 67, 89, 110, 234, 243, 191, 126, 135, 97, 132, 85, 0, 139, 35, 81, 161, 42, 140, 184, 117, 208, 47, 158, 145, 155, 204, 169, 88, 14, 236, 8, 112, 227, 209, 39, 190, 222, 223, 10, 137, 149, 56], 'val_indices': [63, 136, 95, 64, 74, 75, 48, 84, 229, 162, 215, 170, 12, 99, 196, 164, 6, 131, 153, 152, 142, 36, 210, 43, 66, 183, 125, 168, 160, 128, 54, 108, 242, 244, 181, 91, 111, 207, 150, 123, 175, 240, 176, 104, 13, 205, 11, 133, 24], 'accuracy': 0.6938775510204082, 'kappa': 0.38596491228070173, 'auc': 0.7616666666666666}, {'fold_index': 1, 'train_indices': [220, 115, 218, 112, 2, 50, 9, 76, 160, 92, 169, 185, 75, 123, 77, 174, 36, 3, 238, 235, 59, 103, 236, 145, 27, 139, 202, 108, 244, 225, 157, 118, 34, 101, 35, 211, 224, 142, 161, 137, 122, 178, 243, 164, 175, 43, 32, 106, 10, 239, 69, 217, 237, 226, 70, 127, 56, 231, 28, 19, 204, 162, 61, 222, 11, 193, 13, 96, 242, 74, 136, 104, 177, 60, 223, 47, 197, 48, 24, 82, 140, 213, 85, 94, 168, 45, 121, 189, 21, 171, 126, 151, 79, 190, 98, 38, 173, 20, 57, 147, 133, 46, 154, 83, 198, 97, 73, 44, 58, 214, 181, 135, 119, 166, 128, 194, 205, 80, 41, 234, 33, 67, 167, 4, 199, 53, 179, 105, 109, 150, 7, 206, 170, 54, 88, 132, 141, 176, 51, 5, 156, 78, 129, 163, 26, 87, 110, 158, 6, 63, 114, 203, 148, 188, 229, 125, 210, 40, 207, 102, 14, 182, 201, 93, 191, 230, 143, 131, 216, 91, 49, 39, 89, 215, 25, 42, 149, 111, 153, 65, 228, 219, 107, 81, 52, 186, 196, 221, 116, 86, 8, 195, 233, 31, 84, 16], 'val_indices': [212, 146, 68, 72, 15, 29, 113, 0, 232, 22, 241, 18, 90, 180, 64, 200, 240, 144, 192, 134, 159, 37, 117, 12, 95, 208, 62, 187, 183, 71, 172, 1, 30, 184, 23, 100, 120, 17, 66, 227, 130, 209, 152, 99, 155, 55, 124, 165, 138], 'accuracy': 0.7142857142857143, 'kappa': 0.42928452579034937, 'auc': 0.795}, {'fold_index': 2, 'train_indices': [6, 109, 150, 31, 184, 58, 97, 11, 96, 200, 186, 98, 62, 210, 105, 75, 26, 30, 43, 40, 41, 34, 112, 131, 74, 71, 46, 67, 133, 59, 113, 95, 218, 179, 158, 216, 90, 102, 38, 22, 93, 1, 234, 80, 178, 172, 181, 233, 103, 35, 170, 32, 230, 50, 5, 87, 209, 88, 91, 143, 205, 65, 17, 194, 29, 206, 188, 78, 53, 237, 224, 232, 0, 54, 157, 239, 197, 180, 108, 15, 23, 226, 219, 69, 202, 139, 211, 118, 3, 174, 175, 235, 44, 79, 101, 81, 161, 130, 135, 94, 120, 61, 225, 169, 244, 8, 119, 57, 142, 7, 110, 125, 83, 55, 107, 222, 240, 162, 208, 165, 99, 229, 106, 9, 166, 60, 20, 149, 2, 215, 56, 153, 177, 183, 116, 37, 199, 84, 207, 195, 214, 24, 77, 220, 70, 148, 217, 49, 164, 68, 187, 213, 114, 121, 136, 160, 168, 36, 33, 147, 129, 163, 191, 10, 82, 42, 25, 18, 201, 76, 228, 145, 48, 85, 64, 16, 115, 12, 212, 185, 151, 176, 223, 190, 227, 45, 128, 152, 51, 39, 243, 189, 192, 144, 204, 66], 'val_indices': [111, 86, 100, 241, 198, 123, 72, 92, 193, 140, 236, 126, 19, 182, 231, 127, 167, 21, 242, 171, 28, 132, 138, 124, 141, 89, 73, 196, 159, 221, 14, 173, 238, 122, 47, 117, 156, 13, 155, 154, 137, 146, 4, 52, 203, 104, 63, 134, 27], 'accuracy': 0.6530612244897959, 'kappa': 0.30409356725146197, 'auc': 0.7166666666666667}, {'fold_index': 3, 'train_indices': [38, 44, 123, 5, 92, 54, 158, 228, 108, 155, 185, 147, 28, 135, 110, 221, 143, 229, 142, 51, 103, 217, 137, 74, 33, 55, 57, 100, 215, 53, 82, 84, 240, 90, 232, 187, 24, 121, 2, 214, 182, 191, 203, 154, 190, 218, 27, 146, 174, 104, 80, 196, 76, 48, 46, 94, 32, 62, 164, 200, 87, 189, 184, 235, 116, 139, 91, 29, 13, 125, 169, 138, 11, 175, 149, 56, 0, 3, 15, 106, 71, 234, 37, 151, 152, 199, 7, 178, 195, 68, 122, 96, 6, 239, 109, 209, 134, 45, 50, 181, 202, 177, 8, 193, 102, 98, 63, 192, 22, 216, 78, 126, 19, 161, 213, 10, 230, 93, 119, 58, 194, 207, 183, 231, 130, 4, 39, 222, 115, 227, 47, 65, 237, 81, 77, 206, 111, 179, 210, 243, 219, 70, 34, 241, 79, 118, 35, 236, 186, 208, 75, 224, 145, 140, 114, 117, 20, 170, 72, 242, 141, 220, 9, 99, 18, 144, 223, 43, 86, 52, 133, 61, 112, 36, 105, 129, 136, 180, 95, 167, 153, 83, 1, 120, 198, 66, 131, 233, 21, 69, 14, 172, 101, 204, 211, 148], 'val_indices': [17, 107, 132, 26, 225, 165, 188, 42, 41, 128, 226, 16, 176, 197, 205, 163, 12, 171, 127, 124, 49, 60, 159, 97, 160, 113, 64, 40, 173, 25, 23, 157, 201, 162, 31, 67, 85, 73, 150, 238, 212, 89, 166, 30, 168, 59, 156, 244, 88], 'accuracy': 0.7551020408163265, 'kappa': 0.5091819699499165, 'auc': 0.8266666666666667}, {'fold_index': 4, 'train_indices': [74, 72, 212, 176, 171, 132, 127, 228, 110, 81, 46, 184, 198, 229, 49, 32, 4, 134, 60, 23, 56, 79, 192, 99, 71, 150, 131, 223, 90, 136, 215, 177, 236, 178, 120, 10, 244, 30, 156, 67, 62, 84, 206, 238, 163, 172, 37, 24, 109, 92, 8, 53, 5, 170, 187, 76, 55, 208, 33, 117, 98, 103, 0, 174, 45, 147, 153, 51, 66, 19, 78, 21, 105, 227, 36, 104, 209, 15, 14, 16, 146, 64, 193, 195, 69, 88, 181, 101, 217, 166, 40, 9, 167, 80, 210, 17, 89, 57, 130, 113, 111, 94, 63, 75, 224, 13, 180, 158, 219, 137, 28, 44, 218, 133, 139, 207, 91, 68, 86, 157, 34, 168, 201, 233, 73, 25, 194, 189, 199, 59, 160, 216, 242, 87, 126, 173, 188, 93, 151, 38, 240, 3, 179, 115, 202, 77, 125, 96, 123, 2, 230, 54, 107, 48, 155, 124, 7, 58, 128, 196, 52, 43, 31, 239, 41, 141, 232, 97, 61, 70, 162, 20, 140, 221, 143, 200, 12, 241, 197, 1, 144, 112, 205, 149, 226, 154, 182, 102, 183, 82, 39, 122, 145, 211, 164, 231], 'val_indices': [214, 65, 159, 190, 29, 138, 234, 114, 152, 118, 85, 106, 27, 50, 35, 26, 220, 6, 47, 203, 42, 243, 186, 142, 175, 83, 22, 95, 100, 119, 213, 148, 121, 237, 161, 235, 108, 129, 225, 135, 165, 222, 191, 185, 169, 18, 11, 116, 204], 'accuracy': 0.7551020408163265, 'kappa': 0.5116279069767442, 'auc': 0.8033333333333333}], 'std_acc': 0.039, 'std_kappa': 0.078, 'std_auc': 0.038}\n",
      "sbj =  5\n",
      "Filtered from 262 trials to 129 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 276 trials to 135 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (264, 22, 448, 1), y_train shape: (264,)\n",
      "Running fold 0 with 211 training samples and 53 validation samples\n",
      "Fold 0: train indices: [ 90  32  20  93 224], val indices: [213 236  53 126 104]\n",
      "Training data shape: (211, 22, 448, 1), Validation data shape: (53, 22, 448, 1)\n",
      "Fold 0 training loss: 0.009013664908707142\n",
      "y_true (val): [1 1 0 1 1]\n",
      "y_pred: [1 1 1 1 1]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [90, 32, 20, 93, 224, 172, 70, 189, 142, 201, 66, 58, 254, 36, 82, 1, 250, 80, 40, 234, 194, 7, 161, 37, 33, 119, 174, 137, 67, 204, 263, 237, 115, 5, 109, 51, 139, 18, 187, 17, 102, 71, 257, 31, 233, 81, 245, 117, 205, 77, 217, 83, 235, 230, 190, 147, 46, 262, 108, 112, 38, 141, 60, 164, 210, 206, 222, 232, 100, 28, 214, 171, 101, 134, 39, 124, 212, 152, 50, 155, 261, 62, 218, 243, 25, 149, 23, 167, 180, 244, 138, 220, 9, 200, 258, 26, 127, 0, 260, 197, 44, 86, 110, 131, 56, 79, 143, 183, 120, 178, 85, 159, 209, 114, 27, 99, 247, 42, 34, 248, 181, 252, 241, 15, 84, 95, 239, 125, 229, 192, 14, 128, 256, 3, 219, 118, 168, 106, 223, 198, 199, 76, 107, 146, 195, 179, 225, 64, 35, 151, 157, 2, 251, 177, 65, 162, 191, 75, 129, 113, 78, 238, 148, 196, 24, 87, 21, 202, 145, 69, 68, 89, 10, 4, 136, 249, 48, 173, 228, 166, 193, 103, 57, 45, 52, 226, 221, 133, 8, 94, 203, 54, 253, 30, 259, 153, 207, 16, 59, 156, 97, 121, 216, 41, 61, 98, 227, 188, 160, 19, 49], 'val_indices': [213, 236, 53, 126, 104, 72, 208, 74, 150, 73, 255, 231, 13, 175, 96, 116, 184, 105, 135, 240, 63, 158, 47, 130, 88, 154, 123, 132, 91, 215, 11, 22, 111, 163, 246, 144, 242, 185, 176, 43, 169, 29, 92, 140, 165, 186, 6, 122, 211, 182, 55, 12, 170], 'accuracy': 0.8490566037735849, 'kappa': 0.6988636363636364, 'auc': 0.8646723646723647}\n",
      "New Max Found!\n",
      "Running fold 1 with 211 training samples and 53 validation samples\n",
      "Fold 1: train indices: [ 55 190 114 148  58], val indices: [108 188 238  22 210]\n",
      "Training data shape: (211, 22, 448, 1), Validation data shape: (53, 22, 448, 1)\n",
      "Fold 1 training loss: 0.011299152858555317\n",
      "y_true (val): [0 1 1 0 1]\n",
      "y_pred: [0 0 1 1 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [55, 190, 114, 148, 58, 45, 164, 84, 36, 67, 42, 194, 139, 25, 178, 97, 71, 253, 3, 213, 247, 144, 95, 219, 231, 8, 99, 192, 137, 28, 207, 14, 44, 74, 195, 19, 119, 34, 259, 66, 35, 208, 90, 51, 103, 70, 56, 183, 160, 255, 43, 246, 196, 121, 239, 172, 237, 224, 185, 143, 261, 18, 228, 215, 6, 113, 37, 57, 75, 52, 179, 83, 16, 234, 31, 127, 133, 167, 197, 120, 62, 76, 170, 134, 229, 68, 29, 204, 162, 226, 65, 171, 257, 5, 235, 227, 201, 181, 123, 191, 240, 110, 199, 13, 124, 64, 112, 152, 40, 94, 186, 130, 217, 146, 61, 141, 145, 221, 153, 254, 32, 243, 87, 187, 184, 47, 250, 158, 129, 48, 10, 111, 85, 157, 175, 236, 245, 117, 214, 256, 233, 53, 30, 46, 73, 24, 132, 81, 23, 159, 101, 21, 193, 50, 258, 161, 104, 122, 211, 136, 249, 116, 107, 27, 49, 209, 182, 20, 88, 163, 241, 216, 189, 86, 248, 244, 200, 156, 100, 93, 91, 98, 212, 7, 202, 173, 33, 140, 165, 131, 220, 180, 11, 41, 251, 252, 138, 38, 176, 142, 150, 0, 80, 218, 169, 125, 1, 168, 54, 79, 232], 'val_indices': [108, 188, 238, 22, 210, 206, 92, 223, 260, 151, 9, 39, 203, 118, 154, 174, 225, 109, 128, 72, 26, 147, 102, 77, 15, 222, 63, 126, 59, 177, 82, 166, 12, 230, 155, 89, 205, 96, 105, 262, 198, 106, 115, 2, 17, 149, 263, 78, 4, 242, 60, 135, 69], 'accuracy': 0.8679245283018868, 'kappa': 0.736318407960199, 'auc': 0.8618233618233618}\n",
      "New Max Found!\n",
      "Running fold 2 with 211 training samples and 53 validation samples\n",
      "Fold 2: train indices: [100 128  65 131 174], val indices: [196 180 178  88 234]\n",
      "Training data shape: (211, 22, 448, 1), Validation data shape: (53, 22, 448, 1)\n",
      "Fold 2 training loss: 0.017904246225953102\n",
      "y_true (val): [0 0 0 0 1]\n",
      "y_pred: [0 1 0 1 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [100, 128, 65, 131, 174, 89, 255, 124, 31, 175, 137, 2, 236, 30, 13, 227, 208, 228, 162, 204, 112, 14, 9, 98, 48, 4, 246, 259, 171, 53, 138, 125, 220, 37, 186, 38, 143, 21, 60, 163, 214, 66, 167, 90, 195, 110, 70, 193, 216, 57, 210, 56, 172, 27, 109, 1, 217, 147, 17, 76, 18, 209, 26, 16, 101, 129, 177, 49, 139, 7, 58, 190, 68, 224, 83, 79, 192, 116, 197, 249, 136, 247, 46, 118, 185, 173, 151, 132, 219, 148, 117, 218, 51, 201, 166, 105, 152, 159, 74, 260, 80, 10, 43, 123, 145, 32, 99, 64, 87, 183, 86, 140, 122, 184, 160, 42, 150, 92, 225, 114, 250, 156, 11, 261, 161, 130, 63, 6, 182, 229, 253, 103, 126, 25, 44, 205, 108, 170, 34, 238, 54, 149, 135, 3, 47, 207, 222, 256, 252, 82, 29, 231, 75, 39, 73, 176, 61, 153, 134, 96, 179, 19, 241, 95, 237, 158, 263, 230, 69, 85, 23, 12, 211, 142, 33, 102, 213, 52, 257, 50, 115, 254, 235, 22, 91, 194, 28, 226, 215, 169, 212, 242, 189, 221, 71, 206, 188, 262, 133, 119, 181, 104, 55, 154, 94, 240, 36, 24, 5, 258, 113], 'val_indices': [196, 180, 178, 88, 234, 59, 72, 20, 111, 40, 203, 15, 45, 107, 198, 141, 248, 232, 168, 187, 239, 0, 251, 164, 245, 191, 202, 243, 93, 223, 157, 8, 67, 106, 244, 233, 199, 127, 144, 146, 78, 165, 84, 120, 155, 97, 77, 81, 62, 41, 35, 121, 200], 'accuracy': 0.5283018867924528, 'kappa': 0.05693950177935947, 'auc': 0.5740740740740741}\n",
      "Running fold 3 with 211 training samples and 53 validation samples\n",
      "Fold 3: train indices: [233 115 226  98 119], val indices: [247 168 165  74  14]\n",
      "Training data shape: (211, 22, 448, 1), Validation data shape: (53, 22, 448, 1)\n",
      "Fold 3 training loss: 0.00872772466391325\n",
      "y_true (val): [0 1 1 0 1]\n",
      "y_pred: [0 1 1 1 0]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [233, 115, 226, 98, 119, 218, 141, 189, 214, 198, 78, 130, 25, 10, 205, 219, 127, 48, 260, 44, 176, 192, 4, 19, 204, 6, 100, 166, 230, 147, 224, 220, 263, 137, 157, 79, 259, 159, 118, 81, 120, 106, 92, 12, 208, 90, 158, 101, 225, 181, 191, 169, 241, 180, 187, 152, 53, 82, 72, 184, 121, 135, 210, 207, 221, 240, 109, 162, 254, 143, 20, 160, 117, 94, 13, 257, 111, 182, 24, 179, 70, 197, 253, 75, 163, 114, 128, 108, 15, 8, 112, 193, 148, 245, 110, 49, 188, 228, 222, 80, 40, 41, 43, 42, 52, 242, 132, 140, 183, 244, 237, 64, 161, 261, 26, 47, 258, 178, 229, 36, 69, 215, 54, 113, 194, 149, 50, 31, 209, 212, 173, 139, 88, 200, 76, 55, 99, 133, 105, 97, 67, 77, 250, 201, 256, 186, 34, 185, 84, 145, 151, 68, 71, 61, 16, 195, 170, 144, 252, 213, 202, 46, 21, 93, 95, 246, 203, 231, 129, 28, 227, 45, 217, 38, 59, 190, 103, 107, 23, 83, 251, 22, 248, 104, 116, 172, 17, 243, 123, 91, 122, 126, 177, 223, 175, 57, 39, 33, 96, 87, 206, 146, 7, 136, 236, 249, 62, 138, 134, 89, 232], 'val_indices': [247, 168, 165, 74, 14, 27, 239, 196, 235, 125, 156, 63, 0, 56, 142, 5, 171, 35, 60, 11, 73, 153, 124, 154, 37, 66, 1, 216, 255, 65, 9, 86, 155, 18, 131, 85, 58, 29, 238, 199, 2, 30, 32, 262, 234, 51, 167, 3, 102, 174, 164, 211, 150], 'accuracy': 0.7735849056603774, 'kappa': 0.5470085470085471, 'auc': 0.8475783475783476}\n",
      "Running fold 4 with 211 training samples and 53 validation samples\n",
      "Fold 4: train indices: [ 69 254   3 248 142], val indices: [213 257  29 250  98]\n",
      "Training data shape: (211, 22, 448, 1), Validation data shape: (53, 22, 448, 1)\n",
      "Fold 4 training loss: 0.024188419803977013\n",
      "y_true (val): [1 1 0 0 1]\n",
      "y_pred: [1 0 0 0 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [69, 254, 3, 248, 142, 115, 116, 51, 39, 143, 48, 49, 228, 123, 104, 259, 226, 150, 208, 126, 242, 173, 238, 26, 19, 70, 103, 223, 159, 155, 33, 13, 138, 227, 110, 30, 99, 107, 149, 46, 247, 25, 156, 68, 111, 256, 131, 83, 161, 194, 0, 255, 62, 188, 121, 65, 225, 231, 151, 197, 54, 158, 89, 207, 236, 202, 20, 136, 125, 246, 187, 218, 147, 8, 7, 77, 160, 14, 214, 253, 171, 109, 130, 112, 71, 183, 185, 56, 196, 163, 34, 249, 105, 165, 135, 37, 15, 87, 38, 219, 153, 92, 117, 35, 137, 91, 154, 57, 235, 217, 244, 74, 212, 180, 240, 206, 189, 177, 97, 168, 61, 40, 1, 233, 258, 102, 101, 72, 44, 31, 95, 64, 215, 260, 94, 114, 133, 120, 118, 140, 58, 53, 166, 176, 220, 186, 41, 21, 106, 85, 178, 184, 230, 113, 232, 17, 205, 100, 152, 76, 86, 221, 60, 141, 251, 211, 6, 96, 18, 262, 193, 199, 245, 224, 237, 122, 234, 84, 261, 55, 222, 16, 81, 146, 42, 10, 191, 195, 124, 5, 190, 108, 78, 67, 4, 52, 45, 203, 9, 12, 157, 27, 181, 144, 198, 167, 210, 43, 241, 209, 128], 'val_indices': [213, 257, 29, 250, 98, 75, 175, 216, 59, 243, 127, 263, 179, 22, 63, 28, 170, 79, 66, 119, 93, 169, 134, 192, 36, 229, 73, 201, 90, 47, 132, 139, 145, 24, 129, 174, 23, 164, 252, 82, 148, 11, 162, 182, 80, 204, 88, 32, 2, 239, 172, 200, 50], 'accuracy': 0.6226415094339622, 'kappa': 0.24393723252496435, 'auc': 0.6623931623931625}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.728, 'mean_kappa': 0.457, 'mean_auc': 0.762, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [90, 32, 20, 93, 224, 172, 70, 189, 142, 201, 66, 58, 254, 36, 82, 1, 250, 80, 40, 234, 194, 7, 161, 37, 33, 119, 174, 137, 67, 204, 263, 237, 115, 5, 109, 51, 139, 18, 187, 17, 102, 71, 257, 31, 233, 81, 245, 117, 205, 77, 217, 83, 235, 230, 190, 147, 46, 262, 108, 112, 38, 141, 60, 164, 210, 206, 222, 232, 100, 28, 214, 171, 101, 134, 39, 124, 212, 152, 50, 155, 261, 62, 218, 243, 25, 149, 23, 167, 180, 244, 138, 220, 9, 200, 258, 26, 127, 0, 260, 197, 44, 86, 110, 131, 56, 79, 143, 183, 120, 178, 85, 159, 209, 114, 27, 99, 247, 42, 34, 248, 181, 252, 241, 15, 84, 95, 239, 125, 229, 192, 14, 128, 256, 3, 219, 118, 168, 106, 223, 198, 199, 76, 107, 146, 195, 179, 225, 64, 35, 151, 157, 2, 251, 177, 65, 162, 191, 75, 129, 113, 78, 238, 148, 196, 24, 87, 21, 202, 145, 69, 68, 89, 10, 4, 136, 249, 48, 173, 228, 166, 193, 103, 57, 45, 52, 226, 221, 133, 8, 94, 203, 54, 253, 30, 259, 153, 207, 16, 59, 156, 97, 121, 216, 41, 61, 98, 227, 188, 160, 19, 49], 'val_indices': [213, 236, 53, 126, 104, 72, 208, 74, 150, 73, 255, 231, 13, 175, 96, 116, 184, 105, 135, 240, 63, 158, 47, 130, 88, 154, 123, 132, 91, 215, 11, 22, 111, 163, 246, 144, 242, 185, 176, 43, 169, 29, 92, 140, 165, 186, 6, 122, 211, 182, 55, 12, 170], 'accuracy': 0.8490566037735849, 'kappa': 0.6988636363636364, 'auc': 0.8646723646723647}, {'fold_index': 1, 'train_indices': [55, 190, 114, 148, 58, 45, 164, 84, 36, 67, 42, 194, 139, 25, 178, 97, 71, 253, 3, 213, 247, 144, 95, 219, 231, 8, 99, 192, 137, 28, 207, 14, 44, 74, 195, 19, 119, 34, 259, 66, 35, 208, 90, 51, 103, 70, 56, 183, 160, 255, 43, 246, 196, 121, 239, 172, 237, 224, 185, 143, 261, 18, 228, 215, 6, 113, 37, 57, 75, 52, 179, 83, 16, 234, 31, 127, 133, 167, 197, 120, 62, 76, 170, 134, 229, 68, 29, 204, 162, 226, 65, 171, 257, 5, 235, 227, 201, 181, 123, 191, 240, 110, 199, 13, 124, 64, 112, 152, 40, 94, 186, 130, 217, 146, 61, 141, 145, 221, 153, 254, 32, 243, 87, 187, 184, 47, 250, 158, 129, 48, 10, 111, 85, 157, 175, 236, 245, 117, 214, 256, 233, 53, 30, 46, 73, 24, 132, 81, 23, 159, 101, 21, 193, 50, 258, 161, 104, 122, 211, 136, 249, 116, 107, 27, 49, 209, 182, 20, 88, 163, 241, 216, 189, 86, 248, 244, 200, 156, 100, 93, 91, 98, 212, 7, 202, 173, 33, 140, 165, 131, 220, 180, 11, 41, 251, 252, 138, 38, 176, 142, 150, 0, 80, 218, 169, 125, 1, 168, 54, 79, 232], 'val_indices': [108, 188, 238, 22, 210, 206, 92, 223, 260, 151, 9, 39, 203, 118, 154, 174, 225, 109, 128, 72, 26, 147, 102, 77, 15, 222, 63, 126, 59, 177, 82, 166, 12, 230, 155, 89, 205, 96, 105, 262, 198, 106, 115, 2, 17, 149, 263, 78, 4, 242, 60, 135, 69], 'accuracy': 0.8679245283018868, 'kappa': 0.736318407960199, 'auc': 0.8618233618233618}, {'fold_index': 2, 'train_indices': [100, 128, 65, 131, 174, 89, 255, 124, 31, 175, 137, 2, 236, 30, 13, 227, 208, 228, 162, 204, 112, 14, 9, 98, 48, 4, 246, 259, 171, 53, 138, 125, 220, 37, 186, 38, 143, 21, 60, 163, 214, 66, 167, 90, 195, 110, 70, 193, 216, 57, 210, 56, 172, 27, 109, 1, 217, 147, 17, 76, 18, 209, 26, 16, 101, 129, 177, 49, 139, 7, 58, 190, 68, 224, 83, 79, 192, 116, 197, 249, 136, 247, 46, 118, 185, 173, 151, 132, 219, 148, 117, 218, 51, 201, 166, 105, 152, 159, 74, 260, 80, 10, 43, 123, 145, 32, 99, 64, 87, 183, 86, 140, 122, 184, 160, 42, 150, 92, 225, 114, 250, 156, 11, 261, 161, 130, 63, 6, 182, 229, 253, 103, 126, 25, 44, 205, 108, 170, 34, 238, 54, 149, 135, 3, 47, 207, 222, 256, 252, 82, 29, 231, 75, 39, 73, 176, 61, 153, 134, 96, 179, 19, 241, 95, 237, 158, 263, 230, 69, 85, 23, 12, 211, 142, 33, 102, 213, 52, 257, 50, 115, 254, 235, 22, 91, 194, 28, 226, 215, 169, 212, 242, 189, 221, 71, 206, 188, 262, 133, 119, 181, 104, 55, 154, 94, 240, 36, 24, 5, 258, 113], 'val_indices': [196, 180, 178, 88, 234, 59, 72, 20, 111, 40, 203, 15, 45, 107, 198, 141, 248, 232, 168, 187, 239, 0, 251, 164, 245, 191, 202, 243, 93, 223, 157, 8, 67, 106, 244, 233, 199, 127, 144, 146, 78, 165, 84, 120, 155, 97, 77, 81, 62, 41, 35, 121, 200], 'accuracy': 0.5283018867924528, 'kappa': 0.05693950177935947, 'auc': 0.5740740740740741}, {'fold_index': 3, 'train_indices': [233, 115, 226, 98, 119, 218, 141, 189, 214, 198, 78, 130, 25, 10, 205, 219, 127, 48, 260, 44, 176, 192, 4, 19, 204, 6, 100, 166, 230, 147, 224, 220, 263, 137, 157, 79, 259, 159, 118, 81, 120, 106, 92, 12, 208, 90, 158, 101, 225, 181, 191, 169, 241, 180, 187, 152, 53, 82, 72, 184, 121, 135, 210, 207, 221, 240, 109, 162, 254, 143, 20, 160, 117, 94, 13, 257, 111, 182, 24, 179, 70, 197, 253, 75, 163, 114, 128, 108, 15, 8, 112, 193, 148, 245, 110, 49, 188, 228, 222, 80, 40, 41, 43, 42, 52, 242, 132, 140, 183, 244, 237, 64, 161, 261, 26, 47, 258, 178, 229, 36, 69, 215, 54, 113, 194, 149, 50, 31, 209, 212, 173, 139, 88, 200, 76, 55, 99, 133, 105, 97, 67, 77, 250, 201, 256, 186, 34, 185, 84, 145, 151, 68, 71, 61, 16, 195, 170, 144, 252, 213, 202, 46, 21, 93, 95, 246, 203, 231, 129, 28, 227, 45, 217, 38, 59, 190, 103, 107, 23, 83, 251, 22, 248, 104, 116, 172, 17, 243, 123, 91, 122, 126, 177, 223, 175, 57, 39, 33, 96, 87, 206, 146, 7, 136, 236, 249, 62, 138, 134, 89, 232], 'val_indices': [247, 168, 165, 74, 14, 27, 239, 196, 235, 125, 156, 63, 0, 56, 142, 5, 171, 35, 60, 11, 73, 153, 124, 154, 37, 66, 1, 216, 255, 65, 9, 86, 155, 18, 131, 85, 58, 29, 238, 199, 2, 30, 32, 262, 234, 51, 167, 3, 102, 174, 164, 211, 150], 'accuracy': 0.7735849056603774, 'kappa': 0.5470085470085471, 'auc': 0.8475783475783476}, {'fold_index': 4, 'train_indices': [69, 254, 3, 248, 142, 115, 116, 51, 39, 143, 48, 49, 228, 123, 104, 259, 226, 150, 208, 126, 242, 173, 238, 26, 19, 70, 103, 223, 159, 155, 33, 13, 138, 227, 110, 30, 99, 107, 149, 46, 247, 25, 156, 68, 111, 256, 131, 83, 161, 194, 0, 255, 62, 188, 121, 65, 225, 231, 151, 197, 54, 158, 89, 207, 236, 202, 20, 136, 125, 246, 187, 218, 147, 8, 7, 77, 160, 14, 214, 253, 171, 109, 130, 112, 71, 183, 185, 56, 196, 163, 34, 249, 105, 165, 135, 37, 15, 87, 38, 219, 153, 92, 117, 35, 137, 91, 154, 57, 235, 217, 244, 74, 212, 180, 240, 206, 189, 177, 97, 168, 61, 40, 1, 233, 258, 102, 101, 72, 44, 31, 95, 64, 215, 260, 94, 114, 133, 120, 118, 140, 58, 53, 166, 176, 220, 186, 41, 21, 106, 85, 178, 184, 230, 113, 232, 17, 205, 100, 152, 76, 86, 221, 60, 141, 251, 211, 6, 96, 18, 262, 193, 199, 245, 224, 237, 122, 234, 84, 261, 55, 222, 16, 81, 146, 42, 10, 191, 195, 124, 5, 190, 108, 78, 67, 4, 52, 45, 203, 9, 12, 157, 27, 181, 144, 198, 167, 210, 43, 241, 209, 128], 'val_indices': [213, 257, 29, 250, 98, 75, 175, 216, 59, 243, 127, 263, 179, 22, 63, 28, 170, 79, 66, 119, 93, 169, 134, 192, 36, 229, 73, 201, 90, 47, 132, 139, 145, 24, 129, 174, 23, 164, 252, 82, 148, 11, 162, 182, 80, 204, 88, 32, 2, 239, 172, 200, 50], 'accuracy': 0.6226415094339622, 'kappa': 0.24393723252496435, 'auc': 0.6623931623931625}], 'std_acc': 0.132, 'std_kappa': 0.265, 'std_auc': 0.121}\n",
      "sbj =  6\n",
      "Filtered from 219 trials to 113 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 215 trials to 108 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (221, 22, 448, 1), y_train shape: (221,)\n",
      "Running fold 0 with 176 training samples and 45 validation samples\n",
      "Fold 0: train indices: [ 30 209 146  27   1], val indices: [ 44  82  17 123 213]\n",
      "Training data shape: (176, 22, 448, 1), Validation data shape: (45, 22, 448, 1)\n",
      "Fold 0 training loss: 0.01334119401872158\n",
      "y_true (val): [0 0 1 0 1]\n",
      "y_pred: [1 1 1 0 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [30, 209, 146, 27, 1, 199, 196, 105, 116, 109, 133, 187, 163, 217, 25, 141, 208, 107, 159, 158, 128, 73, 122, 214, 85, 189, 204, 144, 53, 108, 165, 101, 65, 39, 84, 55, 198, 61, 69, 58, 42, 15, 20, 24, 32, 95, 43, 219, 29, 168, 206, 170, 113, 37, 132, 9, 115, 54, 5, 167, 66, 56, 47, 192, 120, 106, 151, 46, 138, 28, 102, 162, 119, 178, 127, 148, 88, 218, 174, 2, 91, 4, 50, 33, 201, 0, 11, 197, 179, 155, 57, 40, 68, 203, 64, 156, 62, 143, 220, 104, 184, 96, 48, 52, 86, 212, 111, 23, 193, 79, 78, 117, 169, 215, 173, 188, 8, 83, 205, 186, 153, 94, 200, 41, 51, 183, 89, 157, 131, 87, 80, 134, 191, 45, 93, 81, 154, 216, 18, 10, 126, 147, 139, 74, 13, 31, 118, 3, 72, 26, 142, 70, 114, 60, 211, 175, 152, 182, 76, 176, 135, 7, 207, 99, 130, 194, 75, 125, 190, 38, 63, 49, 34, 137, 124, 161], 'val_indices': [44, 82, 17, 123, 213, 164, 150, 100, 145, 177, 21, 92, 180, 185, 112, 202, 98, 77, 110, 121, 14, 171, 90, 210, 97, 149, 36, 6, 71, 19, 103, 35, 16, 140, 12, 195, 166, 136, 181, 172, 129, 59, 67, 22, 160], 'accuracy': 0.6666666666666666, 'kappa': 0.33366238894373157, 'auc': 0.6778656126482213}\n",
      "New Max Found!\n",
      "Running fold 1 with 176 training samples and 45 validation samples\n",
      "Fold 1: train indices: [ 99 107  73 213  20], val indices: [ 52 162 199 212 136]\n",
      "Training data shape: (176, 22, 448, 1), Validation data shape: (45, 22, 448, 1)\n",
      "Fold 1 training loss: 0.01760725863277912\n",
      "y_true (val): [1 1 0 1 0]\n",
      "y_pred: [1 0 1 1 0]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [99, 107, 73, 213, 20, 116, 83, 51, 69, 193, 7, 58, 139, 97, 191, 29, 170, 39, 217, 150, 160, 168, 113, 123, 70, 180, 134, 208, 62, 143, 171, 155, 185, 209, 12, 102, 38, 63, 45, 210, 174, 207, 6, 1, 135, 142, 19, 5, 87, 104, 65, 125, 95, 215, 114, 133, 132, 112, 183, 196, 35, 220, 211, 77, 3, 163, 198, 90, 94, 137, 121, 184, 126, 64, 56, 165, 118, 194, 103, 119, 173, 8, 41, 117, 34, 130, 89, 98, 32, 175, 82, 78, 80, 57, 218, 202, 154, 61, 158, 122, 204, 13, 131, 172, 2, 15, 55, 48, 23, 42, 18, 67, 96, 177, 140, 141, 0, 153, 14, 166, 146, 43, 105, 91, 106, 71, 176, 216, 147, 50, 206, 201, 93, 189, 92, 145, 192, 167, 68, 152, 219, 33, 120, 76, 17, 115, 108, 49, 66, 54, 203, 109, 81, 72, 188, 195, 169, 200, 4, 159, 179, 178, 157, 25, 59, 28, 205, 74, 27, 53, 10, 75, 86, 127, 9, 37], 'val_indices': [52, 162, 199, 212, 136, 16, 182, 197, 26, 85, 138, 214, 190, 110, 161, 11, 128, 164, 84, 101, 144, 124, 186, 44, 156, 149, 21, 148, 22, 24, 151, 88, 40, 46, 60, 36, 79, 100, 30, 111, 129, 187, 181, 47, 31], 'accuracy': 0.7111111111111111, 'kappa': 0.4202180376610505, 'auc': 0.8043478260869565}\n",
      "New Max Found!\n",
      "Running fold 2 with 176 training samples and 45 validation samples\n",
      "Fold 2: train indices: [178  81 126 211  20], val indices: [164  60 136 219 213]\n",
      "Training data shape: (176, 22, 448, 1), Validation data shape: (45, 22, 448, 1)\n",
      "Fold 2 training loss: 0.012909378856420517\n",
      "y_true (val): [0 0 0 1 1]\n",
      "y_pred: [0 0 0 1 0]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [178, 81, 126, 211, 20, 218, 32, 8, 38, 78, 128, 66, 99, 195, 73, 156, 188, 174, 110, 208, 82, 183, 44, 96, 134, 43, 63, 116, 86, 151, 49, 189, 33, 29, 102, 36, 107, 209, 162, 146, 153, 206, 80, 72, 26, 108, 157, 193, 3, 109, 52, 2, 205, 135, 40, 187, 23, 138, 74, 117, 92, 127, 140, 201, 45, 47, 55, 34, 56, 198, 150, 139, 13, 179, 17, 69, 95, 65, 172, 94, 85, 83, 75, 88, 11, 76, 71, 104, 111, 184, 125, 122, 143, 10, 142, 93, 214, 53, 200, 12, 15, 7, 42, 98, 51, 97, 141, 152, 39, 190, 57, 5, 87, 113, 129, 170, 177, 120, 165, 119, 31, 103, 124, 62, 37, 118, 77, 192, 54, 133, 101, 197, 114, 196, 182, 194, 217, 25, 41, 154, 89, 28, 4, 91, 67, 144, 24, 112, 159, 168, 64, 181, 137, 158, 149, 19, 202, 58, 171, 121, 1, 21, 145, 30, 173, 100, 16, 186, 48, 84, 131, 9, 105, 220, 0, 148], 'val_indices': [164, 60, 136, 219, 213, 207, 203, 106, 215, 166, 132, 163, 22, 18, 6, 204, 210, 79, 185, 180, 147, 212, 59, 130, 14, 161, 35, 169, 176, 90, 68, 61, 50, 123, 175, 46, 191, 155, 27, 115, 199, 70, 216, 160, 167], 'accuracy': 0.6888888888888889, 'kappa': 0.3774703557312252, 'auc': 0.7588932806324111}\n",
      "Running fold 3 with 176 training samples and 45 validation samples\n",
      "Fold 3: train indices: [217  12 192 124 122], val indices: [220   5 169 216 183]\n",
      "Training data shape: (176, 22, 448, 1), Validation data shape: (45, 22, 448, 1)\n",
      "Fold 3 training loss: 0.012903278693556786\n",
      "y_true (val): [1 0 0 1 0]\n",
      "y_pred: [1 0 1 1 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [217, 12, 192, 124, 122, 72, 14, 98, 114, 141, 153, 65, 45, 213, 36, 62, 21, 172, 190, 179, 123, 154, 56, 79, 87, 174, 22, 27, 184, 117, 158, 103, 42, 52, 61, 41, 202, 77, 10, 198, 194, 181, 188, 207, 59, 33, 116, 105, 23, 40, 63, 46, 30, 76, 100, 89, 15, 187, 49, 146, 108, 214, 82, 173, 189, 128, 91, 134, 130, 171, 215, 28, 3, 75, 186, 121, 58, 127, 191, 96, 159, 86, 168, 196, 83, 144, 47, 164, 38, 142, 0, 210, 135, 92, 20, 150, 161, 19, 109, 156, 212, 131, 208, 106, 39, 107, 112, 53, 97, 162, 7, 70, 35, 9, 160, 119, 209, 17, 67, 170, 139, 140, 151, 118, 13, 206, 167, 71, 64, 78, 44, 66, 18, 85, 11, 185, 219, 80, 147, 74, 4, 99, 16, 69, 94, 88, 155, 148, 93, 218, 145, 32, 149, 8, 102, 29, 1, 68, 204, 57, 132, 201, 175, 95, 152, 34, 138, 200, 54, 115, 176, 137, 166, 111, 6, 110], 'val_indices': [220, 5, 169, 216, 183, 129, 90, 136, 205, 25, 73, 81, 101, 50, 120, 51, 31, 24, 104, 182, 203, 197, 180, 199, 143, 211, 26, 43, 193, 177, 60, 195, 125, 126, 2, 55, 133, 157, 48, 84, 165, 178, 163, 113, 37], 'accuracy': 0.7111111111111111, 'kappa': 0.417910447761194, 'auc': 0.7707509881422925}\n",
      "Running fold 4 with 176 training samples and 45 validation samples\n",
      "Fold 4: train indices: [  6  60 206  58 171], val indices: [205 189  26  86  43]\n",
      "Training data shape: (176, 22, 448, 1), Validation data shape: (45, 22, 448, 1)\n",
      "Fold 4 training loss: 0.011973779648542404\n",
      "y_true (val): [0 0 0 1 0]\n",
      "y_pred: [1 1 0 0 1]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [6, 60, 206, 58, 171, 44, 92, 155, 49, 198, 32, 143, 9, 130, 128, 207, 19, 131, 200, 99, 84, 83, 23, 96, 169, 216, 151, 112, 17, 156, 27, 183, 67, 148, 121, 98, 81, 82, 2, 208, 163, 162, 213, 157, 133, 186, 71, 51, 175, 55, 173, 194, 193, 91, 147, 132, 30, 126, 123, 129, 145, 149, 197, 125, 167, 140, 14, 87, 103, 212, 38, 41, 166, 150, 90, 15, 7, 5, 209, 80, 25, 182, 77, 75, 217, 66, 42, 64, 138, 46, 94, 191, 178, 168, 65, 181, 88, 39, 78, 62, 69, 113, 104, 172, 134, 170, 37, 114, 89, 95, 215, 29, 142, 73, 210, 180, 68, 110, 146, 174, 204, 211, 117, 184, 28, 137, 40, 158, 56, 202, 50, 0, 76, 12, 115, 144, 152, 63, 196, 102, 139, 188, 10, 108, 219, 192, 85, 74, 109, 185, 101, 160, 214, 135, 111, 136, 13, 176, 161, 122, 203, 105, 36, 195, 61, 106, 97, 187, 141, 53, 48, 116, 22, 31, 120, 119], 'val_indices': [205, 189, 26, 86, 43, 124, 24, 220, 11, 1, 190, 93, 54, 127, 154, 118, 164, 179, 4, 107, 153, 52, 100, 70, 34, 8, 177, 3, 59, 201, 199, 33, 18, 218, 21, 35, 79, 165, 159, 45, 16, 20, 57, 72, 47], 'accuracy': 0.6, 'kappa': 0.19322709163346607, 'auc': 0.6067193675889329}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.676, 'mean_kappa': 0.348, 'mean_auc': 0.724, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [30, 209, 146, 27, 1, 199, 196, 105, 116, 109, 133, 187, 163, 217, 25, 141, 208, 107, 159, 158, 128, 73, 122, 214, 85, 189, 204, 144, 53, 108, 165, 101, 65, 39, 84, 55, 198, 61, 69, 58, 42, 15, 20, 24, 32, 95, 43, 219, 29, 168, 206, 170, 113, 37, 132, 9, 115, 54, 5, 167, 66, 56, 47, 192, 120, 106, 151, 46, 138, 28, 102, 162, 119, 178, 127, 148, 88, 218, 174, 2, 91, 4, 50, 33, 201, 0, 11, 197, 179, 155, 57, 40, 68, 203, 64, 156, 62, 143, 220, 104, 184, 96, 48, 52, 86, 212, 111, 23, 193, 79, 78, 117, 169, 215, 173, 188, 8, 83, 205, 186, 153, 94, 200, 41, 51, 183, 89, 157, 131, 87, 80, 134, 191, 45, 93, 81, 154, 216, 18, 10, 126, 147, 139, 74, 13, 31, 118, 3, 72, 26, 142, 70, 114, 60, 211, 175, 152, 182, 76, 176, 135, 7, 207, 99, 130, 194, 75, 125, 190, 38, 63, 49, 34, 137, 124, 161], 'val_indices': [44, 82, 17, 123, 213, 164, 150, 100, 145, 177, 21, 92, 180, 185, 112, 202, 98, 77, 110, 121, 14, 171, 90, 210, 97, 149, 36, 6, 71, 19, 103, 35, 16, 140, 12, 195, 166, 136, 181, 172, 129, 59, 67, 22, 160], 'accuracy': 0.6666666666666666, 'kappa': 0.33366238894373157, 'auc': 0.6778656126482213}, {'fold_index': 1, 'train_indices': [99, 107, 73, 213, 20, 116, 83, 51, 69, 193, 7, 58, 139, 97, 191, 29, 170, 39, 217, 150, 160, 168, 113, 123, 70, 180, 134, 208, 62, 143, 171, 155, 185, 209, 12, 102, 38, 63, 45, 210, 174, 207, 6, 1, 135, 142, 19, 5, 87, 104, 65, 125, 95, 215, 114, 133, 132, 112, 183, 196, 35, 220, 211, 77, 3, 163, 198, 90, 94, 137, 121, 184, 126, 64, 56, 165, 118, 194, 103, 119, 173, 8, 41, 117, 34, 130, 89, 98, 32, 175, 82, 78, 80, 57, 218, 202, 154, 61, 158, 122, 204, 13, 131, 172, 2, 15, 55, 48, 23, 42, 18, 67, 96, 177, 140, 141, 0, 153, 14, 166, 146, 43, 105, 91, 106, 71, 176, 216, 147, 50, 206, 201, 93, 189, 92, 145, 192, 167, 68, 152, 219, 33, 120, 76, 17, 115, 108, 49, 66, 54, 203, 109, 81, 72, 188, 195, 169, 200, 4, 159, 179, 178, 157, 25, 59, 28, 205, 74, 27, 53, 10, 75, 86, 127, 9, 37], 'val_indices': [52, 162, 199, 212, 136, 16, 182, 197, 26, 85, 138, 214, 190, 110, 161, 11, 128, 164, 84, 101, 144, 124, 186, 44, 156, 149, 21, 148, 22, 24, 151, 88, 40, 46, 60, 36, 79, 100, 30, 111, 129, 187, 181, 47, 31], 'accuracy': 0.7111111111111111, 'kappa': 0.4202180376610505, 'auc': 0.8043478260869565}, {'fold_index': 2, 'train_indices': [178, 81, 126, 211, 20, 218, 32, 8, 38, 78, 128, 66, 99, 195, 73, 156, 188, 174, 110, 208, 82, 183, 44, 96, 134, 43, 63, 116, 86, 151, 49, 189, 33, 29, 102, 36, 107, 209, 162, 146, 153, 206, 80, 72, 26, 108, 157, 193, 3, 109, 52, 2, 205, 135, 40, 187, 23, 138, 74, 117, 92, 127, 140, 201, 45, 47, 55, 34, 56, 198, 150, 139, 13, 179, 17, 69, 95, 65, 172, 94, 85, 83, 75, 88, 11, 76, 71, 104, 111, 184, 125, 122, 143, 10, 142, 93, 214, 53, 200, 12, 15, 7, 42, 98, 51, 97, 141, 152, 39, 190, 57, 5, 87, 113, 129, 170, 177, 120, 165, 119, 31, 103, 124, 62, 37, 118, 77, 192, 54, 133, 101, 197, 114, 196, 182, 194, 217, 25, 41, 154, 89, 28, 4, 91, 67, 144, 24, 112, 159, 168, 64, 181, 137, 158, 149, 19, 202, 58, 171, 121, 1, 21, 145, 30, 173, 100, 16, 186, 48, 84, 131, 9, 105, 220, 0, 148], 'val_indices': [164, 60, 136, 219, 213, 207, 203, 106, 215, 166, 132, 163, 22, 18, 6, 204, 210, 79, 185, 180, 147, 212, 59, 130, 14, 161, 35, 169, 176, 90, 68, 61, 50, 123, 175, 46, 191, 155, 27, 115, 199, 70, 216, 160, 167], 'accuracy': 0.6888888888888889, 'kappa': 0.3774703557312252, 'auc': 0.7588932806324111}, {'fold_index': 3, 'train_indices': [217, 12, 192, 124, 122, 72, 14, 98, 114, 141, 153, 65, 45, 213, 36, 62, 21, 172, 190, 179, 123, 154, 56, 79, 87, 174, 22, 27, 184, 117, 158, 103, 42, 52, 61, 41, 202, 77, 10, 198, 194, 181, 188, 207, 59, 33, 116, 105, 23, 40, 63, 46, 30, 76, 100, 89, 15, 187, 49, 146, 108, 214, 82, 173, 189, 128, 91, 134, 130, 171, 215, 28, 3, 75, 186, 121, 58, 127, 191, 96, 159, 86, 168, 196, 83, 144, 47, 164, 38, 142, 0, 210, 135, 92, 20, 150, 161, 19, 109, 156, 212, 131, 208, 106, 39, 107, 112, 53, 97, 162, 7, 70, 35, 9, 160, 119, 209, 17, 67, 170, 139, 140, 151, 118, 13, 206, 167, 71, 64, 78, 44, 66, 18, 85, 11, 185, 219, 80, 147, 74, 4, 99, 16, 69, 94, 88, 155, 148, 93, 218, 145, 32, 149, 8, 102, 29, 1, 68, 204, 57, 132, 201, 175, 95, 152, 34, 138, 200, 54, 115, 176, 137, 166, 111, 6, 110], 'val_indices': [220, 5, 169, 216, 183, 129, 90, 136, 205, 25, 73, 81, 101, 50, 120, 51, 31, 24, 104, 182, 203, 197, 180, 199, 143, 211, 26, 43, 193, 177, 60, 195, 125, 126, 2, 55, 133, 157, 48, 84, 165, 178, 163, 113, 37], 'accuracy': 0.7111111111111111, 'kappa': 0.417910447761194, 'auc': 0.7707509881422925}, {'fold_index': 4, 'train_indices': [6, 60, 206, 58, 171, 44, 92, 155, 49, 198, 32, 143, 9, 130, 128, 207, 19, 131, 200, 99, 84, 83, 23, 96, 169, 216, 151, 112, 17, 156, 27, 183, 67, 148, 121, 98, 81, 82, 2, 208, 163, 162, 213, 157, 133, 186, 71, 51, 175, 55, 173, 194, 193, 91, 147, 132, 30, 126, 123, 129, 145, 149, 197, 125, 167, 140, 14, 87, 103, 212, 38, 41, 166, 150, 90, 15, 7, 5, 209, 80, 25, 182, 77, 75, 217, 66, 42, 64, 138, 46, 94, 191, 178, 168, 65, 181, 88, 39, 78, 62, 69, 113, 104, 172, 134, 170, 37, 114, 89, 95, 215, 29, 142, 73, 210, 180, 68, 110, 146, 174, 204, 211, 117, 184, 28, 137, 40, 158, 56, 202, 50, 0, 76, 12, 115, 144, 152, 63, 196, 102, 139, 188, 10, 108, 219, 192, 85, 74, 109, 185, 101, 160, 214, 135, 111, 136, 13, 176, 161, 122, 203, 105, 36, 195, 61, 106, 97, 187, 141, 53, 48, 116, 22, 31, 120, 119], 'val_indices': [205, 189, 26, 86, 43, 124, 24, 220, 11, 1, 190, 93, 54, 127, 154, 118, 164, 179, 4, 107, 153, 52, 100, 70, 34, 8, 177, 3, 59, 201, 199, 33, 18, 218, 21, 35, 79, 165, 159, 45, 16, 20, 57, 72, 47], 'accuracy': 0.6, 'kappa': 0.19322709163346607, 'auc': 0.6067193675889329}], 'std_acc': 0.041, 'std_kappa': 0.084, 'std_auc': 0.072}\n",
      "sbj =  7\n",
      "Filtered from 271 trials to 133 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 277 trials to 140 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (273, 22, 448, 1), y_train shape: (273,)\n",
      "Running fold 0 with 218 training samples and 55 validation samples\n",
      "Fold 0: train indices: [222  87  24  81  62], val indices: [129 118 126  64  23]\n",
      "Training data shape: (218, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 0 training loss: 0.009808117523789406\n",
      "y_true (val): [1 0 1 1 0]\n",
      "y_pred: [1 0 1 1 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [222, 87, 24, 81, 62, 67, 199, 206, 209, 80, 234, 262, 8, 16, 84, 174, 12, 0, 98, 125, 159, 54, 138, 137, 224, 263, 266, 250, 223, 99, 230, 128, 93, 155, 5, 75, 148, 13, 97, 7, 59, 211, 173, 94, 20, 257, 19, 4, 241, 57, 9, 153, 60, 122, 61, 152, 107, 106, 22, 51, 197, 101, 28, 18, 253, 40, 156, 114, 260, 165, 205, 264, 123, 269, 82, 193, 184, 83, 132, 31, 119, 102, 130, 217, 183, 145, 186, 142, 194, 90, 27, 35, 233, 221, 188, 38, 239, 189, 71, 158, 245, 240, 124, 58, 11, 212, 259, 63, 160, 103, 207, 76, 52, 133, 55, 226, 244, 229, 86, 231, 154, 177, 254, 140, 144, 47, 201, 225, 271, 227, 121, 265, 134, 49, 45, 37, 246, 203, 192, 150, 34, 39, 238, 79, 33, 200, 198, 3, 247, 70, 65, 78, 214, 117, 68, 187, 42, 190, 172, 48, 236, 191, 261, 1, 166, 115, 29, 110, 196, 208, 272, 136, 170, 195, 270, 143, 164, 147, 69, 219, 146, 210, 109, 46, 95, 89, 131, 242, 112, 258, 232, 151, 139, 85, 228, 237, 213, 10, 41, 215, 182, 50, 77, 204, 251, 185, 249, 167, 88, 162, 268, 43, 2, 36, 17, 96, 105, 25], 'val_indices': [129, 118, 126, 64, 23, 100, 161, 104, 6, 108, 175, 171, 44, 178, 111, 248, 30, 91, 252, 15, 168, 116, 163, 181, 14, 74, 113, 267, 53, 149, 73, 235, 157, 220, 21, 141, 216, 179, 176, 243, 256, 202, 218, 66, 169, 120, 127, 72, 255, 56, 180, 26, 135, 32, 92], 'accuracy': 0.9090909090909091, 'kappa': 0.8182419035029742, 'auc': 0.962962962962963}\n",
      "New Max Found!\n",
      "Running fold 1 with 218 training samples and 55 validation samples\n",
      "Fold 1: train indices: [  1 224  78 203 111], val indices: [109 268  61 101  80]\n",
      "Training data shape: (218, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 1 training loss: 0.013071428053081036\n",
      "y_true (val): [0 1 1 1 1]\n",
      "y_pred: [0 1 1 1 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [1, 224, 78, 203, 111, 155, 186, 164, 90, 22, 175, 87, 86, 16, 108, 116, 238, 122, 31, 264, 199, 200, 135, 228, 56, 113, 73, 221, 62, 20, 232, 217, 157, 102, 211, 141, 156, 129, 118, 251, 99, 0, 248, 267, 144, 255, 225, 24, 76, 11, 29, 198, 44, 66, 79, 191, 106, 179, 170, 167, 128, 261, 256, 37, 172, 52, 91, 41, 185, 48, 181, 173, 213, 35, 28, 190, 176, 59, 40, 75, 165, 257, 105, 195, 262, 67, 15, 151, 55, 57, 263, 270, 103, 19, 183, 134, 250, 146, 171, 121, 205, 42, 271, 70, 30, 54, 14, 58, 127, 212, 26, 63, 136, 143, 196, 188, 140, 45, 247, 253, 82, 139, 158, 204, 34, 260, 119, 10, 125, 163, 174, 239, 147, 123, 230, 272, 51, 229, 49, 96, 3, 114, 150, 47, 137, 252, 133, 85, 209, 126, 180, 98, 104, 219, 178, 68, 214, 17, 25, 233, 32, 88, 132, 159, 6, 36, 192, 222, 168, 153, 227, 130, 241, 269, 21, 201, 94, 206, 117, 245, 154, 124, 7, 46, 234, 160, 152, 5, 13, 43, 131, 110, 189, 259, 220, 12, 77, 208, 71, 74, 166, 33, 266, 53, 149, 120, 100, 210, 215, 97, 162, 243, 81, 207, 246, 18, 138, 115], 'val_indices': [109, 268, 61, 101, 80, 265, 231, 216, 202, 107, 236, 4, 27, 177, 142, 65, 240, 249, 226, 184, 72, 237, 148, 50, 161, 9, 242, 92, 83, 8, 182, 223, 187, 218, 84, 112, 69, 193, 244, 254, 197, 39, 194, 60, 23, 235, 38, 93, 64, 169, 89, 145, 2, 95, 258], 'accuracy': 0.9636363636363636, 'kappa': 0.9272486772486772, 'auc': 0.9828042328042328}\n",
      "New Max Found!\n",
      "Running fold 2 with 218 training samples and 55 validation samples\n",
      "Fold 2: train indices: [207  66 128  65 239], val indices: [100 114   3 147  82]\n",
      "Training data shape: (218, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 2 training loss: 0.00575738400220871\n",
      "y_true (val): [1 0 0 1 1]\n",
      "y_pred: [1 0 1 1 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [207, 66, 128, 65, 239, 168, 123, 144, 72, 104, 89, 251, 174, 182, 143, 90, 186, 265, 52, 257, 215, 268, 163, 197, 230, 136, 241, 27, 74, 30, 233, 73, 21, 25, 37, 81, 105, 92, 155, 71, 181, 219, 222, 183, 54, 212, 252, 117, 195, 152, 156, 200, 272, 141, 267, 108, 258, 248, 93, 176, 243, 97, 40, 242, 60, 85, 247, 69, 262, 76, 86, 261, 47, 269, 61, 146, 237, 221, 36, 180, 250, 6, 113, 58, 64, 78, 202, 142, 17, 1, 51, 59, 23, 120, 211, 216, 95, 238, 159, 10, 98, 131, 227, 210, 7, 217, 46, 175, 179, 214, 31, 137, 130, 148, 229, 138, 41, 162, 18, 22, 203, 189, 205, 91, 9, 127, 84, 15, 112, 187, 224, 266, 39, 151, 129, 87, 119, 80, 0, 49, 45, 158, 110, 121, 161, 260, 57, 228, 55, 109, 28, 177, 157, 67, 191, 101, 167, 199, 99, 63, 154, 264, 16, 13, 145, 29, 133, 218, 164, 48, 153, 34, 271, 150, 125, 190, 188, 70, 226, 56, 172, 42, 263, 75, 204, 38, 132, 149, 194, 249, 94, 256, 246, 5, 208, 231, 44, 26, 206, 20, 4, 254, 171, 12, 139, 79, 220, 103, 24, 234, 235, 68, 165, 160, 14, 124, 170, 11], 'val_indices': [100, 114, 3, 147, 82, 198, 240, 225, 111, 106, 196, 116, 19, 77, 192, 107, 232, 88, 185, 213, 43, 166, 35, 2, 118, 115, 96, 209, 253, 83, 223, 201, 193, 169, 173, 122, 33, 236, 255, 53, 126, 62, 134, 102, 259, 140, 50, 244, 32, 135, 184, 178, 8, 270, 245], 'accuracy': 0.9636363636363636, 'kappa': 0.9273447820343461, 'auc': 1.0}\n",
      "Running fold 3 with 218 training samples and 55 validation samples\n",
      "Fold 3: train indices: [252 150  66   5 259], val indices: [ 92 241  45  20  73]\n",
      "Training data shape: (218, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 3 training loss: 0.005710323341190815\n",
      "y_true (val): [0 1 0 1 0]\n",
      "y_pred: [0 1 0 0 0]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [252, 150, 66, 5, 259, 87, 267, 160, 28, 72, 170, 117, 189, 52, 244, 214, 79, 44, 17, 112, 238, 175, 148, 256, 57, 10, 258, 51, 2, 171, 26, 146, 76, 185, 118, 177, 219, 272, 164, 97, 108, 202, 122, 199, 77, 30, 243, 223, 124, 47, 190, 262, 149, 188, 43, 120, 235, 46, 197, 42, 70, 19, 209, 194, 184, 27, 11, 249, 38, 129, 141, 231, 104, 50, 81, 137, 99, 109, 119, 135, 31, 187, 144, 156, 84, 61, 268, 140, 56, 165, 6, 90, 8, 195, 253, 143, 48, 67, 12, 64, 89, 107, 113, 3, 161, 88, 200, 82, 225, 114, 126, 138, 65, 132, 152, 115, 59, 25, 229, 139, 145, 98, 53, 103, 204, 32, 14, 247, 215, 222, 196, 54, 218, 21, 29, 169, 24, 207, 94, 7, 220, 255, 173, 172, 133, 159, 157, 71, 16, 123, 228, 180, 58, 23, 41, 198, 192, 239, 105, 49, 121, 186, 34, 39, 212, 226, 74, 236, 191, 230, 127, 205, 110, 261, 142, 151, 251, 0, 63, 166, 240, 13, 40, 217, 265, 95, 153, 193, 254, 155, 201, 264, 134, 242, 183, 245, 158, 100, 83, 106, 35, 154, 69, 203, 179, 22, 101, 271, 4, 213, 9, 60, 208, 33, 246, 270, 224, 232], 'val_indices': [92, 241, 45, 20, 73, 1, 163, 250, 233, 237, 263, 125, 178, 80, 96, 136, 18, 91, 85, 227, 168, 116, 62, 221, 93, 75, 181, 68, 147, 102, 248, 162, 128, 78, 206, 111, 86, 176, 55, 216, 15, 266, 269, 257, 260, 210, 131, 182, 130, 211, 174, 37, 36, 167, 234], 'accuracy': 0.8727272727272727, 'kappa': 0.7452018530774321, 'auc': 0.9298941798941798}\n",
      "Running fold 4 with 218 training samples and 55 validation samples\n",
      "Fold 4: train indices: [ 86 218 117 120 239], val indices: [187 189  25  73 233]\n",
      "Training data shape: (218, 22, 448, 1), Validation data shape: (55, 22, 448, 1)\n",
      "Fold 4 training loss: 0.010460318997502327\n",
      "y_true (val): [0 0 0 0 0]\n",
      "y_pred: [0 0 1 0 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [86, 218, 117, 120, 239, 207, 74, 3, 137, 145, 42, 243, 128, 113, 252, 119, 244, 245, 52, 23, 53, 150, 34, 213, 188, 62, 48, 103, 193, 265, 209, 126, 181, 254, 122, 160, 182, 132, 24, 131, 216, 11, 115, 88, 217, 234, 69, 139, 51, 77, 58, 220, 82, 194, 143, 49, 232, 212, 255, 228, 93, 71, 190, 157, 174, 167, 191, 258, 158, 95, 272, 149, 169, 178, 60, 22, 40, 118, 215, 222, 9, 92, 177, 35, 99, 19, 114, 204, 260, 226, 67, 203, 196, 241, 61, 267, 192, 198, 156, 231, 7, 199, 72, 146, 180, 175, 133, 240, 85, 263, 248, 104, 29, 223, 65, 253, 87, 205, 134, 130, 144, 102, 214, 153, 116, 8, 36, 236, 0, 106, 68, 202, 70, 140, 12, 161, 109, 251, 225, 50, 210, 136, 159, 155, 142, 148, 183, 219, 224, 56, 271, 27, 47, 270, 147, 90, 162, 32, 81, 14, 18, 168, 230, 173, 171, 166, 94, 89, 246, 16, 101, 5, 26, 259, 75, 91, 123, 152, 110, 151, 30, 176, 107, 242, 38, 257, 129, 96, 28, 76, 55, 63, 200, 154, 266, 108, 17, 179, 64, 43, 10, 141, 135, 80, 211, 221, 163, 165, 268, 21, 97, 1, 247, 121, 197, 262, 138, 2], 'val_indices': [187, 189, 25, 73, 233, 170, 186, 238, 125, 44, 78, 124, 201, 185, 57, 41, 105, 13, 237, 54, 261, 33, 111, 269, 20, 66, 15, 39, 6, 46, 249, 264, 84, 206, 79, 195, 208, 235, 184, 229, 45, 256, 127, 172, 59, 4, 164, 98, 112, 37, 31, 100, 227, 250, 83], 'accuracy': 0.8909090909090909, 'kappa': 0.7817460317460317, 'auc': 0.9404761904761905}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.92, 'mean_kappa': 0.84, 'mean_auc': 0.963, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [222, 87, 24, 81, 62, 67, 199, 206, 209, 80, 234, 262, 8, 16, 84, 174, 12, 0, 98, 125, 159, 54, 138, 137, 224, 263, 266, 250, 223, 99, 230, 128, 93, 155, 5, 75, 148, 13, 97, 7, 59, 211, 173, 94, 20, 257, 19, 4, 241, 57, 9, 153, 60, 122, 61, 152, 107, 106, 22, 51, 197, 101, 28, 18, 253, 40, 156, 114, 260, 165, 205, 264, 123, 269, 82, 193, 184, 83, 132, 31, 119, 102, 130, 217, 183, 145, 186, 142, 194, 90, 27, 35, 233, 221, 188, 38, 239, 189, 71, 158, 245, 240, 124, 58, 11, 212, 259, 63, 160, 103, 207, 76, 52, 133, 55, 226, 244, 229, 86, 231, 154, 177, 254, 140, 144, 47, 201, 225, 271, 227, 121, 265, 134, 49, 45, 37, 246, 203, 192, 150, 34, 39, 238, 79, 33, 200, 198, 3, 247, 70, 65, 78, 214, 117, 68, 187, 42, 190, 172, 48, 236, 191, 261, 1, 166, 115, 29, 110, 196, 208, 272, 136, 170, 195, 270, 143, 164, 147, 69, 219, 146, 210, 109, 46, 95, 89, 131, 242, 112, 258, 232, 151, 139, 85, 228, 237, 213, 10, 41, 215, 182, 50, 77, 204, 251, 185, 249, 167, 88, 162, 268, 43, 2, 36, 17, 96, 105, 25], 'val_indices': [129, 118, 126, 64, 23, 100, 161, 104, 6, 108, 175, 171, 44, 178, 111, 248, 30, 91, 252, 15, 168, 116, 163, 181, 14, 74, 113, 267, 53, 149, 73, 235, 157, 220, 21, 141, 216, 179, 176, 243, 256, 202, 218, 66, 169, 120, 127, 72, 255, 56, 180, 26, 135, 32, 92], 'accuracy': 0.9090909090909091, 'kappa': 0.8182419035029742, 'auc': 0.962962962962963}, {'fold_index': 1, 'train_indices': [1, 224, 78, 203, 111, 155, 186, 164, 90, 22, 175, 87, 86, 16, 108, 116, 238, 122, 31, 264, 199, 200, 135, 228, 56, 113, 73, 221, 62, 20, 232, 217, 157, 102, 211, 141, 156, 129, 118, 251, 99, 0, 248, 267, 144, 255, 225, 24, 76, 11, 29, 198, 44, 66, 79, 191, 106, 179, 170, 167, 128, 261, 256, 37, 172, 52, 91, 41, 185, 48, 181, 173, 213, 35, 28, 190, 176, 59, 40, 75, 165, 257, 105, 195, 262, 67, 15, 151, 55, 57, 263, 270, 103, 19, 183, 134, 250, 146, 171, 121, 205, 42, 271, 70, 30, 54, 14, 58, 127, 212, 26, 63, 136, 143, 196, 188, 140, 45, 247, 253, 82, 139, 158, 204, 34, 260, 119, 10, 125, 163, 174, 239, 147, 123, 230, 272, 51, 229, 49, 96, 3, 114, 150, 47, 137, 252, 133, 85, 209, 126, 180, 98, 104, 219, 178, 68, 214, 17, 25, 233, 32, 88, 132, 159, 6, 36, 192, 222, 168, 153, 227, 130, 241, 269, 21, 201, 94, 206, 117, 245, 154, 124, 7, 46, 234, 160, 152, 5, 13, 43, 131, 110, 189, 259, 220, 12, 77, 208, 71, 74, 166, 33, 266, 53, 149, 120, 100, 210, 215, 97, 162, 243, 81, 207, 246, 18, 138, 115], 'val_indices': [109, 268, 61, 101, 80, 265, 231, 216, 202, 107, 236, 4, 27, 177, 142, 65, 240, 249, 226, 184, 72, 237, 148, 50, 161, 9, 242, 92, 83, 8, 182, 223, 187, 218, 84, 112, 69, 193, 244, 254, 197, 39, 194, 60, 23, 235, 38, 93, 64, 169, 89, 145, 2, 95, 258], 'accuracy': 0.9636363636363636, 'kappa': 0.9272486772486772, 'auc': 0.9828042328042328}, {'fold_index': 2, 'train_indices': [207, 66, 128, 65, 239, 168, 123, 144, 72, 104, 89, 251, 174, 182, 143, 90, 186, 265, 52, 257, 215, 268, 163, 197, 230, 136, 241, 27, 74, 30, 233, 73, 21, 25, 37, 81, 105, 92, 155, 71, 181, 219, 222, 183, 54, 212, 252, 117, 195, 152, 156, 200, 272, 141, 267, 108, 258, 248, 93, 176, 243, 97, 40, 242, 60, 85, 247, 69, 262, 76, 86, 261, 47, 269, 61, 146, 237, 221, 36, 180, 250, 6, 113, 58, 64, 78, 202, 142, 17, 1, 51, 59, 23, 120, 211, 216, 95, 238, 159, 10, 98, 131, 227, 210, 7, 217, 46, 175, 179, 214, 31, 137, 130, 148, 229, 138, 41, 162, 18, 22, 203, 189, 205, 91, 9, 127, 84, 15, 112, 187, 224, 266, 39, 151, 129, 87, 119, 80, 0, 49, 45, 158, 110, 121, 161, 260, 57, 228, 55, 109, 28, 177, 157, 67, 191, 101, 167, 199, 99, 63, 154, 264, 16, 13, 145, 29, 133, 218, 164, 48, 153, 34, 271, 150, 125, 190, 188, 70, 226, 56, 172, 42, 263, 75, 204, 38, 132, 149, 194, 249, 94, 256, 246, 5, 208, 231, 44, 26, 206, 20, 4, 254, 171, 12, 139, 79, 220, 103, 24, 234, 235, 68, 165, 160, 14, 124, 170, 11], 'val_indices': [100, 114, 3, 147, 82, 198, 240, 225, 111, 106, 196, 116, 19, 77, 192, 107, 232, 88, 185, 213, 43, 166, 35, 2, 118, 115, 96, 209, 253, 83, 223, 201, 193, 169, 173, 122, 33, 236, 255, 53, 126, 62, 134, 102, 259, 140, 50, 244, 32, 135, 184, 178, 8, 270, 245], 'accuracy': 0.9636363636363636, 'kappa': 0.9273447820343461, 'auc': 1.0}, {'fold_index': 3, 'train_indices': [252, 150, 66, 5, 259, 87, 267, 160, 28, 72, 170, 117, 189, 52, 244, 214, 79, 44, 17, 112, 238, 175, 148, 256, 57, 10, 258, 51, 2, 171, 26, 146, 76, 185, 118, 177, 219, 272, 164, 97, 108, 202, 122, 199, 77, 30, 243, 223, 124, 47, 190, 262, 149, 188, 43, 120, 235, 46, 197, 42, 70, 19, 209, 194, 184, 27, 11, 249, 38, 129, 141, 231, 104, 50, 81, 137, 99, 109, 119, 135, 31, 187, 144, 156, 84, 61, 268, 140, 56, 165, 6, 90, 8, 195, 253, 143, 48, 67, 12, 64, 89, 107, 113, 3, 161, 88, 200, 82, 225, 114, 126, 138, 65, 132, 152, 115, 59, 25, 229, 139, 145, 98, 53, 103, 204, 32, 14, 247, 215, 222, 196, 54, 218, 21, 29, 169, 24, 207, 94, 7, 220, 255, 173, 172, 133, 159, 157, 71, 16, 123, 228, 180, 58, 23, 41, 198, 192, 239, 105, 49, 121, 186, 34, 39, 212, 226, 74, 236, 191, 230, 127, 205, 110, 261, 142, 151, 251, 0, 63, 166, 240, 13, 40, 217, 265, 95, 153, 193, 254, 155, 201, 264, 134, 242, 183, 245, 158, 100, 83, 106, 35, 154, 69, 203, 179, 22, 101, 271, 4, 213, 9, 60, 208, 33, 246, 270, 224, 232], 'val_indices': [92, 241, 45, 20, 73, 1, 163, 250, 233, 237, 263, 125, 178, 80, 96, 136, 18, 91, 85, 227, 168, 116, 62, 221, 93, 75, 181, 68, 147, 102, 248, 162, 128, 78, 206, 111, 86, 176, 55, 216, 15, 266, 269, 257, 260, 210, 131, 182, 130, 211, 174, 37, 36, 167, 234], 'accuracy': 0.8727272727272727, 'kappa': 0.7452018530774321, 'auc': 0.9298941798941798}, {'fold_index': 4, 'train_indices': [86, 218, 117, 120, 239, 207, 74, 3, 137, 145, 42, 243, 128, 113, 252, 119, 244, 245, 52, 23, 53, 150, 34, 213, 188, 62, 48, 103, 193, 265, 209, 126, 181, 254, 122, 160, 182, 132, 24, 131, 216, 11, 115, 88, 217, 234, 69, 139, 51, 77, 58, 220, 82, 194, 143, 49, 232, 212, 255, 228, 93, 71, 190, 157, 174, 167, 191, 258, 158, 95, 272, 149, 169, 178, 60, 22, 40, 118, 215, 222, 9, 92, 177, 35, 99, 19, 114, 204, 260, 226, 67, 203, 196, 241, 61, 267, 192, 198, 156, 231, 7, 199, 72, 146, 180, 175, 133, 240, 85, 263, 248, 104, 29, 223, 65, 253, 87, 205, 134, 130, 144, 102, 214, 153, 116, 8, 36, 236, 0, 106, 68, 202, 70, 140, 12, 161, 109, 251, 225, 50, 210, 136, 159, 155, 142, 148, 183, 219, 224, 56, 271, 27, 47, 270, 147, 90, 162, 32, 81, 14, 18, 168, 230, 173, 171, 166, 94, 89, 246, 16, 101, 5, 26, 259, 75, 91, 123, 152, 110, 151, 30, 176, 107, 242, 38, 257, 129, 96, 28, 76, 55, 63, 200, 154, 266, 108, 17, 179, 64, 43, 10, 141, 135, 80, 211, 221, 163, 165, 268, 21, 97, 1, 247, 121, 197, 262, 138, 2], 'val_indices': [187, 189, 25, 73, 233, 170, 186, 238, 125, 44, 78, 124, 201, 185, 57, 41, 105, 13, 237, 54, 261, 33, 111, 269, 20, 66, 15, 39, 6, 46, 249, 264, 84, 206, 79, 195, 208, 235, 184, 229, 45, 256, 127, 172, 59, 4, 164, 98, 112, 37, 31, 100, 227, 250, 83], 'accuracy': 0.8909090909090909, 'kappa': 0.7817460317460317, 'auc': 0.9404761904761905}], 'std_acc': 0.037, 'std_kappa': 0.075, 'std_auc': 0.026}\n",
      "sbj =  8\n",
      "Filtered from 264 trials to 132 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 271 trials to 134 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (266, 22, 448, 1), y_train shape: (266,)\n",
      "Running fold 0 with 212 training samples and 54 validation samples\n",
      "Fold 0: train indices: [113  90  13  10 187], val indices: [241  14 177 143  71]\n",
      "Training data shape: (212, 22, 448, 1), Validation data shape: (54, 22, 448, 1)\n",
      "Fold 0 training loss: 0.0031574061140418053\n",
      "y_true (val): [1 1 1 1 0]\n",
      "y_pred: [1 1 1 1 1]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [113, 90, 13, 10, 187, 185, 137, 12, 60, 171, 237, 244, 77, 216, 102, 32, 22, 254, 110, 50, 239, 121, 249, 206, 70, 165, 105, 93, 172, 7, 256, 80, 109, 229, 240, 24, 66, 5, 144, 116, 139, 123, 97, 265, 58, 154, 45, 194, 124, 35, 19, 223, 106, 168, 199, 210, 221, 214, 69, 79, 178, 18, 209, 260, 54, 128, 31, 1, 48, 17, 198, 164, 37, 227, 242, 38, 27, 251, 83, 175, 259, 134, 34, 245, 235, 75, 155, 49, 258, 115, 158, 41, 76, 211, 140, 247, 56, 16, 146, 85, 184, 248, 78, 138, 225, 9, 205, 36, 25, 150, 0, 212, 202, 82, 201, 43, 86, 111, 120, 218, 40, 195, 59, 81, 108, 219, 182, 74, 162, 26, 101, 98, 152, 252, 42, 20, 151, 122, 57, 232, 130, 3, 145, 224, 127, 243, 95, 228, 203, 204, 220, 96, 53, 188, 183, 230, 262, 191, 142, 160, 2, 255, 246, 181, 64, 153, 61, 170, 118, 114, 193, 222, 62, 189, 23, 87, 11, 207, 131, 197, 68, 67, 89, 39, 4, 136, 253, 47, 166, 84, 233, 159, 186, 149, 148, 44, 51, 231, 226, 133, 8, 238, 208, 263, 192, 29, 104, 156, 264, 33, 196, 100], 'val_indices': [241, 14, 177, 143, 71, 200, 107, 179, 157, 15, 250, 72, 103, 52, 141, 163, 73, 92, 94, 129, 63, 112, 176, 126, 161, 119, 30, 55, 261, 236, 46, 234, 21, 28, 213, 117, 147, 88, 174, 180, 91, 167, 65, 132, 135, 169, 190, 6, 99, 173, 217, 257, 125, 215], 'accuracy': 0.9074074074074074, 'kappa': 0.8148148148148149, 'auc': 0.9903978052126201}\n",
      "New Max Found!\n",
      "Running fold 1 with 212 training samples and 54 validation samples\n",
      "Fold 1: train indices: [102 149 115 152 196], val indices: [ 79 129 116 208 212]\n",
      "Training data shape: (212, 22, 448, 1), Validation data shape: (54, 22, 448, 1)\n",
      "Fold 1 training loss: 0.0020725741051137447\n",
      "y_true (val): [1 1 0 0 1]\n",
      "y_pred: [0 1 1 0 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [102, 149, 115, 152, 196, 44, 76, 101, 13, 66, 53, 187, 139, 24, 182, 130, 70, 33, 3, 61, 252, 257, 217, 224, 154, 8, 100, 177, 137, 27, 122, 98, 43, 73, 188, 172, 222, 35, 85, 65, 167, 213, 90, 50, 243, 69, 190, 263, 221, 193, 30, 251, 189, 106, 55, 165, 145, 229, 82, 146, 103, 20, 169, 223, 6, 114, 39, 219, 200, 51, 183, 84, 18, 148, 81, 176, 133, 107, 202, 126, 239, 242, 163, 134, 236, 67, 28, 209, 147, 231, 64, 164, 259, 5, 171, 232, 206, 185, 31, 195, 234, 111, 204, 15, 75, 38, 113, 155, 128, 237, 191, 119, 210, 260, 32, 77, 108, 226, 156, 256, 12, 248, 87, 153, 125, 46, 255, 161, 118, 47, 238, 112, 74, 160, 179, 41, 250, 168, 199, 258, 123, 151, 52, 29, 45, 72, 23, 132, 244, 22, 162, 104, 11, 186, 49, 97, 34, 214, 144, 216, 136, 254, 117, 96, 26, 48, 194, 124, 10, 88, 143, 235, 16, 37, 86, 253, 249, 205, 159, 218, 93, 91, 127, 58, 7, 207, 166, 241, 262, 201, 120, 225, 184, 57, 42, 109, 245, 138, 36, 180, 62, 141, 0, 215, 211, 175, 174, 246, 1, 173, 54, 80], 'val_indices': [79, 129, 116, 208, 212, 60, 142, 71, 261, 2, 135, 40, 94, 121, 228, 110, 227, 9, 131, 158, 203, 198, 59, 78, 265, 240, 181, 63, 220, 17, 4, 83, 170, 14, 192, 178, 95, 197, 99, 247, 150, 21, 233, 157, 68, 264, 230, 19, 56, 25, 92, 105, 140, 89], 'accuracy': 0.9259259259259259, 'kappa': 0.8518518518518519, 'auc': 0.99039780521262}\n",
      "New Max Found!\n",
      "Running fold 2 with 212 training samples and 54 validation samples\n",
      "Fold 2: train indices: [ 60 150  64 231  52], val indices: [189 184 182  88 191]\n",
      "Training data shape: (212, 22, 448, 1), Validation data shape: (54, 22, 448, 1)\n",
      "Fold 2 training loss: 0.0031843550968915224\n",
      "y_true (val): [0 0 0 0 1]\n",
      "y_pred: [0 0 0 0 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [60, 150, 64, 231, 52, 89, 200, 213, 237, 135, 136, 3, 40, 29, 15, 209, 212, 229, 154, 6, 113, 196, 9, 101, 47, 4, 188, 57, 178, 226, 137, 129, 224, 98, 153, 126, 148, 11, 38, 167, 192, 65, 175, 90, 187, 27, 69, 210, 262, 99, 131, 56, 164, 26, 110, 1, 157, 173, 19, 102, 20, 193, 25, 240, 143, 118, 165, 48, 138, 7, 58, 220, 67, 161, 84, 219, 103, 140, 250, 183, 159, 251, 211, 171, 194, 49, 141, 132, 166, 97, 214, 119, 50, 232, 16, 94, 142, 92, 73, 77, 81, 107, 24, 152, 122, 33, 176, 263, 180, 243, 86, 104, 125, 13, 39, 53, 156, 87, 163, 134, 235, 133, 201, 264, 246, 116, 63, 30, 32, 75, 244, 260, 37, 72, 46, 127, 109, 162, 121, 55, 221, 254, 185, 115, 45, 238, 218, 181, 258, 128, 83, 28, 242, 76, 239, 117, 179, 61, 111, 202, 177, 206, 31, 234, 190, 18, 227, 265, 261, 68, 74, 22, 256, 215, 216, 34, 105, 170, 51, 259, 43, 2, 35, 197, 21, 91, 186, 5, 230, 108, 217, 14, 80, 151, 225, 70, 106, 199, 174, 155, 146, 253, 257, 245, 139, 12, 233, 54, 23, 120, 145, 114], 'val_indices': [189, 184, 182, 88, 191, 62, 71, 10, 112, 241, 208, 79, 44, 96, 203, 85, 252, 222, 59, 36, 42, 0, 255, 169, 249, 82, 207, 247, 93, 228, 160, 8, 66, 95, 248, 223, 204, 17, 130, 195, 78, 168, 147, 236, 123, 158, 124, 198, 172, 149, 41, 144, 100, 205], 'accuracy': 0.9444444444444444, 'kappa': 0.8888888888888888, 'auc': 0.9917695473251029}\n",
      "New Max Found!\n",
      "Running fold 3 with 212 training samples and 54 validation samples\n",
      "Fold 3: train indices: [102 116 202 260 195], val indices: [  1  33 169  74  16]\n",
      "Training data shape: (212, 22, 448, 1), Validation data shape: (54, 22, 448, 1)\n",
      "Fold 3 training loss: 0.002411086345091462\n",
      "y_true (val): [0 1 1 0 1]\n",
      "y_pred: [0 1 0 0 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [102, 116, 202, 260, 195, 183, 84, 245, 101, 209, 18, 119, 24, 163, 75, 210, 108, 258, 106, 43, 208, 144, 4, 19, 99, 104, 59, 122, 220, 12, 92, 211, 263, 137, 160, 241, 35, 162, 193, 149, 53, 95, 227, 42, 117, 90, 112, 242, 257, 216, 148, 173, 233, 182, 125, 155, 52, 55, 71, 3, 150, 135, 41, 78, 224, 232, 207, 219, 111, 146, 67, 264, 170, 161, 103, 15, 185, 151, 197, 23, 181, 69, 188, 47, 198, 83, 115, 221, 109, 34, 8, 113, 184, 192, 248, 130, 48, 222, 231, 225, 14, 191, 79, 30, 175, 51, 10, 132, 37, 177, 247, 77, 80, 82, 176, 25, 46, 215, 180, 124, 121, 68, 54, 147, 114, 187, 140, 49, 32, 262, 154, 166, 139, 88, 203, 100, 31, 153, 110, 94, 174, 66, 265, 254, 27, 152, 261, 61, 196, 85, 76, 142, 229, 70, 217, 201, 186, 230, 237, 246, 214, 205, 45, 11, 93, 143, 249, 206, 131, 118, 190, 133, 44, 234, 39, 81, 194, 17, 96, 22, 212, 255, 21, 252, 62, 6, 165, 167, 235, 126, 91, 40, 129, 179, 226, 228, 57, 123, 97, 98, 87, 200, 199, 7, 136, 107, 253, 223, 138, 134, 89, 244], 'val_indices': [1, 33, 169, 74, 16, 251, 243, 158, 239, 128, 65, 63, 189, 56, 145, 157, 0, 36, 60, 13, 178, 156, 127, 159, 38, 250, 28, 218, 256, 64, 164, 86, 29, 20, 120, 72, 58, 5, 259, 50, 26, 141, 240, 238, 236, 2, 172, 171, 9, 105, 204, 168, 213, 73], 'accuracy': 0.9629629629629629, 'kappa': 0.9259259259259259, 'auc': 0.9931412894375857}\n",
      "New Max Found!\n",
      "Running fold 4 with 212 training samples and 54 validation samples\n",
      "Fold 4: train indices: [ 73 237   3  30 238], val indices: [242 256  72 254 101]\n",
      "Training data shape: (212, 22, 448, 1), Validation data shape: (54, 22, 448, 1)\n",
      "Fold 4 training loss: 0.003566113067790866\n",
      "y_true (val): [1 1 0 0 1]\n",
      "y_pred: [1 1 0 0 1]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [73, 237, 3, 30, 238, 119, 69, 164, 122, 152, 159, 86, 60, 32, 34, 103, 166, 109, 16, 54, 216, 50, 17, 9, 145, 114, 176, 6, 95, 115, 61, 170, 157, 150, 8, 91, 75, 182, 211, 43, 94, 234, 44, 226, 249, 217, 161, 53, 107, 92, 0, 194, 223, 230, 58, 71, 133, 144, 155, 68, 55, 232, 112, 126, 240, 250, 25, 252, 221, 136, 31, 233, 190, 113, 48, 77, 243, 18, 200, 149, 89, 189, 188, 142, 224, 193, 108, 56, 5, 167, 1, 74, 203, 208, 80, 64, 236, 127, 210, 62, 7, 87, 225, 15, 195, 111, 229, 251, 175, 79, 137, 158, 4, 212, 52, 187, 39, 263, 207, 177, 12, 105, 98, 41, 201, 100, 131, 78, 181, 138, 143, 192, 171, 197, 42, 128, 255, 45, 196, 124, 57, 153, 24, 169, 120, 231, 246, 245, 11, 47, 185, 10, 264, 259, 26, 172, 19, 129, 106, 135, 198, 116, 110, 262, 36, 227, 35, 141, 146, 99, 220, 96, 20, 29, 247, 49, 121, 261, 82, 125, 199, 214, 202, 147, 102, 85, 104, 40, 38, 162, 97, 253, 239, 156, 191, 66, 140, 184, 117, 51, 186, 14, 70, 160, 204, 244, 67, 213, 260, 228, 180, 123], 'val_indices': [242, 256, 72, 254, 101, 222, 93, 174, 218, 88, 219, 173, 205, 21, 59, 178, 134, 33, 2, 241, 183, 215, 206, 148, 168, 63, 179, 46, 23, 90, 235, 65, 130, 27, 132, 248, 22, 257, 37, 83, 84, 76, 265, 154, 258, 151, 209, 163, 13, 118, 81, 139, 165, 28], 'accuracy': 0.9629629629629629, 'kappa': 0.9259259259259259, 'auc': 1.0}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.941, 'mean_kappa': 0.881, 'mean_auc': 0.993, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [113, 90, 13, 10, 187, 185, 137, 12, 60, 171, 237, 244, 77, 216, 102, 32, 22, 254, 110, 50, 239, 121, 249, 206, 70, 165, 105, 93, 172, 7, 256, 80, 109, 229, 240, 24, 66, 5, 144, 116, 139, 123, 97, 265, 58, 154, 45, 194, 124, 35, 19, 223, 106, 168, 199, 210, 221, 214, 69, 79, 178, 18, 209, 260, 54, 128, 31, 1, 48, 17, 198, 164, 37, 227, 242, 38, 27, 251, 83, 175, 259, 134, 34, 245, 235, 75, 155, 49, 258, 115, 158, 41, 76, 211, 140, 247, 56, 16, 146, 85, 184, 248, 78, 138, 225, 9, 205, 36, 25, 150, 0, 212, 202, 82, 201, 43, 86, 111, 120, 218, 40, 195, 59, 81, 108, 219, 182, 74, 162, 26, 101, 98, 152, 252, 42, 20, 151, 122, 57, 232, 130, 3, 145, 224, 127, 243, 95, 228, 203, 204, 220, 96, 53, 188, 183, 230, 262, 191, 142, 160, 2, 255, 246, 181, 64, 153, 61, 170, 118, 114, 193, 222, 62, 189, 23, 87, 11, 207, 131, 197, 68, 67, 89, 39, 4, 136, 253, 47, 166, 84, 233, 159, 186, 149, 148, 44, 51, 231, 226, 133, 8, 238, 208, 263, 192, 29, 104, 156, 264, 33, 196, 100], 'val_indices': [241, 14, 177, 143, 71, 200, 107, 179, 157, 15, 250, 72, 103, 52, 141, 163, 73, 92, 94, 129, 63, 112, 176, 126, 161, 119, 30, 55, 261, 236, 46, 234, 21, 28, 213, 117, 147, 88, 174, 180, 91, 167, 65, 132, 135, 169, 190, 6, 99, 173, 217, 257, 125, 215], 'accuracy': 0.9074074074074074, 'kappa': 0.8148148148148149, 'auc': 0.9903978052126201}, {'fold_index': 1, 'train_indices': [102, 149, 115, 152, 196, 44, 76, 101, 13, 66, 53, 187, 139, 24, 182, 130, 70, 33, 3, 61, 252, 257, 217, 224, 154, 8, 100, 177, 137, 27, 122, 98, 43, 73, 188, 172, 222, 35, 85, 65, 167, 213, 90, 50, 243, 69, 190, 263, 221, 193, 30, 251, 189, 106, 55, 165, 145, 229, 82, 146, 103, 20, 169, 223, 6, 114, 39, 219, 200, 51, 183, 84, 18, 148, 81, 176, 133, 107, 202, 126, 239, 242, 163, 134, 236, 67, 28, 209, 147, 231, 64, 164, 259, 5, 171, 232, 206, 185, 31, 195, 234, 111, 204, 15, 75, 38, 113, 155, 128, 237, 191, 119, 210, 260, 32, 77, 108, 226, 156, 256, 12, 248, 87, 153, 125, 46, 255, 161, 118, 47, 238, 112, 74, 160, 179, 41, 250, 168, 199, 258, 123, 151, 52, 29, 45, 72, 23, 132, 244, 22, 162, 104, 11, 186, 49, 97, 34, 214, 144, 216, 136, 254, 117, 96, 26, 48, 194, 124, 10, 88, 143, 235, 16, 37, 86, 253, 249, 205, 159, 218, 93, 91, 127, 58, 7, 207, 166, 241, 262, 201, 120, 225, 184, 57, 42, 109, 245, 138, 36, 180, 62, 141, 0, 215, 211, 175, 174, 246, 1, 173, 54, 80], 'val_indices': [79, 129, 116, 208, 212, 60, 142, 71, 261, 2, 135, 40, 94, 121, 228, 110, 227, 9, 131, 158, 203, 198, 59, 78, 265, 240, 181, 63, 220, 17, 4, 83, 170, 14, 192, 178, 95, 197, 99, 247, 150, 21, 233, 157, 68, 264, 230, 19, 56, 25, 92, 105, 140, 89], 'accuracy': 0.9259259259259259, 'kappa': 0.8518518518518519, 'auc': 0.99039780521262}, {'fold_index': 2, 'train_indices': [60, 150, 64, 231, 52, 89, 200, 213, 237, 135, 136, 3, 40, 29, 15, 209, 212, 229, 154, 6, 113, 196, 9, 101, 47, 4, 188, 57, 178, 226, 137, 129, 224, 98, 153, 126, 148, 11, 38, 167, 192, 65, 175, 90, 187, 27, 69, 210, 262, 99, 131, 56, 164, 26, 110, 1, 157, 173, 19, 102, 20, 193, 25, 240, 143, 118, 165, 48, 138, 7, 58, 220, 67, 161, 84, 219, 103, 140, 250, 183, 159, 251, 211, 171, 194, 49, 141, 132, 166, 97, 214, 119, 50, 232, 16, 94, 142, 92, 73, 77, 81, 107, 24, 152, 122, 33, 176, 263, 180, 243, 86, 104, 125, 13, 39, 53, 156, 87, 163, 134, 235, 133, 201, 264, 246, 116, 63, 30, 32, 75, 244, 260, 37, 72, 46, 127, 109, 162, 121, 55, 221, 254, 185, 115, 45, 238, 218, 181, 258, 128, 83, 28, 242, 76, 239, 117, 179, 61, 111, 202, 177, 206, 31, 234, 190, 18, 227, 265, 261, 68, 74, 22, 256, 215, 216, 34, 105, 170, 51, 259, 43, 2, 35, 197, 21, 91, 186, 5, 230, 108, 217, 14, 80, 151, 225, 70, 106, 199, 174, 155, 146, 253, 257, 245, 139, 12, 233, 54, 23, 120, 145, 114], 'val_indices': [189, 184, 182, 88, 191, 62, 71, 10, 112, 241, 208, 79, 44, 96, 203, 85, 252, 222, 59, 36, 42, 0, 255, 169, 249, 82, 207, 247, 93, 228, 160, 8, 66, 95, 248, 223, 204, 17, 130, 195, 78, 168, 147, 236, 123, 158, 124, 198, 172, 149, 41, 144, 100, 205], 'accuracy': 0.9444444444444444, 'kappa': 0.8888888888888888, 'auc': 0.9917695473251029}, {'fold_index': 3, 'train_indices': [102, 116, 202, 260, 195, 183, 84, 245, 101, 209, 18, 119, 24, 163, 75, 210, 108, 258, 106, 43, 208, 144, 4, 19, 99, 104, 59, 122, 220, 12, 92, 211, 263, 137, 160, 241, 35, 162, 193, 149, 53, 95, 227, 42, 117, 90, 112, 242, 257, 216, 148, 173, 233, 182, 125, 155, 52, 55, 71, 3, 150, 135, 41, 78, 224, 232, 207, 219, 111, 146, 67, 264, 170, 161, 103, 15, 185, 151, 197, 23, 181, 69, 188, 47, 198, 83, 115, 221, 109, 34, 8, 113, 184, 192, 248, 130, 48, 222, 231, 225, 14, 191, 79, 30, 175, 51, 10, 132, 37, 177, 247, 77, 80, 82, 176, 25, 46, 215, 180, 124, 121, 68, 54, 147, 114, 187, 140, 49, 32, 262, 154, 166, 139, 88, 203, 100, 31, 153, 110, 94, 174, 66, 265, 254, 27, 152, 261, 61, 196, 85, 76, 142, 229, 70, 217, 201, 186, 230, 237, 246, 214, 205, 45, 11, 93, 143, 249, 206, 131, 118, 190, 133, 44, 234, 39, 81, 194, 17, 96, 22, 212, 255, 21, 252, 62, 6, 165, 167, 235, 126, 91, 40, 129, 179, 226, 228, 57, 123, 97, 98, 87, 200, 199, 7, 136, 107, 253, 223, 138, 134, 89, 244], 'val_indices': [1, 33, 169, 74, 16, 251, 243, 158, 239, 128, 65, 63, 189, 56, 145, 157, 0, 36, 60, 13, 178, 156, 127, 159, 38, 250, 28, 218, 256, 64, 164, 86, 29, 20, 120, 72, 58, 5, 259, 50, 26, 141, 240, 238, 236, 2, 172, 171, 9, 105, 204, 168, 213, 73], 'accuracy': 0.9629629629629629, 'kappa': 0.9259259259259259, 'auc': 0.9931412894375857}, {'fold_index': 4, 'train_indices': [73, 237, 3, 30, 238, 119, 69, 164, 122, 152, 159, 86, 60, 32, 34, 103, 166, 109, 16, 54, 216, 50, 17, 9, 145, 114, 176, 6, 95, 115, 61, 170, 157, 150, 8, 91, 75, 182, 211, 43, 94, 234, 44, 226, 249, 217, 161, 53, 107, 92, 0, 194, 223, 230, 58, 71, 133, 144, 155, 68, 55, 232, 112, 126, 240, 250, 25, 252, 221, 136, 31, 233, 190, 113, 48, 77, 243, 18, 200, 149, 89, 189, 188, 142, 224, 193, 108, 56, 5, 167, 1, 74, 203, 208, 80, 64, 236, 127, 210, 62, 7, 87, 225, 15, 195, 111, 229, 251, 175, 79, 137, 158, 4, 212, 52, 187, 39, 263, 207, 177, 12, 105, 98, 41, 201, 100, 131, 78, 181, 138, 143, 192, 171, 197, 42, 128, 255, 45, 196, 124, 57, 153, 24, 169, 120, 231, 246, 245, 11, 47, 185, 10, 264, 259, 26, 172, 19, 129, 106, 135, 198, 116, 110, 262, 36, 227, 35, 141, 146, 99, 220, 96, 20, 29, 247, 49, 121, 261, 82, 125, 199, 214, 202, 147, 102, 85, 104, 40, 38, 162, 97, 253, 239, 156, 191, 66, 140, 184, 117, 51, 186, 14, 70, 160, 204, 244, 67, 213, 260, 228, 180, 123], 'val_indices': [242, 256, 72, 254, 101, 222, 93, 174, 218, 88, 219, 173, 205, 21, 59, 178, 134, 33, 2, 241, 183, 215, 206, 148, 168, 63, 179, 46, 23, 90, 235, 65, 130, 27, 132, 248, 22, 257, 37, 83, 84, 76, 265, 154, 258, 151, 209, 163, 13, 118, 81, 139, 165, 28], 'accuracy': 0.9629629629629629, 'kappa': 0.9259259259259259, 'auc': 1.0}], 'std_acc': 0.022, 'std_kappa': 0.043, 'std_auc': 0.004}\n",
      "sbj =  9\n",
      "Filtered from 237 trials to 116 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "Filtered from 264 trials to 130 trials (classes 0 and 1 only).\n",
      "Resampling from 250.000000 to 128.000000 Hz.\n",
      "X_train shape: (246, 22, 448, 1), y_train shape: (246,)\n",
      "Running fold 0 with 196 training samples and 50 validation samples\n",
      "Fold 0: train indices: [131 102  30 133 152], val indices: [ 12 142 101 109  81]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (50, 22, 448, 1)\n",
      "Fold 0 training loss: 0.007953684777021408\n",
      "y_true (val): [1 0 0 1 0]\n",
      "y_pred: [1 0 0 0 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [131, 102, 30, 133, 152, 84, 154, 64, 245, 106, 122, 203, 195, 153, 231, 123, 143, 9, 2, 157, 155, 76, 54, 5, 212, 165, 65, 159, 42, 189, 160, 36, 162, 150, 124, 53, 182, 151, 18, 83, 62, 238, 116, 225, 241, 180, 43, 19, 163, 215, 16, 235, 234, 132, 174, 41, 73, 96, 77, 21, 63, 104, 91, 60, 38, 243, 26, 198, 37, 34, 25, 46, 44, 136, 57, 158, 107, 187, 0, 4, 137, 128, 120, 204, 236, 240, 108, 149, 59, 207, 172, 110, 51, 66, 28, 58, 126, 181, 156, 45, 178, 72, 125, 192, 171, 70, 129, 23, 223, 1, 48, 79, 233, 145, 244, 216, 39, 175, 147, 201, 196, 85, 130, 194, 227, 113, 55, 94, 11, 52, 167, 121, 205, 140, 141, 56, 199, 164, 229, 78, 50, 206, 214, 190, 93, 191, 14, 144, 75, 105, 89, 232, 188, 138, 169, 210, 222, 118, 197, 3, 111, 27, 74, 80, 90, 134, 88, 95, 173, 224, 217, 119, 29, 183, 40, 202, 99, 31, 20, 213, 112, 193, 230, 7, 100, 98, 242, 228, 35, 179, 166, 184, 177, 67, 22, 176], 'val_indices': [12, 142, 101, 109, 81, 239, 47, 135, 208, 69, 226, 170, 32, 92, 209, 218, 6, 127, 161, 148, 15, 17, 211, 221, 115, 8, 114, 71, 168, 68, 61, 103, 87, 86, 13, 97, 117, 10, 146, 219, 185, 186, 237, 200, 220, 33, 139, 24, 49, 82], 'accuracy': 0.82, 'kappa': 0.6434231378763867, 'auc': 0.9503205128205128}\n",
      "New Max Found!\n",
      "Running fold 1 with 196 training samples and 50 validation samples\n",
      "Fold 1: train indices: [221 168 218 120  84], val indices: [150  50  63  71  39]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (50, 22, 448, 1)\n",
      "Fold 1 training loss: 0.005681878887116909\n",
      "y_true (val): [1 1 0 1 0]\n",
      "y_pred: [1 1 0 1 0]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [221, 168, 218, 120, 84, 57, 81, 189, 124, 98, 186, 75, 82, 11, 72, 143, 198, 3, 199, 223, 105, 70, 129, 239, 27, 156, 95, 24, 113, 225, 117, 212, 87, 107, 238, 192, 169, 173, 88, 226, 94, 185, 133, 128, 233, 132, 42, 18, 43, 130, 64, 16, 134, 2, 65, 86, 37, 231, 76, 222, 201, 49, 56, 53, 54, 191, 68, 228, 13, 162, 139, 106, 121, 55, 52, 46, 78, 214, 184, 77, 10, 146, 151, 100, 243, 44, 220, 187, 154, 122, 51, 165, 74, 188, 90, 34, 211, 194, 158, 204, 127, 45, 47, 176, 136, 38, 4, 171, 193, 145, 91, 164, 112, 108, 36, 235, 202, 182, 114, 234, 131, 62, 155, 102, 159, 60, 109, 245, 28, 141, 7, 224, 230, 61, 83, 206, 236, 104, 116, 138, 161, 30, 147, 196, 26, 200, 5, 170, 6, 244, 229, 152, 31, 58, 125, 73, 183, 32, 237, 219, 110, 180, 153, 208, 240, 99, 149, 166, 160, 97, 48, 35, 80, 142, 25, 175, 190, 22, 85, 17, 21, 89, 197, 135, 59, 8, 118, 29, 103, 215, 20, 209, 207, 41, 179, 216], 'val_indices': [150, 50, 63, 71, 39, 33, 174, 119, 213, 0, 15, 96, 232, 115, 79, 69, 242, 195, 241, 137, 205, 140, 167, 12, 123, 1, 101, 203, 9, 181, 92, 66, 172, 40, 67, 23, 93, 111, 14, 157, 227, 126, 210, 148, 217, 163, 178, 177, 19, 144], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.9631410256410257}\n",
      "New Max Found!\n",
      "Running fold 2 with 196 training samples and 50 validation samples\n",
      "Fold 2: train indices: [ 63 104 146  49  48], val indices: [140  93 237  88 242]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (50, 22, 448, 1)\n",
      "Fold 2 training loss: 0.004204689059406519\n",
      "y_true (val): [0 1 1 1 1]\n",
      "y_pred: [0 1 1 0 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [63, 104, 146, 49, 48, 67, 196, 8, 82, 47, 165, 41, 244, 232, 174, 37, 158, 40, 184, 240, 74, 151, 118, 43, 57, 215, 45, 62, 210, 177, 120, 9, 178, 220, 226, 70, 102, 96, 12, 175, 217, 99, 1, 6, 33, 145, 66, 72, 124, 76, 34, 230, 3, 23, 213, 5, 32, 212, 84, 97, 149, 122, 77, 112, 161, 36, 52, 229, 107, 60, 54, 194, 27, 65, 61, 154, 156, 95, 137, 103, 105, 42, 201, 222, 101, 75, 157, 214, 125, 127, 186, 187, 236, 0, 173, 136, 30, 19, 192, 189, 100, 17, 200, 138, 228, 73, 20, 131, 51, 135, 7, 116, 110, 238, 14, 181, 179, 197, 109, 91, 90, 108, 166, 53, 21, 38, 202, 245, 139, 191, 168, 56, 121, 172, 204, 234, 132, 221, 128, 241, 141, 227, 24, 235, 111, 205, 55, 155, 39, 69, 119, 195, 190, 169, 86, 207, 170, 92, 218, 199, 153, 126, 216, 206, 211, 160, 223, 25, 15, 71, 83, 233, 89, 22, 87, 152, 78, 28, 94, 225, 182, 29, 188, 224, 64, 185, 44, 180, 81, 58, 35, 31, 123, 2, 50, 203], 'val_indices': [140, 93, 237, 88, 242, 114, 231, 143, 142, 133, 159, 129, 134, 176, 162, 13, 18, 198, 219, 79, 59, 164, 208, 115, 243, 46, 163, 98, 144, 239, 11, 4, 150, 106, 148, 80, 209, 10, 171, 117, 113, 147, 68, 85, 167, 130, 16, 193, 26, 183], 'accuracy': 0.88, 'kappa': 0.7611464968152866, 'auc': 0.969551282051282}\n",
      "Running fold 3 with 196 training samples and 50 validation samples\n",
      "Fold 3: train indices: [ 10 229 129   5 104], val indices: [ 14 196 183  26 143]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (50, 22, 448, 1)\n",
      "Fold 3 training loss: 0.008174826391041279\n",
      "y_true (val): [1 1 0 0 0]\n",
      "y_pred: [1 0 0 0 0]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [10, 229, 129, 5, 104, 60, 172, 169, 205, 24, 93, 243, 28, 210, 1, 241, 95, 140, 149, 144, 199, 114, 221, 233, 15, 50, 216, 202, 81, 76, 86, 78, 73, 127, 212, 195, 123, 32, 101, 213, 12, 126, 106, 64, 58, 220, 59, 222, 166, 135, 68, 231, 98, 47, 45, 79, 27, 67, 8, 223, 49, 188, 237, 215, 207, 132, 206, 57, 56, 112, 118, 214, 174, 162, 142, 159, 42, 187, 133, 108, 39, 66, 150, 145, 234, 193, 96, 121, 83, 63, 33, 122, 43, 173, 190, 141, 117, 30, 161, 105, 136, 185, 20, 192, 240, 242, 178, 228, 111, 176, 152, 179, 181, 74, 0, 22, 209, 163, 110, 53, 184, 137, 77, 82, 2, 4, 35, 197, 97, 99, 46, 236, 238, 175, 72, 34, 103, 194, 7, 244, 201, 100, 153, 239, 75, 232, 31, 198, 218, 217, 147, 139, 51, 89, 208, 44, 17, 191, 65, 156, 113, 200, 21, 92, 107, 180, 19, 128, 88, 125, 170, 177, 116, 52, 91, 120, 3, 219, 230, 29, 227, 151, 6, 224, 16, 71, 225, 124, 18, 102, 11, 148, 94, 203, 61, 134], 'val_indices': [14, 196, 183, 26, 143, 54, 85, 38, 37, 131, 48, 36, 40, 182, 70, 13, 204, 171, 155, 130, 138, 55, 167, 245, 226, 119, 115, 9, 164, 211, 25, 23, 69, 90, 109, 189, 165, 154, 80, 146, 235, 186, 62, 158, 168, 87, 160, 41, 157, 84], 'accuracy': 0.88, 'kappa': 0.7596153846153846, 'auc': 0.9503205128205128}\n",
      "Running fold 4 with 196 training samples and 50 validation samples\n",
      "Fold 4: train indices: [ 23  79  56 183 187], val indices: [ 26 234 144  15 191]\n",
      "Training data shape: (196, 22, 448, 1), Validation data shape: (50, 22, 448, 1)\n",
      "Fold 4 training loss: 0.005753675475716591\n",
      "y_true (val): [0 0 0 1 0]\n",
      "y_pred: [0 1 0 1 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [23, 79, 56, 183, 187, 65, 181, 232, 221, 54, 174, 48, 168, 143, 81, 42, 4, 140, 24, 146, 104, 99, 71, 178, 66, 190, 127, 89, 96, 94, 194, 201, 11, 164, 215, 188, 22, 184, 40, 142, 105, 95, 72, 210, 62, 145, 213, 182, 45, 136, 98, 20, 60, 5, 230, 195, 83, 50, 116, 30, 123, 216, 97, 0, 171, 68, 76, 28, 88, 154, 34, 243, 18, 52, 227, 172, 33, 55, 36, 202, 114, 197, 237, 208, 229, 64, 84, 32, 203, 204, 14, 156, 21, 74, 176, 225, 222, 85, 137, 126, 119, 117, 100, 133, 82, 214, 10, 111, 205, 196, 233, 44, 121, 151, 189, 193, 90, 166, 63, 69, 163, 12, 37, 17, 102, 80, 25, 139, 113, 9, 241, 226, 115, 235, 177, 150, 170, 186, 43, 138, 219, 134, 118, 173, 3, 16, 242, 75, 207, 159, 2, 165, 61, 109, 47, 162, 132, 7, 53, 131, 206, 59, 149, 41, 240, 220, 200, 147, 86, 92, 175, 129, 130, 91, 107, 155, 51, 13, 217, 29, 1, 223, 128, 67, 58, 106, 161, 73, 160, 158, 231, 35, 245, 49, 209, 239], 'val_indices': [26, 234, 144, 15, 191, 120, 108, 27, 212, 152, 39, 124, 180, 70, 46, 57, 148, 218, 6, 167, 77, 38, 112, 244, 31, 238, 185, 78, 19, 101, 87, 8, 211, 224, 93, 153, 110, 103, 125, 228, 141, 157, 135, 192, 179, 169, 199, 236, 122, 198], 'accuracy': 0.9, 'kappa': 0.8006379585326954, 'auc': 0.9647435897435898}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.876, 'mean_kappa': 0.753, 'mean_auc': 0.96, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [131, 102, 30, 133, 152, 84, 154, 64, 245, 106, 122, 203, 195, 153, 231, 123, 143, 9, 2, 157, 155, 76, 54, 5, 212, 165, 65, 159, 42, 189, 160, 36, 162, 150, 124, 53, 182, 151, 18, 83, 62, 238, 116, 225, 241, 180, 43, 19, 163, 215, 16, 235, 234, 132, 174, 41, 73, 96, 77, 21, 63, 104, 91, 60, 38, 243, 26, 198, 37, 34, 25, 46, 44, 136, 57, 158, 107, 187, 0, 4, 137, 128, 120, 204, 236, 240, 108, 149, 59, 207, 172, 110, 51, 66, 28, 58, 126, 181, 156, 45, 178, 72, 125, 192, 171, 70, 129, 23, 223, 1, 48, 79, 233, 145, 244, 216, 39, 175, 147, 201, 196, 85, 130, 194, 227, 113, 55, 94, 11, 52, 167, 121, 205, 140, 141, 56, 199, 164, 229, 78, 50, 206, 214, 190, 93, 191, 14, 144, 75, 105, 89, 232, 188, 138, 169, 210, 222, 118, 197, 3, 111, 27, 74, 80, 90, 134, 88, 95, 173, 224, 217, 119, 29, 183, 40, 202, 99, 31, 20, 213, 112, 193, 230, 7, 100, 98, 242, 228, 35, 179, 166, 184, 177, 67, 22, 176], 'val_indices': [12, 142, 101, 109, 81, 239, 47, 135, 208, 69, 226, 170, 32, 92, 209, 218, 6, 127, 161, 148, 15, 17, 211, 221, 115, 8, 114, 71, 168, 68, 61, 103, 87, 86, 13, 97, 117, 10, 146, 219, 185, 186, 237, 200, 220, 33, 139, 24, 49, 82], 'accuracy': 0.82, 'kappa': 0.6434231378763867, 'auc': 0.9503205128205128}, {'fold_index': 1, 'train_indices': [221, 168, 218, 120, 84, 57, 81, 189, 124, 98, 186, 75, 82, 11, 72, 143, 198, 3, 199, 223, 105, 70, 129, 239, 27, 156, 95, 24, 113, 225, 117, 212, 87, 107, 238, 192, 169, 173, 88, 226, 94, 185, 133, 128, 233, 132, 42, 18, 43, 130, 64, 16, 134, 2, 65, 86, 37, 231, 76, 222, 201, 49, 56, 53, 54, 191, 68, 228, 13, 162, 139, 106, 121, 55, 52, 46, 78, 214, 184, 77, 10, 146, 151, 100, 243, 44, 220, 187, 154, 122, 51, 165, 74, 188, 90, 34, 211, 194, 158, 204, 127, 45, 47, 176, 136, 38, 4, 171, 193, 145, 91, 164, 112, 108, 36, 235, 202, 182, 114, 234, 131, 62, 155, 102, 159, 60, 109, 245, 28, 141, 7, 224, 230, 61, 83, 206, 236, 104, 116, 138, 161, 30, 147, 196, 26, 200, 5, 170, 6, 244, 229, 152, 31, 58, 125, 73, 183, 32, 237, 219, 110, 180, 153, 208, 240, 99, 149, 166, 160, 97, 48, 35, 80, 142, 25, 175, 190, 22, 85, 17, 21, 89, 197, 135, 59, 8, 118, 29, 103, 215, 20, 209, 207, 41, 179, 216], 'val_indices': [150, 50, 63, 71, 39, 33, 174, 119, 213, 0, 15, 96, 232, 115, 79, 69, 242, 195, 241, 137, 205, 140, 167, 12, 123, 1, 101, 203, 9, 181, 92, 66, 172, 40, 67, 23, 93, 111, 14, 157, 227, 126, 210, 148, 217, 163, 178, 177, 19, 144], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.9631410256410257}, {'fold_index': 2, 'train_indices': [63, 104, 146, 49, 48, 67, 196, 8, 82, 47, 165, 41, 244, 232, 174, 37, 158, 40, 184, 240, 74, 151, 118, 43, 57, 215, 45, 62, 210, 177, 120, 9, 178, 220, 226, 70, 102, 96, 12, 175, 217, 99, 1, 6, 33, 145, 66, 72, 124, 76, 34, 230, 3, 23, 213, 5, 32, 212, 84, 97, 149, 122, 77, 112, 161, 36, 52, 229, 107, 60, 54, 194, 27, 65, 61, 154, 156, 95, 137, 103, 105, 42, 201, 222, 101, 75, 157, 214, 125, 127, 186, 187, 236, 0, 173, 136, 30, 19, 192, 189, 100, 17, 200, 138, 228, 73, 20, 131, 51, 135, 7, 116, 110, 238, 14, 181, 179, 197, 109, 91, 90, 108, 166, 53, 21, 38, 202, 245, 139, 191, 168, 56, 121, 172, 204, 234, 132, 221, 128, 241, 141, 227, 24, 235, 111, 205, 55, 155, 39, 69, 119, 195, 190, 169, 86, 207, 170, 92, 218, 199, 153, 126, 216, 206, 211, 160, 223, 25, 15, 71, 83, 233, 89, 22, 87, 152, 78, 28, 94, 225, 182, 29, 188, 224, 64, 185, 44, 180, 81, 58, 35, 31, 123, 2, 50, 203], 'val_indices': [140, 93, 237, 88, 242, 114, 231, 143, 142, 133, 159, 129, 134, 176, 162, 13, 18, 198, 219, 79, 59, 164, 208, 115, 243, 46, 163, 98, 144, 239, 11, 4, 150, 106, 148, 80, 209, 10, 171, 117, 113, 147, 68, 85, 167, 130, 16, 193, 26, 183], 'accuracy': 0.88, 'kappa': 0.7611464968152866, 'auc': 0.969551282051282}, {'fold_index': 3, 'train_indices': [10, 229, 129, 5, 104, 60, 172, 169, 205, 24, 93, 243, 28, 210, 1, 241, 95, 140, 149, 144, 199, 114, 221, 233, 15, 50, 216, 202, 81, 76, 86, 78, 73, 127, 212, 195, 123, 32, 101, 213, 12, 126, 106, 64, 58, 220, 59, 222, 166, 135, 68, 231, 98, 47, 45, 79, 27, 67, 8, 223, 49, 188, 237, 215, 207, 132, 206, 57, 56, 112, 118, 214, 174, 162, 142, 159, 42, 187, 133, 108, 39, 66, 150, 145, 234, 193, 96, 121, 83, 63, 33, 122, 43, 173, 190, 141, 117, 30, 161, 105, 136, 185, 20, 192, 240, 242, 178, 228, 111, 176, 152, 179, 181, 74, 0, 22, 209, 163, 110, 53, 184, 137, 77, 82, 2, 4, 35, 197, 97, 99, 46, 236, 238, 175, 72, 34, 103, 194, 7, 244, 201, 100, 153, 239, 75, 232, 31, 198, 218, 217, 147, 139, 51, 89, 208, 44, 17, 191, 65, 156, 113, 200, 21, 92, 107, 180, 19, 128, 88, 125, 170, 177, 116, 52, 91, 120, 3, 219, 230, 29, 227, 151, 6, 224, 16, 71, 225, 124, 18, 102, 11, 148, 94, 203, 61, 134], 'val_indices': [14, 196, 183, 26, 143, 54, 85, 38, 37, 131, 48, 36, 40, 182, 70, 13, 204, 171, 155, 130, 138, 55, 167, 245, 226, 119, 115, 9, 164, 211, 25, 23, 69, 90, 109, 189, 165, 154, 80, 146, 235, 186, 62, 158, 168, 87, 160, 41, 157, 84], 'accuracy': 0.88, 'kappa': 0.7596153846153846, 'auc': 0.9503205128205128}, {'fold_index': 4, 'train_indices': [23, 79, 56, 183, 187, 65, 181, 232, 221, 54, 174, 48, 168, 143, 81, 42, 4, 140, 24, 146, 104, 99, 71, 178, 66, 190, 127, 89, 96, 94, 194, 201, 11, 164, 215, 188, 22, 184, 40, 142, 105, 95, 72, 210, 62, 145, 213, 182, 45, 136, 98, 20, 60, 5, 230, 195, 83, 50, 116, 30, 123, 216, 97, 0, 171, 68, 76, 28, 88, 154, 34, 243, 18, 52, 227, 172, 33, 55, 36, 202, 114, 197, 237, 208, 229, 64, 84, 32, 203, 204, 14, 156, 21, 74, 176, 225, 222, 85, 137, 126, 119, 117, 100, 133, 82, 214, 10, 111, 205, 196, 233, 44, 121, 151, 189, 193, 90, 166, 63, 69, 163, 12, 37, 17, 102, 80, 25, 139, 113, 9, 241, 226, 115, 235, 177, 150, 170, 186, 43, 138, 219, 134, 118, 173, 3, 16, 242, 75, 207, 159, 2, 165, 61, 109, 47, 162, 132, 7, 53, 131, 206, 59, 149, 41, 240, 220, 200, 147, 86, 92, 175, 129, 130, 91, 107, 155, 51, 13, 217, 29, 1, 223, 128, 67, 58, 106, 161, 73, 160, 158, 231, 35, 245, 49, 209, 239], 'val_indices': [26, 234, 144, 15, 191, 120, 108, 27, 212, 152, 39, 124, 180, 70, 46, 57, 148, 218, 6, 167, 77, 38, 112, 244, 31, 238, 185, 78, 19, 101, 87, 8, 211, 224, 93, 153, 110, 103, 125, 228, 141, 157, 135, 192, 179, 169, 199, 236, 122, 198], 'accuracy': 0.9, 'kappa': 0.8006379585326954, 'auc': 0.9647435897435898}], 'std_acc': 0.029, 'std_kappa': 0.058, 'std_auc': 0.008}\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "\n",
    "subjects = [1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "for sbj in subjects[:]:\n",
    "  print('sbj = ', sbj)\n",
    "  load_args['sbj'] = sbj\n",
    "  results = train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed)\n",
    "  with open('sbj' + str(load_args['sbj']) + '.txt', 'wb') as f:\n",
    "    dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee57eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T08:39:31.690857Z",
     "iopub.status.busy": "2025-08-17T08:39:31.690233Z",
     "iopub.status.idle": "2025-08-17T08:39:33.920554Z",
     "shell.execute_reply": "2025-08-17T08:39:33.919597Z"
    },
    "id": "V7-P0xjwzXVX",
    "outputId": "270dceef-351d-48d1-f71e-2c3367c7fdac",
    "papermill": {
     "duration": 2.250834,
     "end_time": "2025-08-17T08:39:33.922631",
     "exception": false,
     "start_time": "2025-08-17T08:39:31.671797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: sbj1.h5 (deflated 19%)\r\n",
      "  adding: sbj2.h5 (deflated 19%)\r\n",
      "  adding: sbj3.h5 (deflated 19%)\r\n",
      "  adding: sbj4.h5 (deflated 19%)\r\n",
      "  adding: sbj5.h5 (deflated 19%)\r\n",
      "  adding: sbj6.h5 (deflated 18%)\r\n",
      "  adding: sbj7.h5 (deflated 18%)\r\n",
      "  adding: sbj8.h5 (deflated 19%)\r\n",
      "  adding: sbj9.h5 (deflated 19%)\r\n",
      "  adding: sbj1.txt (deflated 38%)\r\n",
      "  adding: sbj2.txt (deflated 39%)\r\n",
      "  adding: sbj3.txt (deflated 40%)\r\n",
      "  adding: sbj4.txt (deflated 39%)\r\n",
      "  adding: sbj5.txt (deflated 38%)\r\n",
      "  adding: sbj6.txt (deflated 40%)\r\n",
      "  adding: sbj7.txt (deflated 38%)\r\n",
      "  adding: sbj8.txt (deflated 39%)\r\n",
      "  adding: sbj9.txt (deflated 40%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip Models_8ch_EEGNet_BCI.zip ./*.h5 \n",
    "!zip Results_8ch_EEGNet_BCI.zip ./*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4a5c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T08:39:33.960788Z",
     "iopub.status.busy": "2025-08-17T08:39:33.960498Z",
     "iopub.status.idle": "2025-08-17T08:39:33.964539Z",
     "shell.execute_reply": "2025-08-17T08:39:33.963849Z"
    },
    "papermill": {
     "duration": 0.024575,
     "end_time": "2025-08-17T08:39:33.966154",
     "exception": false,
     "start_time": "2025-08-17T08:39:33.941579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle as pkl\n",
    "\n",
    "#with open(file= '/kaggle/working/sbj14.txt', mode = 'rb' ) as f:\n",
    "#    results_64ch_ShallowConvNet = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c345036b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T08:39:34.003593Z",
     "iopub.status.busy": "2025-08-17T08:39:34.003351Z",
     "iopub.status.idle": "2025-08-17T08:39:34.007144Z",
     "shell.execute_reply": "2025-08-17T08:39:34.006320Z"
    },
    "papermill": {
     "duration": 0.025222,
     "end_time": "2025-08-17T08:39:34.009115",
     "exception": false,
     "start_time": "2025-08-17T08:39:33.983893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_64ch_ShallowConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c85224e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T08:39:34.045575Z",
     "iopub.status.busy": "2025-08-17T08:39:34.045257Z",
     "iopub.status.idle": "2025-08-17T08:39:34.048780Z",
     "shell.execute_reply": "2025-08-17T08:39:34.048088Z"
    },
    "papermill": {
     "duration": 0.02333,
     "end_time": "2025-08-17T08:39:34.050425",
     "exception": false,
     "start_time": "2025-08-17T08:39:34.027095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(file= '/kaggle/working/sbj2.txt', mode = 'rb' ) as f:\n",
    " #   results_64ch_ShallowConvNet = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87dcbc5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T08:39:34.086765Z",
     "iopub.status.busy": "2025-08-17T08:39:34.086489Z",
     "iopub.status.idle": "2025-08-17T08:39:34.090046Z",
     "shell.execute_reply": "2025-08-17T08:39:34.089133Z"
    },
    "papermill": {
     "duration": 0.023506,
     "end_time": "2025-08-17T08:39:34.091669",
     "exception": false,
     "start_time": "2025-08-17T08:39:34.068163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_64ch_ShallowConvNet"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1645904,
     "sourceId": 2702213,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1269900,
     "sourceId": 2702226,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2984453,
     "sourceId": 5137200,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3008205,
     "sourceId": 5175158,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3009745,
     "sourceId": 5177340,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18890.186472,
   "end_time": "2025-08-17T08:39:37.164925",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-17T03:24:46.978453",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
