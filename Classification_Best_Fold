{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c2ec6d",
   "metadata": {
    "id": "x9LNzEYERaH2",
    "papermill": {
     "duration": 0.004263,
     "end_time": "2025-04-08T22:33:32.465027",
     "exception": false,
     "start_time": "2025-04-08T22:33:32.460764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174bb77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:33:32.475417Z",
     "iopub.status.busy": "2025-04-08T22:33:32.474555Z",
     "iopub.status.idle": "2025-04-08T22:33:33.559328Z",
     "shell.execute_reply": "2025-04-08T22:33:33.558140Z"
    },
    "papermill": {
     "duration": 1.091717,
     "end_time": "2025-04-08T22:33:33.561538",
     "exception": false,
     "start_time": "2025-04-08T22:33:32.469821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-8585c320-9cd5-063c-d56e-dde4e0917253)\r\n",
      "GPU 1: Tesla T4 (UUID: GPU-cf7cd990-d462-2360-df5f-a4d5bd586225)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9043f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:33:33.570586Z",
     "iopub.status.busy": "2025-04-08T22:33:33.569870Z",
     "iopub.status.idle": "2025-04-08T22:34:21.933575Z",
     "shell.execute_reply": "2025-04-08T22:34:21.932536Z"
    },
    "id": "K0oS6IH7VTZX",
    "papermill": {
     "duration": 48.370451,
     "end_time": "2025-04-08T22:34:21.935671",
     "exception": false,
     "start_time": "2025-04-08T22:33:33.565220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n",
    "!pip install mne #The MNE Package is installed\n",
    "FILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip MI_EEG_ClassMeth.zip #Package with useful functions for motor imagery classification based in EEG.\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ab193c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:34:21.943604Z",
     "iopub.status.busy": "2025-04-08T22:34:21.943218Z",
     "iopub.status.idle": "2025-04-08T22:35:55.533641Z",
     "shell.execute_reply": "2025-04-08T22:35:55.532466Z"
    },
    "papermill": {
     "duration": 93.596785,
     "end_time": "2025-04-08T22:35:55.535720",
     "exception": false,
     "start_time": "2025-04-08T22:34:21.938935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "Package libcudnn8 is not available, but is referred to by another package.\r\n",
      "This may mean that the package is missing, has been obsoleted, or\r\n",
      "is only available from another source\r\n",
      "\r\n",
      "E: Version '8.1.0.77-1+cuda11.2' for 'libcudnn8' was not found\r\n",
      "Collecting tensorflow==2.8.2\r\n",
      "  Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (24.3.25)\r\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.11.0)\r\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.2)\r\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (18.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.3.0)\r\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.8.2)\r\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.16.0)\r\n",
      "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow==2.8.2)\r\n",
      "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.2)\r\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.37.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.62.2)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.2) (0.43.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.30.0)\r\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.6)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.32.3)\r\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.2)\r\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.0.4)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2024.8.30)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.5)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.6.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.2)\r\n",
      "Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl (498.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\r\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tensorflow-estimator, tensorboard-plugin-wit, keras, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\r\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "  Attempting uninstall: tensorboard-data-server\r\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\r\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\r\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: google-auth-oauthlib\r\n",
      "    Found existing installation: google-auth-oauthlib 1.2.0\r\n",
      "    Uninstalling google-auth-oauthlib-1.2.0:\r\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.0\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.16.2\r\n",
      "    Uninstalling tensorboard-2.16.2:\r\n",
      "      Successfully uninstalled tensorboard-2.16.2\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.16.1\r\n",
      "    Uninstalling tensorflow-2.16.1:\r\n",
      "      Successfully uninstalled tensorflow-2.16.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-datastore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-language 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-videointelligence 2.13.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "onnx 1.17.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.2 which is incompatible.\r\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.8.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.2 tensorflow-estimator-2.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 -y\n",
    "!pip install tensorflow==2.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738b576",
   "metadata": {
    "papermill": {
     "duration": 0.010773,
     "end_time": "2025-04-08T22:35:55.558089",
     "exception": false,
     "start_time": "2025-04-08T22:35:55.547316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b083e028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:35:55.581589Z",
     "iopub.status.busy": "2025-04-08T22:35:55.581264Z",
     "iopub.status.idle": "2025-04-08T22:36:08.546844Z",
     "shell.execute_reply": "2025-04-08T22:36:08.546013Z"
    },
    "id": "yE1sbHYQVbBq",
    "papermill": {
     "duration": 12.979931,
     "end_time": "2025-04-08T22:36:08.548819",
     "exception": false,
     "start_time": "2025-04-08T22:35:55.568888",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gcpds.databases.BCI_Competition_IV import Dataset_2a\n",
    "from typing import Sequence, Tuple\n",
    "from MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "\n",
    "def load_BCICIV2a(db: Dataset_2a,\n",
    "               sbj: int,\n",
    "               mode: str,\n",
    "               fs: float, \n",
    "               f_bank: np.ndarray, \n",
    "               vwt: np.ndarray, \n",
    "               new_fs: float) -> np.ndarray:\n",
    "\n",
    "  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
    "\n",
    "  db.load_subject(sbj, mode = mode)\n",
    "    \n",
    "  X, y = db.get_data() #Load all classes, all channels {EEG, EOG}, reject bad trials\n",
    "\n",
    "  X = X[:,:-3,:] # pick EEG channels\n",
    "  X = X*1e6 #uV\n",
    "  X = np.squeeze(tf_repr.transform(X))\n",
    "  #Resampling\n",
    "  if new_fs == fs:\n",
    "    print('No resampling, since new sampling rate same.')\n",
    "  else:\n",
    "    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
    "    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
    "    \n",
    "  return X, y\n",
    "\n",
    "\n",
    "from gcpds.databases import GIGA_MI_ME\n",
    "\n",
    "def load_GIGA_MI_ME(db: GIGA_MI_ME,\n",
    "              sbj: int,\n",
    "              eeg_ch_names: Sequence[str],\n",
    "              fs: float, \n",
    "              f_bank: np.ndarray, \n",
    "              vwt: np.ndarray, \n",
    "              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    index_eeg_chs = db.format_channels_selectors(channels=eeg_ch_names) - 1\n",
    "\n",
    "    tf_repr = TimeFrequencyRpr(sfreq=fs, f_bank=f_bank, vwt=vwt)\n",
    "\n",
    "    # Load subject data\n",
    "    db.load_subject(sbj)\n",
    "    X, y = db.get_data(classes=['left hand mi', 'right hand mi'])\n",
    "    \n",
    "    # Debugging total trials\n",
    "    print(f\"Total trials loaded: {X.shape[0]}\")\n",
    "    print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
    "\n",
    "    # Spatial rearrangement\n",
    "    X = X[:, index_eeg_chs, :]  \n",
    "    X = np.squeeze(tf_repr.transform(X))\n",
    "\n",
    "    # Resampling\n",
    "    if new_fs == fs:\n",
    "        print('No resampling, since new sampling rate is the same.')\n",
    "    else:\n",
    "        print(f\"Resampling from {fs} to {new_fs} Hz.\")\n",
    "        X = resample(X, int((X.shape[-1] / fs) * new_fs), axis=-1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def load_DB(db_name, **load_args):\n",
    "  if db_name == 'BCICIV2a':\n",
    "    X_train, y_train = load_BCICIV2a(**load_args, mode = 'training')\n",
    "    X_test, y_test = load_BCICIV2a(**load_args, mode = 'evaluation')\n",
    "\n",
    "    X_train = np.concatenate([X_train, X_test], axis = 0)\n",
    "    y_train = np.concatenate([y_train, y_test], axis = 0)\n",
    "\n",
    "  elif db_name == 'GIGA_MI_ME':\n",
    "    X_train, y_train = load_GIGA_MI_ME(**load_args)\n",
    "    \n",
    "  else:\n",
    "    raise ValueError('No valid database name')\n",
    "\n",
    "  return X_train, y_train\n",
    "\n",
    "\n",
    "from EEG_Tensorflow_models.Models import DeepConvNet, ShallowConvNet, EEGNet, DMTL_BCI, TCNet_fusion, PST_attention\n",
    "\n",
    "\n",
    "def get_model(model_name, nb_classes):\n",
    "  if model_name == 'DeepConvNet':\n",
    "    model = DeepConvNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5, version='2018')\n",
    "    \n",
    "  elif model_name == 'ShallowConvNet':\n",
    "    model = ShallowConvNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      version = '2018')\n",
    "    \n",
    "  elif model_name == 'EEGNet':\n",
    "    model = EEGNet\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      kernLength = 32,\n",
    "                      F1 = 8,\n",
    "                      D = 2,\n",
    "                      F2 = 16,\n",
    "                      norm_rate = 0.25, \n",
    "                      dropoutType = 'Dropout')\n",
    "    \n",
    "  elif model_name == 'DMTL_BCI':\n",
    "    model = DMTL_BCI\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      l1 = 0,\n",
    "                      l2 = 0)\n",
    "    \n",
    "  elif model_name == 'TCNet_fusion':\n",
    "    model = TCNet_fusion\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      layers = 2,\n",
    "                      kernel_s = 4,\n",
    "                      filt = 12,\n",
    "                      dropout = 0.3,\n",
    "                      activation = 'relu',\n",
    "                      F1 = 24,\n",
    "                      D = 2,\n",
    "                      kernLength = 32,\n",
    "                      N_residuals = 2)\n",
    "    \n",
    "  elif model_name == 'PST_attention':\n",
    "    model = PST_attention\n",
    "    model_params = dict(nb_classes = nb_classes,\n",
    "                      dropoutRate = 0.5,\n",
    "                      last_layer = 'Dense')\n",
    "    \n",
    "  else:\n",
    "    raise ValueError('No valid model name')\n",
    "    \n",
    "  return model, model_params\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score,\\\n",
    "                            f1_score, recall_score, precision_score\n",
    "\n",
    "def train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed):\n",
    "    X_train, y_train = load_DB(db_name, **load_args)\n",
    "    X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    \n",
    "    cv_results = {'params': [],\n",
    "                  'mean_acc': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_kappa': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_auc': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_f1_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_f1_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_recall_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_recall_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_precision_left': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'mean_precision_right': np.zeros(cv_args['cv'].get_n_splits()),\n",
    "                  'all_folds': []}\n",
    "    \n",
    "    k = 0\n",
    "    max_acc = -np.inf\n",
    "\n",
    "    # Loop through folds\n",
    "    for train_index, val_index in cv_args['cv'].split(X_train, y_train):\n",
    "        print(f\"Running fold {k} with {len(train_index)} training samples and {len(val_index)} validation samples\")\n",
    "        print(f\"Fold {k}: train indices: {train_index[:5]}, val indices: {val_index[:5]}\")  # Print first indices\n",
    "        \n",
    "        X, X_val = X_train[train_index], X_train[val_index]\n",
    "        y, y_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        if model_args['autoencoder']:\n",
    "            y = [X, y]\n",
    "        \n",
    "        print(f\"Training data shape: {X.shape}, Validation data shape: {X_val.shape}\")\n",
    "        \n",
    "        batch_size, C, T = X.shape[:-1]\n",
    "        clear_session()\n",
    "        set_seed(seed)\n",
    "\n",
    "        model_cll, model_params = get_model(model_args['model_name'], model_args['nb_classes'])\n",
    "        model = model_cll(**model_params, Chans=64, Samples=T)\n",
    "        model.compile(loss=compile_args['loss'], optimizer=Adam(compile_args['init_lr']))\n",
    "\n",
    "        history = model.fit(X, y, batch_size=batch_size, **fit_args)\n",
    "        print(f\"Fold {k} training loss: {history.history['loss'][-1]}\")  # Print final loss\n",
    "\n",
    "        if model_args['autoencoder']:\n",
    "            y_prob = model.predict(X_val)[-1]\n",
    "        else:\n",
    "            y_prob = model.predict(X_val)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "        print(f\"y_true (val): {y_val[:5]}\")\n",
    "        print(f\"y_pred: {y_pred[:5]}\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        kappa = cohen_kappa_score(y_val, y_pred)\n",
    "        auc = roc_auc_score(y_val, y_prob[:, 1], average='macro') if model_args['nb_classes'] == 2 else None\n",
    "        \n",
    "        # Save metrics for this fold\n",
    "        fold_result = {\n",
    "            'fold_index': k,\n",
    "            'train_indices': train_index.tolist(),\n",
    "            'val_indices': val_index.tolist(),\n",
    "            'accuracy': acc,\n",
    "            'kappa': kappa,\n",
    "            'auc': auc\n",
    "        }\n",
    "        print(f\"Appending results for fold {k}: {fold_result}\")\n",
    "        cv_results['all_folds'].append(fold_result)\n",
    "\n",
    "        # Update overall fold metrics\n",
    "        cv_results['mean_acc'][k] = acc\n",
    "        cv_results['mean_kappa'][k] = kappa\n",
    "        if auc is not None:\n",
    "            cv_results['mean_auc'][k] = auc\n",
    "        \n",
    "        # Save the best model weights\n",
    "        if acc > max_acc:\n",
    "            print('New Max Found!')\n",
    "            max_acc = acc\n",
    "            model.save_weights(f'sbj{load_args[\"sbj\"]}.h5')\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    # Calculate mean and std metrics\n",
    "    cv_results['std_acc'] = round(cv_results['mean_acc'].std(), 3)\n",
    "    cv_results['mean_acc'] = round(cv_results['mean_acc'].mean(), 3)\n",
    "    cv_results['std_kappa'] = round(cv_results['mean_kappa'].std(), 3)\n",
    "    cv_results['mean_kappa'] = round(cv_results['mean_kappa'].mean(), 3)\n",
    "    cv_results['std_auc'] = round(cv_results['mean_auc'].std(), 3)\n",
    "    cv_results['mean_auc'] = round(cv_results['mean_auc'].mean(), 3)\n",
    "    \n",
    "    print(f\"Final cross-validation results: {cv_results}\")\n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae87d1",
   "metadata": {
    "id": "uBAeW6J5S68g",
    "papermill": {
     "duration": 0.011701,
     "end_time": "2025-04-08T22:36:08.572567",
     "exception": false,
     "start_time": "2025-04-08T22:36:08.560866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54d48f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:36:08.596346Z",
     "iopub.status.busy": "2025-04-08T22:36:08.595499Z",
     "iopub.status.idle": "2025-04-08T22:36:08.600524Z",
     "shell.execute_reply": "2025-04-08T22:36:08.599611Z"
    },
    "id": "2I3IQnNSS9-a",
    "papermill": {
     "duration": 0.018833,
     "end_time": "2025-04-08T22:36:08.602414",
     "exception": false,
     "start_time": "2025-04-08T22:36:08.583581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Marcos, use these two variables to run the state of the art. First, for BCICIV2a run all the models.\n",
    "# Remeber that this network DMTL_BCI is an autoencoder. Set the nb_classses parameter depending of the database.\n",
    "# set autoencoder based on the model\n",
    "# We need to run all these tests again. Do not forget to add the recall, preci, and f1 for each class (bci 4, giga 2)\n",
    "db_name = 'GIGA_MI_ME'\n",
    "model_args = dict(model_name = 'TCNet_fusion',\n",
    "                  nb_classes = 2,\n",
    "                  autoencoder = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5db362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:36:08.626192Z",
     "iopub.status.busy": "2025-04-08T22:36:08.625927Z",
     "iopub.status.idle": "2025-04-08T22:36:08.647467Z",
     "shell.execute_reply": "2025-04-08T22:36:08.646458Z"
    },
    "id": "tqMhUFoBIc3B",
    "outputId": "1405fd59-1374-4d5d-8e3a-5e7a45c79bba",
    "papermill": {
     "duration": 0.035608,
     "end_time": "2025-04-08T22:36:08.649203",
     "exception": false,
     "start_time": "2025-04-08T22:36:08.613595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TerminateOnNaN\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "if db_name == 'BCICIV2a':\n",
    "  db = Dataset_2a('/kaggle/input/dataset-2a')\n",
    "  fs = db.metadata['sampling_rate']\n",
    "  load_args = dict(db = db,\n",
    "                 fs = fs,\n",
    "                 f_bank = np.asarray([[4., 40.]]),\n",
    "                 vwt = np.asarray([[2.5, 6]]),\n",
    "                 new_fs = 128.)\n",
    "  subjects = np.arange(db.metadata['subjects']) + 1\n",
    "  \n",
    "elif db_name == 'GIGA_MI_ME':\n",
    "  db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n",
    "  fs = db.metadata['sampling_rate']\n",
    "\n",
    "  eeg_ch_names = ['Fp1','Fpz','Fp2',\n",
    "                     'AF7','AF3','AFz','AF4','AF8',\n",
    "                    'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
    "                   'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n",
    "                    'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
    "                   'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n",
    "                    'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n",
    "                    'PO7','PO3','POz','PO4','PO8',\n",
    "                    'O1','Oz','O2',\n",
    "                    'Iz']\n",
    "\n",
    "  # eeg_ch_names = ['Fp1','Fp2',\n",
    "  #                  'AF3','AF4',\n",
    "  #                  'F7','F3','Fz','F4','F8',\n",
    "  #                  'FC5','FC1','FC2','FC6',\n",
    "  #                  'T7','C3','Cz','C4','T8',\n",
    "  #                  'CP5','CP1','CP2','CP6',\n",
    "  #                  'P7','P3','Pz','P4','P8',\n",
    "  #                  'PO3','PO4',\n",
    "  #                  'O1','Oz','O2']\n",
    "\n",
    "  # eeg_ch_names = ['Fp1','Fp2',\n",
    "  #                 'F7','F3','F4','F8',\n",
    "  #                 'T7','C3','C4','T8',\n",
    "  #                 'P7','P3','P4','P8',\n",
    "  #                 'O1','O2']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # eeg_ch_names = ['Fp1','Fp2',\n",
    "  #              'T7','C3','C4','T8',\n",
    "  #              'O1','O2']\n",
    "    \n",
    "\n",
    "\n",
    "  load_args = dict(db = db,\n",
    "                  eeg_ch_names = eeg_ch_names,\n",
    "                  fs = fs,\n",
    "                  f_bank = np.asarray([[4., 40.]]),\n",
    "                  vwt = np.asarray([[2.5, 5]]),\n",
    "                  new_fs = 128.)\n",
    "  subjects = np.arange(db.metadata['subjects']) + 1\n",
    "  subjects = np.delete(subjects, [28,33])\n",
    "  \n",
    "else:\n",
    "  raise ValueError('No valid database name')\n",
    "\n",
    "verbose = 0\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 30, verbose = verbose, mode = 'min', min_delta = 0.01, min_lr = 0)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "callbacks = [reduce_lr_on_plateau, terminate_on_nan]\n",
    "seed = 23\n",
    "\n",
    "cv_args = dict(cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.2, random_state = seed))\n",
    "\n",
    "compile_args = dict(loss = SparseCategoricalCrossentropy(), #['mse' , SparseCategoricalCrossentropy()]\n",
    "                    init_lr = 1e-2)\n",
    "                      \n",
    "fit_args = dict(epochs = 500,\n",
    "                verbose = verbose,\n",
    "                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6fd589",
   "metadata": {
    "id": "ukhXifxzTaj9",
    "papermill": {
     "duration": 0.010711,
     "end_time": "2025-04-08T22:36:08.670801",
     "exception": false,
     "start_time": "2025-04-08T22:36:08.660090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a06698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:36:08.693685Z",
     "iopub.status.busy": "2025-04-08T22:36:08.693375Z",
     "iopub.status.idle": "2025-04-09T05:45:28.081656Z",
     "shell.execute_reply": "2025-04-09T05:45:28.080763Z"
    },
    "id": "Ymqd_W21y3NK",
    "outputId": "5ca97a2f-f57c-46ee-8f53-f00181ccea90",
    "papermill": {
     "duration": 25759.401831,
     "end_time": "2025-04-09T05:45:28.083611",
     "exception": false,
     "start_time": "2025-04-08T22:36:08.681780",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbj =  23\n",
      "Total trials loaded: 197\n",
      "Shape of X: (197, 64, 3584), Shape of y: (197,)\n",
      "Resampling from 512 to 128.0 Hz.\n",
      "X_train shape: (197, 64, 320, 1), y_train shape: (197,)\n",
      "Running fold 0 with 157 training samples and 40 validation samples\n",
      "Fold 0: train indices: [113 134  84 164  63], val indices: [ 83  73 176  49  76]\n",
      "Training data shape: (157, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 0 training loss: 0.002388168126344681\n",
      "y_true (val): [0 0 1 0 0]\n",
      "y_pred: [0 0 1 1 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [113, 134, 84, 164, 63, 55, 95, 37, 20, 0, 79, 138, 1, 4, 47, 87, 19, 58, 56, 158, 61, 71, 77, 111, 115, 101, 143, 180, 103, 62, 72, 48, 43, 179, 14, 78, 57, 23, 147, 186, 90, 82, 163, 187, 2, 28, 171, 18, 141, 104, 185, 27, 42, 189, 96, 169, 172, 156, 81, 107, 26, 175, 174, 191, 128, 97, 67, 193, 74, 24, 188, 22, 181, 36, 106, 126, 161, 110, 92, 149, 105, 100, 168, 17, 50, 46, 38, 145, 52, 194, 122, 7, 8, 15, 99, 157, 118, 33, 29, 137, 13, 5, 184, 11, 93, 35, 192, 165, 177, 94, 10, 117, 173, 32, 167, 195, 119, 30, 34, 59, 70, 135, 80, 182, 159, 120, 86, 9, 170, 123, 154, 65, 60, 155, 68, 178, 142, 108, 190, 150, 144, 89, 146, 41, 16, 3, 124, 129, 44, 166, 116, 53, 153, 112, 88, 162, 114], 'val_indices': [83, 73, 176, 49, 76, 130, 160, 183, 98, 45, 75, 109, 21, 54, 31, 121, 132, 140, 39, 40, 131, 12, 139, 102, 148, 51, 6, 136, 127, 152, 133, 69, 25, 85, 66, 125, 151, 64, 91, 196], 'accuracy': 0.875, 'kappa': 0.75, 'auc': 0.9750000000000001}\n",
      "New Max Found!\n",
      "Running fold 1 with 157 training samples and 40 validation samples\n",
      "Fold 1: train indices: [151 168  51 186 137], val indices: [147 131  92 176 187]\n",
      "Training data shape: (157, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 1 training loss: 0.0008624638430774212\n",
      "y_true (val): [1 1 0 1 1]\n",
      "y_pred: [1 1 0 1 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [151, 168, 51, 186, 137, 106, 148, 85, 178, 156, 172, 20, 17, 130, 46, 41, 73, 37, 101, 44, 182, 24, 113, 58, 120, 185, 144, 99, 68, 119, 59, 69, 6, 125, 190, 53, 88, 181, 133, 112, 97, 95, 63, 124, 1, 10, 163, 138, 96, 65, 39, 27, 188, 179, 146, 183, 175, 108, 34, 191, 48, 74, 30, 71, 77, 184, 110, 45, 5, 35, 12, 143, 160, 111, 117, 33, 64, 103, 123, 87, 171, 166, 122, 141, 40, 167, 47, 105, 36, 70, 114, 8, 0, 4, 132, 145, 28, 162, 29, 149, 83, 104, 15, 26, 76, 11, 127, 107, 170, 66, 25, 23, 129, 75, 155, 140, 60, 50, 84, 150, 55, 161, 121, 153, 157, 189, 102, 81, 194, 89, 195, 9, 126, 82, 136, 56, 62, 177, 100, 164, 93, 79, 193, 49, 14, 19, 139, 72, 128, 52, 42, 118, 174, 152, 31, 43, 3], 'val_indices': [147, 131, 92, 176, 187, 165, 135, 90, 142, 98, 115, 54, 7, 18, 196, 109, 80, 116, 67, 86, 16, 61, 192, 13, 159, 180, 32, 57, 158, 38, 21, 94, 134, 22, 91, 2, 173, 169, 154, 78], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.99}\n",
      "New Max Found!\n",
      "Running fold 2 with 157 training samples and 40 validation samples\n",
      "Fold 2: train indices: [ 72 177 113  86 167], val indices: [ 45 147 186  12 168]\n",
      "Training data shape: (157, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 2 training loss: 0.0015172347193583846\n",
      "y_true (val): [0 1 1 0 1]\n",
      "y_pred: [0 1 1 0 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [72, 177, 113, 86, 167, 23, 125, 20, 49, 164, 64, 115, 41, 56, 97, 178, 6, 121, 52, 165, 191, 132, 87, 19, 181, 0, 70, 188, 13, 109, 142, 46, 71, 75, 78, 43, 159, 17, 63, 127, 90, 139, 60, 100, 117, 68, 25, 123, 135, 32, 1, 171, 4, 27, 158, 89, 104, 144, 128, 136, 108, 37, 22, 129, 119, 99, 16, 193, 192, 194, 38, 111, 140, 30, 11, 24, 10, 34, 33, 91, 39, 179, 44, 174, 156, 154, 163, 166, 107, 67, 59, 69, 55, 126, 96, 65, 170, 152, 2, 88, 120, 53, 79, 116, 15, 133, 73, 155, 54, 124, 146, 31, 101, 36, 122, 143, 153, 134, 189, 7, 106, 76, 81, 172, 77, 66, 185, 84, 195, 183, 180, 51, 160, 141, 95, 58, 35, 26, 105, 162, 145, 175, 80, 149, 98, 93, 131, 173, 42, 14, 9, 82, 182, 28, 187, 184, 103], 'val_indices': [45, 147, 186, 12, 168, 61, 83, 138, 94, 130, 29, 47, 3, 62, 85, 176, 190, 112, 114, 18, 102, 92, 21, 5, 169, 161, 148, 137, 118, 74, 157, 48, 8, 57, 110, 50, 150, 196, 40, 151], 'accuracy': 0.925, 'kappa': 0.85, 'auc': 0.9775}\n",
      "New Max Found!\n",
      "Running fold 3 with 157 training samples and 40 validation samples\n",
      "Fold 3: train indices: [30 81 22 37 32], val indices: [122 180  94  51 132]\n",
      "Training data shape: (157, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 3 training loss: 0.0008630367228761315\n",
      "y_true (val): [1 1 0 0 1]\n",
      "y_pred: [1 1 1 1 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [30, 81, 22, 37, 32, 105, 9, 29, 18, 170, 151, 82, 31, 149, 26, 15, 147, 83, 92, 178, 195, 11, 50, 12, 176, 54, 148, 124, 73, 3, 102, 177, 25, 60, 159, 86, 173, 16, 119, 140, 72, 1, 138, 7, 136, 98, 196, 4, 117, 152, 108, 181, 44, 17, 134, 172, 169, 75, 121, 71, 41, 193, 35, 61, 55, 123, 155, 165, 95, 156, 91, 85, 38, 74, 49, 89, 101, 184, 107, 188, 130, 106, 28, 40, 68, 179, 90, 65, 34, 141, 0, 84, 93, 185, 43, 118, 111, 104, 77, 78, 69, 45, 145, 160, 47, 183, 168, 62, 24, 139, 96, 6, 164, 110, 48, 66, 143, 194, 109, 146, 13, 56, 52, 53, 128, 23, 115, 137, 175, 63, 126, 190, 120, 129, 33, 88, 166, 21, 8, 59, 187, 157, 116, 162, 144, 174, 125, 163, 131, 133, 99, 76, 10, 171, 158, 87, 192], 'val_indices': [122, 180, 94, 51, 132, 150, 191, 14, 153, 154, 36, 142, 113, 79, 39, 182, 5, 80, 114, 189, 58, 186, 27, 57, 135, 19, 103, 64, 70, 20, 46, 42, 2, 97, 167, 67, 100, 127, 112, 161], 'accuracy': 0.85, 'kappa': 0.7, 'auc': 0.9375}\n",
      "Running fold 4 with 157 training samples and 40 validation samples\n",
      "Fold 4: train indices: [37 47 48 68 55], val indices: [  5  40  42 138 130]\n",
      "Training data shape: (157, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 4 training loss: 0.0024363172706216574\n",
      "y_true (val): [0 0 0 1 1]\n",
      "y_pred: [0 0 1 1 1]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [37, 47, 48, 68, 55, 74, 84, 177, 135, 188, 23, 109, 94, 61, 114, 184, 59, 72, 77, 143, 194, 182, 98, 153, 30, 155, 35, 14, 85, 10, 134, 147, 193, 149, 190, 169, 38, 15, 160, 179, 187, 133, 176, 52, 99, 128, 161, 129, 16, 115, 97, 21, 120, 51, 34, 6, 141, 92, 76, 191, 139, 172, 58, 93, 174, 73, 87, 112, 88, 171, 108, 36, 136, 60, 86, 142, 28, 148, 27, 159, 104, 8, 125, 145, 131, 53, 18, 157, 110, 175, 181, 7, 20, 113, 105, 163, 44, 116, 80, 102, 25, 12, 13, 67, 54, 195, 127, 189, 24, 124, 82, 63, 57, 31, 123, 11, 185, 4, 96, 49, 71, 64, 46, 119, 186, 39, 173, 103, 9, 83, 101, 100, 168, 75, 0, 95, 117, 3, 196, 50, 154, 180, 69, 22, 146, 192, 66, 165, 152, 89, 26, 166, 107, 45, 183, 70, 156], 'val_indices': [5, 40, 42, 138, 130, 126, 158, 17, 170, 178, 140, 79, 137, 164, 90, 1, 151, 33, 78, 132, 122, 62, 118, 144, 29, 2, 32, 43, 81, 41, 150, 167, 162, 121, 65, 106, 91, 19, 111, 56], 'accuracy': 0.875, 'kappa': 0.75, 'auc': 0.98}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.885, 'mean_kappa': 0.77, 'mean_auc': 0.972, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [113, 134, 84, 164, 63, 55, 95, 37, 20, 0, 79, 138, 1, 4, 47, 87, 19, 58, 56, 158, 61, 71, 77, 111, 115, 101, 143, 180, 103, 62, 72, 48, 43, 179, 14, 78, 57, 23, 147, 186, 90, 82, 163, 187, 2, 28, 171, 18, 141, 104, 185, 27, 42, 189, 96, 169, 172, 156, 81, 107, 26, 175, 174, 191, 128, 97, 67, 193, 74, 24, 188, 22, 181, 36, 106, 126, 161, 110, 92, 149, 105, 100, 168, 17, 50, 46, 38, 145, 52, 194, 122, 7, 8, 15, 99, 157, 118, 33, 29, 137, 13, 5, 184, 11, 93, 35, 192, 165, 177, 94, 10, 117, 173, 32, 167, 195, 119, 30, 34, 59, 70, 135, 80, 182, 159, 120, 86, 9, 170, 123, 154, 65, 60, 155, 68, 178, 142, 108, 190, 150, 144, 89, 146, 41, 16, 3, 124, 129, 44, 166, 116, 53, 153, 112, 88, 162, 114], 'val_indices': [83, 73, 176, 49, 76, 130, 160, 183, 98, 45, 75, 109, 21, 54, 31, 121, 132, 140, 39, 40, 131, 12, 139, 102, 148, 51, 6, 136, 127, 152, 133, 69, 25, 85, 66, 125, 151, 64, 91, 196], 'accuracy': 0.875, 'kappa': 0.75, 'auc': 0.9750000000000001}, {'fold_index': 1, 'train_indices': [151, 168, 51, 186, 137, 106, 148, 85, 178, 156, 172, 20, 17, 130, 46, 41, 73, 37, 101, 44, 182, 24, 113, 58, 120, 185, 144, 99, 68, 119, 59, 69, 6, 125, 190, 53, 88, 181, 133, 112, 97, 95, 63, 124, 1, 10, 163, 138, 96, 65, 39, 27, 188, 179, 146, 183, 175, 108, 34, 191, 48, 74, 30, 71, 77, 184, 110, 45, 5, 35, 12, 143, 160, 111, 117, 33, 64, 103, 123, 87, 171, 166, 122, 141, 40, 167, 47, 105, 36, 70, 114, 8, 0, 4, 132, 145, 28, 162, 29, 149, 83, 104, 15, 26, 76, 11, 127, 107, 170, 66, 25, 23, 129, 75, 155, 140, 60, 50, 84, 150, 55, 161, 121, 153, 157, 189, 102, 81, 194, 89, 195, 9, 126, 82, 136, 56, 62, 177, 100, 164, 93, 79, 193, 49, 14, 19, 139, 72, 128, 52, 42, 118, 174, 152, 31, 43, 3], 'val_indices': [147, 131, 92, 176, 187, 165, 135, 90, 142, 98, 115, 54, 7, 18, 196, 109, 80, 116, 67, 86, 16, 61, 192, 13, 159, 180, 32, 57, 158, 38, 21, 94, 134, 22, 91, 2, 173, 169, 154, 78], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.99}, {'fold_index': 2, 'train_indices': [72, 177, 113, 86, 167, 23, 125, 20, 49, 164, 64, 115, 41, 56, 97, 178, 6, 121, 52, 165, 191, 132, 87, 19, 181, 0, 70, 188, 13, 109, 142, 46, 71, 75, 78, 43, 159, 17, 63, 127, 90, 139, 60, 100, 117, 68, 25, 123, 135, 32, 1, 171, 4, 27, 158, 89, 104, 144, 128, 136, 108, 37, 22, 129, 119, 99, 16, 193, 192, 194, 38, 111, 140, 30, 11, 24, 10, 34, 33, 91, 39, 179, 44, 174, 156, 154, 163, 166, 107, 67, 59, 69, 55, 126, 96, 65, 170, 152, 2, 88, 120, 53, 79, 116, 15, 133, 73, 155, 54, 124, 146, 31, 101, 36, 122, 143, 153, 134, 189, 7, 106, 76, 81, 172, 77, 66, 185, 84, 195, 183, 180, 51, 160, 141, 95, 58, 35, 26, 105, 162, 145, 175, 80, 149, 98, 93, 131, 173, 42, 14, 9, 82, 182, 28, 187, 184, 103], 'val_indices': [45, 147, 186, 12, 168, 61, 83, 138, 94, 130, 29, 47, 3, 62, 85, 176, 190, 112, 114, 18, 102, 92, 21, 5, 169, 161, 148, 137, 118, 74, 157, 48, 8, 57, 110, 50, 150, 196, 40, 151], 'accuracy': 0.925, 'kappa': 0.85, 'auc': 0.9775}, {'fold_index': 3, 'train_indices': [30, 81, 22, 37, 32, 105, 9, 29, 18, 170, 151, 82, 31, 149, 26, 15, 147, 83, 92, 178, 195, 11, 50, 12, 176, 54, 148, 124, 73, 3, 102, 177, 25, 60, 159, 86, 173, 16, 119, 140, 72, 1, 138, 7, 136, 98, 196, 4, 117, 152, 108, 181, 44, 17, 134, 172, 169, 75, 121, 71, 41, 193, 35, 61, 55, 123, 155, 165, 95, 156, 91, 85, 38, 74, 49, 89, 101, 184, 107, 188, 130, 106, 28, 40, 68, 179, 90, 65, 34, 141, 0, 84, 93, 185, 43, 118, 111, 104, 77, 78, 69, 45, 145, 160, 47, 183, 168, 62, 24, 139, 96, 6, 164, 110, 48, 66, 143, 194, 109, 146, 13, 56, 52, 53, 128, 23, 115, 137, 175, 63, 126, 190, 120, 129, 33, 88, 166, 21, 8, 59, 187, 157, 116, 162, 144, 174, 125, 163, 131, 133, 99, 76, 10, 171, 158, 87, 192], 'val_indices': [122, 180, 94, 51, 132, 150, 191, 14, 153, 154, 36, 142, 113, 79, 39, 182, 5, 80, 114, 189, 58, 186, 27, 57, 135, 19, 103, 64, 70, 20, 46, 42, 2, 97, 167, 67, 100, 127, 112, 161], 'accuracy': 0.85, 'kappa': 0.7, 'auc': 0.9375}, {'fold_index': 4, 'train_indices': [37, 47, 48, 68, 55, 74, 84, 177, 135, 188, 23, 109, 94, 61, 114, 184, 59, 72, 77, 143, 194, 182, 98, 153, 30, 155, 35, 14, 85, 10, 134, 147, 193, 149, 190, 169, 38, 15, 160, 179, 187, 133, 176, 52, 99, 128, 161, 129, 16, 115, 97, 21, 120, 51, 34, 6, 141, 92, 76, 191, 139, 172, 58, 93, 174, 73, 87, 112, 88, 171, 108, 36, 136, 60, 86, 142, 28, 148, 27, 159, 104, 8, 125, 145, 131, 53, 18, 157, 110, 175, 181, 7, 20, 113, 105, 163, 44, 116, 80, 102, 25, 12, 13, 67, 54, 195, 127, 189, 24, 124, 82, 63, 57, 31, 123, 11, 185, 4, 96, 49, 71, 64, 46, 119, 186, 39, 173, 103, 9, 83, 101, 100, 168, 75, 0, 95, 117, 3, 196, 50, 154, 180, 69, 22, 146, 192, 66, 165, 152, 89, 26, 166, 107, 45, 183, 70, 156], 'val_indices': [5, 40, 42, 138, 130, 126, 158, 17, 170, 178, 140, 79, 137, 164, 90, 1, 151, 33, 78, 132, 122, 62, 118, 144, 29, 2, 32, 43, 81, 41, 150, 167, 162, 121, 65, 106, 91, 19, 111, 56], 'accuracy': 0.875, 'kappa': 0.75, 'auc': 0.98}], 'std_acc': 0.025, 'std_kappa': 0.051, 'std_auc': 0.018}\n",
      "sbj =  5\n",
      "Total trials loaded: 199\n",
      "Shape of X: (199, 64, 3584), Shape of y: (199,)\n",
      "Resampling from 512 to 128.0 Hz.\n",
      "X_train shape: (199, 64, 320, 1), y_train shape: (199,)\n",
      "Running fold 0 with 159 training samples and 40 validation samples\n",
      "Fold 0: train indices: [168 178  79  37 170], val indices: [ 31 161 177 133  76]\n",
      "Training data shape: (159, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 0 training loss: 0.0008051578188315034\n",
      "y_true (val): [0 1 1 1 0]\n",
      "y_pred: [0 0 1 1 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [168, 178, 79, 37, 170, 84, 72, 20, 14, 4, 1, 130, 135, 109, 102, 182, 55, 166, 71, 108, 92, 47, 77, 179, 127, 114, 56, 58, 87, 115, 125, 21, 19, 185, 193, 0, 61, 104, 180, 23, 63, 2, 57, 96, 82, 171, 175, 78, 70, 28, 136, 18, 174, 159, 142, 162, 27, 181, 42, 197, 97, 62, 26, 117, 48, 43, 112, 81, 113, 98, 67, 86, 74, 24, 144, 22, 165, 36, 194, 139, 119, 145, 93, 191, 176, 106, 101, 123, 17, 50, 46, 38, 196, 190, 52, 156, 167, 157, 7, 8, 15, 100, 163, 9, 33, 29, 129, 13, 5, 183, 11, 94, 35, 187, 150, 160, 111, 95, 10, 107, 143, 32, 146, 116, 121, 105, 30, 34, 59, 80, 148, 124, 169, 65, 60, 186, 68, 138, 120, 118, 195, 189, 158, 89, 147, 41, 16, 3, 172, 188, 44, 173, 154, 53, 151, 192, 88, 164, 155], 'val_indices': [31, 161, 177, 133, 76, 75, 103, 12, 83, 110, 6, 66, 99, 85, 73, 54, 152, 149, 122, 39, 40, 184, 45, 140, 141, 137, 25, 51, 132, 128, 134, 153, 198, 131, 90, 64, 49, 126, 91, 69], 'accuracy': 0.85, 'kappa': 0.7, 'auc': 0.8949999999999999}\n",
      "New Max Found!\n",
      "Running fold 1 with 159 training samples and 40 validation samples\n",
      "Fold 1: train indices: [ 17 127  87 123 111], val indices: [ 99  95  57  92 135]\n",
      "Training data shape: (159, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 1 training loss: 0.005733715370297432\n",
      "y_true (val): [1 0 0 0 1]\n",
      "y_pred: [1 0 0 1 1]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [17, 127, 87, 123, 111, 73, 1, 126, 151, 164, 59, 68, 139, 20, 129, 81, 58, 193, 3, 69, 147, 51, 44, 165, 46, 172, 37, 169, 144, 119, 48, 65, 195, 171, 185, 24, 6, 30, 96, 180, 53, 89, 161, 101, 156, 187, 153, 150, 128, 192, 122, 10, 109, 74, 97, 154, 39, 27, 63, 84, 173, 186, 115, 168, 34, 71, 85, 176, 134, 45, 5, 35, 12, 182, 41, 191, 108, 145, 33, 64, 149, 102, 88, 142, 130, 107, 133, 175, 40, 121, 104, 47, 118, 36, 70, 167, 8, 131, 0, 4, 184, 188, 28, 146, 29, 178, 76, 105, 15, 26, 77, 11, 106, 197, 120, 66, 25, 23, 157, 75, 158, 190, 60, 50, 79, 140, 55, 43, 113, 114, 138, 82, 100, 93, 183, 9, 163, 83, 152, 56, 62, 196, 141, 125, 94, 98, 103, 49, 14, 19, 179, 72, 112, 52, 42, 137, 162, 124, 31], 'val_indices': [99, 95, 57, 92, 135, 90, 136, 18, 7, 148, 155, 116, 132, 91, 189, 174, 159, 78, 143, 110, 54, 117, 170, 166, 80, 2, 67, 177, 86, 16, 61, 194, 13, 181, 22, 32, 198, 160, 38, 21], 'accuracy': 0.875, 'kappa': 0.75, 'auc': 0.9475}\n",
      "New Max Found!\n",
      "Running fold 2 with 159 training samples and 40 validation samples\n",
      "Fold 2: train indices: [ 94  85  87 178 144], val indices: [ 33 151 152  83 170]\n",
      "Training data shape: (159, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 2 training loss: 0.0016510443529114127\n",
      "y_true (val): [0 1 1 0 1]\n",
      "y_pred: [0 1 1 0 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [94, 85, 87, 178, 144, 163, 24, 135, 187, 36, 89, 190, 32, 157, 177, 174, 173, 181, 117, 58, 120, 26, 105, 184, 91, 98, 69, 65, 1, 3, 68, 84, 107, 124, 38, 77, 81, 164, 44, 42, 93, 179, 70, 43, 142, 39, 101, 153, 171, 75, 197, 114, 145, 140, 112, 166, 122, 66, 34, 110, 51, 60, 121, 74, 56, 185, 116, 143, 118, 82, 99, 165, 167, 90, 182, 106, 154, 46, 141, 175, 97, 72, 49, 52, 78, 22, 17, 80, 137, 0, 161, 189, 160, 156, 172, 108, 95, 71, 67, 96, 127, 136, 79, 53, 129, 146, 40, 4, 123, 20, 30, 102, 55, 176, 64, 159, 35, 192, 125, 31, 104, 86, 92, 126, 195, 133, 193, 16, 128, 73, 14, 19, 2, 7, 194, 168, 196, 23, 155, 198, 15, 28, 37, 13, 188, 109, 150, 25, 10, 147, 130, 63, 100, 134, 11, 59, 41, 27, 132], 'val_indices': [33, 151, 152, 83, 170, 5, 169, 21, 12, 29, 180, 6, 149, 9, 48, 183, 54, 119, 158, 113, 115, 186, 8, 148, 61, 50, 88, 138, 103, 45, 47, 131, 111, 76, 62, 162, 18, 139, 191, 57], 'accuracy': 0.975, 'kappa': 0.95, 'auc': 0.9974999999999999}\n",
      "New Max Found!\n",
      "Running fold 3 with 159 training samples and 40 validation samples\n",
      "Fold 3: train indices: [ 63  71  75 107  94], val indices: [123 181  96  27 133]\n",
      "Training data shape: (159, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 3 training loss: 0.002390376292169094\n",
      "y_true (val): [1 1 0 0 1]\n",
      "y_pred: [1 1 0 0 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [63, 71, 75, 107, 94, 22, 73, 138, 100, 117, 15, 112, 196, 119, 59, 190, 45, 31, 61, 146, 30, 38, 99, 188, 160, 105, 54, 103, 8, 92, 47, 137, 52, 89, 171, 186, 65, 87, 29, 62, 40, 116, 16, 134, 26, 118, 102, 173, 1, 145, 97, 142, 35, 132, 184, 4, 198, 172, 82, 106, 9, 17, 135, 72, 110, 66, 12, 34, 149, 189, 150, 21, 129, 53, 48, 50, 83, 81, 74, 120, 157, 152, 156, 131, 130, 86, 85, 60, 178, 109, 77, 44, 18, 158, 0, 25, 41, 174, 37, 127, 147, 98, 93, 13, 56, 55, 148, 170, 91, 164, 180, 3, 24, 161, 153, 11, 6, 192, 108, 49, 88, 144, 122, 195, 141, 169, 84, 76, 95, 32, 197, 78, 194, 139, 176, 175, 23, 33, 167, 7, 69, 28, 163, 111, 124, 182, 159, 121, 125, 179, 177, 166, 126, 43, 10, 140, 185, 68, 165], 'val_indices': [123, 181, 96, 27, 133, 151, 193, 14, 154, 155, 36, 143, 114, 79, 39, 183, 5, 80, 115, 191, 46, 187, 57, 58, 136, 90, 104, 64, 70, 19, 20, 2, 51, 42, 168, 67, 101, 128, 113, 162], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.9474999999999999}\n",
      "Running fold 4 with 159 training samples and 40 validation samples\n",
      "Fold 4: train indices: [144  37 124 181  93], val indices: [ 56 163   5  40 133]\n",
      "Training data shape: (159, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 4 training loss: 0.002980009652674198\n",
      "y_true (val): [0 1 0 0 1]\n",
      "y_pred: [0 1 0 1 1]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [144, 37, 124, 181, 93, 137, 103, 61, 59, 105, 196, 39, 95, 23, 170, 64, 164, 160, 121, 143, 10, 184, 35, 14, 82, 116, 69, 97, 157, 175, 107, 52, 177, 149, 114, 85, 109, 67, 167, 189, 47, 76, 173, 113, 38, 15, 48, 6, 30, 117, 150, 178, 108, 80, 155, 147, 190, 195, 16, 132, 161, 98, 21, 34, 51, 55, 77, 58, 192, 94, 191, 74, 88, 130, 89, 148, 153, 176, 36, 128, 60, 118, 87, 102, 28, 120, 27, 182, 194, 8, 162, 125, 115, 53, 96, 129, 166, 135, 197, 75, 7, 101, 0, 136, 169, 140, 44, 104, 86, 100, 25, 188, 12, 13, 68, 54, 154, 174, 46, 24, 111, 83, 63, 57, 31, 180, 11, 72, 4, 49, 3, 84, 186, 142, 134, 20, 9, 73, 156, 18, 185, 50, 198, 183, 70, 22, 106, 146, 66, 187, 126, 90, 26, 110, 172, 45, 158, 71, 99], 'val_indices': [56, 163, 5, 40, 133, 145, 17, 1, 19, 42, 65, 131, 32, 159, 41, 171, 79, 141, 112, 62, 152, 92, 91, 179, 165, 168, 33, 151, 193, 127, 78, 29, 43, 139, 122, 138, 119, 2, 81, 123], 'accuracy': 0.95, 'kappa': 0.9, 'auc': 0.9625}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.91, 'mean_kappa': 0.82, 'mean_auc': 0.95, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [168, 178, 79, 37, 170, 84, 72, 20, 14, 4, 1, 130, 135, 109, 102, 182, 55, 166, 71, 108, 92, 47, 77, 179, 127, 114, 56, 58, 87, 115, 125, 21, 19, 185, 193, 0, 61, 104, 180, 23, 63, 2, 57, 96, 82, 171, 175, 78, 70, 28, 136, 18, 174, 159, 142, 162, 27, 181, 42, 197, 97, 62, 26, 117, 48, 43, 112, 81, 113, 98, 67, 86, 74, 24, 144, 22, 165, 36, 194, 139, 119, 145, 93, 191, 176, 106, 101, 123, 17, 50, 46, 38, 196, 190, 52, 156, 167, 157, 7, 8, 15, 100, 163, 9, 33, 29, 129, 13, 5, 183, 11, 94, 35, 187, 150, 160, 111, 95, 10, 107, 143, 32, 146, 116, 121, 105, 30, 34, 59, 80, 148, 124, 169, 65, 60, 186, 68, 138, 120, 118, 195, 189, 158, 89, 147, 41, 16, 3, 172, 188, 44, 173, 154, 53, 151, 192, 88, 164, 155], 'val_indices': [31, 161, 177, 133, 76, 75, 103, 12, 83, 110, 6, 66, 99, 85, 73, 54, 152, 149, 122, 39, 40, 184, 45, 140, 141, 137, 25, 51, 132, 128, 134, 153, 198, 131, 90, 64, 49, 126, 91, 69], 'accuracy': 0.85, 'kappa': 0.7, 'auc': 0.8949999999999999}, {'fold_index': 1, 'train_indices': [17, 127, 87, 123, 111, 73, 1, 126, 151, 164, 59, 68, 139, 20, 129, 81, 58, 193, 3, 69, 147, 51, 44, 165, 46, 172, 37, 169, 144, 119, 48, 65, 195, 171, 185, 24, 6, 30, 96, 180, 53, 89, 161, 101, 156, 187, 153, 150, 128, 192, 122, 10, 109, 74, 97, 154, 39, 27, 63, 84, 173, 186, 115, 168, 34, 71, 85, 176, 134, 45, 5, 35, 12, 182, 41, 191, 108, 145, 33, 64, 149, 102, 88, 142, 130, 107, 133, 175, 40, 121, 104, 47, 118, 36, 70, 167, 8, 131, 0, 4, 184, 188, 28, 146, 29, 178, 76, 105, 15, 26, 77, 11, 106, 197, 120, 66, 25, 23, 157, 75, 158, 190, 60, 50, 79, 140, 55, 43, 113, 114, 138, 82, 100, 93, 183, 9, 163, 83, 152, 56, 62, 196, 141, 125, 94, 98, 103, 49, 14, 19, 179, 72, 112, 52, 42, 137, 162, 124, 31], 'val_indices': [99, 95, 57, 92, 135, 90, 136, 18, 7, 148, 155, 116, 132, 91, 189, 174, 159, 78, 143, 110, 54, 117, 170, 166, 80, 2, 67, 177, 86, 16, 61, 194, 13, 181, 22, 32, 198, 160, 38, 21], 'accuracy': 0.875, 'kappa': 0.75, 'auc': 0.9475}, {'fold_index': 2, 'train_indices': [94, 85, 87, 178, 144, 163, 24, 135, 187, 36, 89, 190, 32, 157, 177, 174, 173, 181, 117, 58, 120, 26, 105, 184, 91, 98, 69, 65, 1, 3, 68, 84, 107, 124, 38, 77, 81, 164, 44, 42, 93, 179, 70, 43, 142, 39, 101, 153, 171, 75, 197, 114, 145, 140, 112, 166, 122, 66, 34, 110, 51, 60, 121, 74, 56, 185, 116, 143, 118, 82, 99, 165, 167, 90, 182, 106, 154, 46, 141, 175, 97, 72, 49, 52, 78, 22, 17, 80, 137, 0, 161, 189, 160, 156, 172, 108, 95, 71, 67, 96, 127, 136, 79, 53, 129, 146, 40, 4, 123, 20, 30, 102, 55, 176, 64, 159, 35, 192, 125, 31, 104, 86, 92, 126, 195, 133, 193, 16, 128, 73, 14, 19, 2, 7, 194, 168, 196, 23, 155, 198, 15, 28, 37, 13, 188, 109, 150, 25, 10, 147, 130, 63, 100, 134, 11, 59, 41, 27, 132], 'val_indices': [33, 151, 152, 83, 170, 5, 169, 21, 12, 29, 180, 6, 149, 9, 48, 183, 54, 119, 158, 113, 115, 186, 8, 148, 61, 50, 88, 138, 103, 45, 47, 131, 111, 76, 62, 162, 18, 139, 191, 57], 'accuracy': 0.975, 'kappa': 0.95, 'auc': 0.9974999999999999}, {'fold_index': 3, 'train_indices': [63, 71, 75, 107, 94, 22, 73, 138, 100, 117, 15, 112, 196, 119, 59, 190, 45, 31, 61, 146, 30, 38, 99, 188, 160, 105, 54, 103, 8, 92, 47, 137, 52, 89, 171, 186, 65, 87, 29, 62, 40, 116, 16, 134, 26, 118, 102, 173, 1, 145, 97, 142, 35, 132, 184, 4, 198, 172, 82, 106, 9, 17, 135, 72, 110, 66, 12, 34, 149, 189, 150, 21, 129, 53, 48, 50, 83, 81, 74, 120, 157, 152, 156, 131, 130, 86, 85, 60, 178, 109, 77, 44, 18, 158, 0, 25, 41, 174, 37, 127, 147, 98, 93, 13, 56, 55, 148, 170, 91, 164, 180, 3, 24, 161, 153, 11, 6, 192, 108, 49, 88, 144, 122, 195, 141, 169, 84, 76, 95, 32, 197, 78, 194, 139, 176, 175, 23, 33, 167, 7, 69, 28, 163, 111, 124, 182, 159, 121, 125, 179, 177, 166, 126, 43, 10, 140, 185, 68, 165], 'val_indices': [123, 181, 96, 27, 133, 151, 193, 14, 154, 155, 36, 143, 114, 79, 39, 183, 5, 80, 115, 191, 46, 187, 57, 58, 136, 90, 104, 64, 70, 19, 20, 2, 51, 42, 168, 67, 101, 128, 113, 162], 'accuracy': 0.9, 'kappa': 0.8, 'auc': 0.9474999999999999}, {'fold_index': 4, 'train_indices': [144, 37, 124, 181, 93, 137, 103, 61, 59, 105, 196, 39, 95, 23, 170, 64, 164, 160, 121, 143, 10, 184, 35, 14, 82, 116, 69, 97, 157, 175, 107, 52, 177, 149, 114, 85, 109, 67, 167, 189, 47, 76, 173, 113, 38, 15, 48, 6, 30, 117, 150, 178, 108, 80, 155, 147, 190, 195, 16, 132, 161, 98, 21, 34, 51, 55, 77, 58, 192, 94, 191, 74, 88, 130, 89, 148, 153, 176, 36, 128, 60, 118, 87, 102, 28, 120, 27, 182, 194, 8, 162, 125, 115, 53, 96, 129, 166, 135, 197, 75, 7, 101, 0, 136, 169, 140, 44, 104, 86, 100, 25, 188, 12, 13, 68, 54, 154, 174, 46, 24, 111, 83, 63, 57, 31, 180, 11, 72, 4, 49, 3, 84, 186, 142, 134, 20, 9, 73, 156, 18, 185, 50, 198, 183, 70, 22, 106, 146, 66, 187, 126, 90, 26, 110, 172, 45, 158, 71, 99], 'val_indices': [56, 163, 5, 40, 133, 145, 17, 1, 19, 42, 65, 131, 32, 159, 41, 171, 79, 141, 112, 62, 152, 92, 91, 179, 165, 168, 33, 151, 193, 127, 78, 29, 43, 139, 122, 138, 119, 2, 81, 123], 'accuracy': 0.95, 'kappa': 0.9, 'auc': 0.9625}], 'std_acc': 0.046, 'std_kappa': 0.093, 'std_auc': 0.033}\n",
      "sbj =  43\n",
      "Total trials loaded: 200\n",
      "Shape of X: (200, 64, 3584), Shape of y: (200,)\n",
      "Resampling from 512 to 128.0 Hz.\n",
      "X_train shape: (200, 64, 320, 1), y_train shape: (200,)\n",
      "Running fold 0 with 160 training samples and 40 validation samples\n",
      "Fold 0: train indices: [  4 142 183  71  50], val indices: [ 25 107  31 188  83]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 0 training loss: 0.0008330298587679863\n",
      "y_true (val): [0 1 0 1 0]\n",
      "y_pred: [0 1 0 1 0]\n",
      "Appending results for fold 0: {'fold_index': 0, 'train_indices': [4, 142, 183, 71, 50, 179, 125, 131, 117, 60, 82, 55, 89, 21, 157, 47, 5, 42, 11, 19, 23, 172, 148, 99, 140, 34, 146, 115, 48, 147, 93, 2, 182, 138, 43, 57, 158, 187, 128, 18, 160, 33, 97, 14, 44, 177, 196, 61, 56, 174, 46, 67, 8, 101, 7, 41, 129, 184, 198, 98, 190, 74, 169, 24, 159, 173, 15, 70, 163, 58, 186, 72, 27, 87, 81, 26, 122, 96, 120, 65, 119, 102, 123, 167, 94, 130, 135, 77, 192, 175, 20, 37, 16, 0, 180, 144, 52, 145, 106, 139, 63, 9, 36, 153, 126, 17, 59, 29, 164, 30, 85, 156, 53, 79, 38, 118, 124, 193, 171, 35, 13, 151, 110, 95, 149, 136, 165, 168, 109, 88, 84, 92, 3, 121, 114, 143, 1, 10, 195, 28, 197, 103, 137, 152, 113, 112, 32, 189, 62, 199, 78, 68, 176, 161, 22, 155, 108, 80, 181, 166], 'val_indices': [25, 107, 31, 188, 83, 86, 111, 75, 191, 170, 76, 12, 100, 154, 73, 6, 66, 54, 104, 162, 91, 51, 132, 39, 105, 40, 134, 141, 45, 116, 185, 178, 127, 150, 194, 69, 133, 90, 64, 49], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}\n",
      "New Max Found!\n",
      "Running fold 1 with 160 training samples and 40 validation samples\n",
      "Fold 1: train indices: [162  56 128 110  84], val indices: [175 156   7 191  76]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 1 training loss: 0.0006409409688785672\n",
      "y_true (val): [1 1 0 1 0]\n",
      "y_pred: [1 1 0 1 0]\n",
      "Appending results for fold 1: {'fold_index': 1, 'train_indices': [162, 56, 128, 110, 84, 70, 139, 147, 115, 155, 50, 165, 142, 109, 159, 194, 60, 15, 140, 195, 55, 86, 87, 130, 38, 79, 177, 92, 145, 47, 39, 135, 94, 197, 164, 104, 108, 88, 14, 21, 154, 17, 49, 11, 187, 114, 181, 158, 19, 77, 185, 123, 34, 25, 4, 12, 65, 30, 40, 129, 81, 189, 102, 141, 170, 68, 24, 71, 132, 107, 36, 27, 96, 66, 138, 63, 193, 113, 124, 99, 10, 150, 103, 5, 143, 146, 153, 122, 148, 9, 183, 105, 53, 166, 75, 52, 169, 43, 188, 59, 35, 186, 199, 93, 106, 3, 184, 33, 125, 74, 37, 1, 48, 180, 126, 121, 72, 62, 0, 173, 83, 119, 152, 23, 95, 73, 179, 44, 58, 120, 127, 157, 20, 163, 69, 190, 26, 112, 6, 134, 29, 64, 192, 172, 174, 28, 45, 168, 8, 46, 31, 116, 85, 131, 51, 32, 176, 198, 151, 42], 'val_indices': [175, 156, 7, 191, 76, 117, 54, 16, 2, 80, 41, 118, 78, 90, 100, 160, 149, 161, 171, 18, 82, 182, 101, 61, 91, 167, 144, 133, 196, 67, 22, 57, 137, 136, 98, 111, 89, 13, 178, 97], 'accuracy': 0.975, 'kappa': 0.95, 'auc': 0.9974999999999999}\n",
      "Running fold 2 with 160 training samples and 40 validation samples\n",
      "Fold 2: train indices: [  3 109 165  70  15], val indices: [ 58 152 153  54 171]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 2 training loss: 0.0020319693721830845\n",
      "y_true (val): [0 1 1 0 1]\n",
      "y_pred: [0 1 1 0 1]\n",
      "Appending results for fold 2: {'fold_index': 2, 'train_indices': [3, 109, 165, 70, 15, 172, 19, 5, 38, 146, 77, 11, 147, 198, 92, 18, 174, 2, 176, 168, 118, 199, 63, 100, 158, 17, 134, 86, 105, 24, 34, 175, 61, 166, 125, 97, 39, 108, 78, 79, 80, 31, 46, 180, 60, 113, 127, 87, 186, 144, 124, 67, 13, 136, 74, 65, 115, 167, 123, 72, 191, 182, 82, 23, 110, 40, 119, 183, 148, 128, 143, 85, 142, 107, 189, 30, 130, 145, 103, 96, 164, 151, 98, 64, 101, 43, 81, 49, 75, 69, 89, 106, 66, 162, 154, 161, 122, 188, 121, 10, 20, 91, 52, 111, 137, 57, 93, 178, 102, 138, 55, 47, 133, 42, 12, 196, 99, 177, 44, 169, 37, 193, 157, 1, 190, 0, 26, 141, 155, 173, 28, 27, 16, 32, 7, 195, 131, 197, 14, 156, 185, 36, 95, 71, 51, 160, 194, 117, 56, 68, 126, 41, 59, 135, 129, 4, 53, 90, 94, 179], 'val_indices': [58, 152, 153, 54, 171, 88, 170, 45, 21, 84, 181, 73, 150, 22, 29, 184, 25, 120, 159, 114, 116, 187, 6, 149, 83, 33, 50, 139, 104, 9, 48, 132, 112, 35, 76, 163, 8, 140, 192, 62], 'accuracy': 0.975, 'kappa': 0.95, 'auc': 1.0}\n",
      "Running fold 3 with 160 training samples and 40 validation samples\n",
      "Fold 3: train indices: [66 43 45 22 69], val indices: [ 20  14 169 144 196]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 3 training loss: 0.001196115161292255\n",
      "y_true (val): [0 0 1 1 1]\n",
      "y_pred: [0 0 1 1 1]\n",
      "Appending results for fold 3: {'fold_index': 3, 'train_indices': [66, 43, 45, 22, 69, 48, 44, 60, 123, 74, 179, 25, 150, 171, 132, 28, 165, 96, 73, 113, 127, 72, 135, 52, 38, 23, 122, 100, 177, 92, 137, 148, 12, 8, 91, 159, 172, 125, 187, 32, 29, 173, 40, 108, 4, 151, 37, 186, 34, 21, 1, 33, 190, 176, 35, 146, 143, 68, 160, 136, 107, 103, 53, 49, 141, 131, 15, 50, 54, 199, 126, 154, 7, 193, 0, 89, 55, 56, 10, 98, 134, 106, 161, 168, 138, 112, 63, 88, 83, 174, 121, 81, 65, 61, 109, 78, 26, 47, 104, 9, 153, 180, 31, 94, 71, 77, 18, 195, 167, 75, 164, 162, 86, 85, 157, 119, 3, 84, 149, 142, 82, 95, 175, 191, 139, 133, 117, 24, 76, 41, 62, 198, 6, 111, 183, 110, 30, 11, 99, 178, 93, 87, 13, 166, 189, 170, 185, 118, 130, 197, 120, 128, 158, 140, 16, 59, 145, 101, 17, 181], 'val_indices': [20, 14, 169, 144, 196, 105, 67, 182, 36, 39, 97, 57, 64, 58, 79, 90, 188, 194, 155, 129, 102, 192, 27, 5, 124, 116, 80, 184, 152, 163, 46, 156, 114, 147, 115, 70, 19, 2, 51, 42], 'accuracy': 0.95, 'kappa': 0.9, 'auc': 0.9974999999999999}\n",
      "Running fold 4 with 160 training samples and 40 validation samples\n",
      "Fold 4: train indices: [ 52   4 194  64  46], val indices: [123  35  89 183   0]\n",
      "Training data shape: (160, 64, 320, 1), Validation data shape: (40, 64, 320, 1)\n",
      "Fold 4 training loss: 0.00024792630574665964\n",
      "y_true (val): [1 0 0 1 0]\n",
      "y_pred: [1 0 0 1 0]\n",
      "Appending results for fold 4: {'fold_index': 4, 'train_indices': [52, 4, 194, 64, 46, 59, 38, 21, 193, 157, 28, 57, 17, 154, 184, 97, 139, 125, 102, 182, 30, 143, 180, 50, 126, 13, 161, 100, 15, 135, 45, 74, 153, 51, 115, 189, 181, 187, 37, 133, 118, 168, 16, 136, 66, 73, 19, 174, 22, 24, 71, 192, 63, 144, 122, 72, 54, 175, 147, 155, 85, 107, 149, 103, 69, 31, 27, 145, 7, 84, 77, 191, 88, 79, 114, 49, 90, 124, 5, 111, 36, 172, 131, 61, 32, 185, 173, 2, 166, 39, 148, 110, 34, 199, 65, 186, 23, 91, 159, 170, 93, 119, 195, 116, 129, 76, 53, 158, 101, 130, 178, 156, 6, 94, 138, 167, 96, 68, 132, 165, 92, 140, 12, 137, 44, 188, 160, 83, 47, 60, 98, 81, 105, 78, 58, 11, 25, 26, 82, 141, 171, 196, 62, 48, 1, 177, 70, 121, 8, 163, 109, 95, 104, 43, 117, 150, 14, 197, 127, 33], 'val_indices': [123, 35, 89, 183, 0, 80, 75, 134, 10, 87, 120, 40, 151, 67, 86, 99, 152, 42, 20, 176, 162, 169, 41, 190, 56, 9, 142, 146, 112, 108, 3, 128, 198, 106, 55, 29, 18, 164, 113, 179], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}\n",
      "Final cross-validation results: {'params': [], 'mean_acc': 0.98, 'mean_kappa': 0.96, 'mean_auc': 0.999, 'mean_f1_left': array([0., 0., 0., 0., 0.]), 'mean_f1_right': array([0., 0., 0., 0., 0.]), 'mean_recall_left': array([0., 0., 0., 0., 0.]), 'mean_recall_right': array([0., 0., 0., 0., 0.]), 'mean_precision_left': array([0., 0., 0., 0., 0.]), 'mean_precision_right': array([0., 0., 0., 0., 0.]), 'all_folds': [{'fold_index': 0, 'train_indices': [4, 142, 183, 71, 50, 179, 125, 131, 117, 60, 82, 55, 89, 21, 157, 47, 5, 42, 11, 19, 23, 172, 148, 99, 140, 34, 146, 115, 48, 147, 93, 2, 182, 138, 43, 57, 158, 187, 128, 18, 160, 33, 97, 14, 44, 177, 196, 61, 56, 174, 46, 67, 8, 101, 7, 41, 129, 184, 198, 98, 190, 74, 169, 24, 159, 173, 15, 70, 163, 58, 186, 72, 27, 87, 81, 26, 122, 96, 120, 65, 119, 102, 123, 167, 94, 130, 135, 77, 192, 175, 20, 37, 16, 0, 180, 144, 52, 145, 106, 139, 63, 9, 36, 153, 126, 17, 59, 29, 164, 30, 85, 156, 53, 79, 38, 118, 124, 193, 171, 35, 13, 151, 110, 95, 149, 136, 165, 168, 109, 88, 84, 92, 3, 121, 114, 143, 1, 10, 195, 28, 197, 103, 137, 152, 113, 112, 32, 189, 62, 199, 78, 68, 176, 161, 22, 155, 108, 80, 181, 166], 'val_indices': [25, 107, 31, 188, 83, 86, 111, 75, 191, 170, 76, 12, 100, 154, 73, 6, 66, 54, 104, 162, 91, 51, 132, 39, 105, 40, 134, 141, 45, 116, 185, 178, 127, 150, 194, 69, 133, 90, 64, 49], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}, {'fold_index': 1, 'train_indices': [162, 56, 128, 110, 84, 70, 139, 147, 115, 155, 50, 165, 142, 109, 159, 194, 60, 15, 140, 195, 55, 86, 87, 130, 38, 79, 177, 92, 145, 47, 39, 135, 94, 197, 164, 104, 108, 88, 14, 21, 154, 17, 49, 11, 187, 114, 181, 158, 19, 77, 185, 123, 34, 25, 4, 12, 65, 30, 40, 129, 81, 189, 102, 141, 170, 68, 24, 71, 132, 107, 36, 27, 96, 66, 138, 63, 193, 113, 124, 99, 10, 150, 103, 5, 143, 146, 153, 122, 148, 9, 183, 105, 53, 166, 75, 52, 169, 43, 188, 59, 35, 186, 199, 93, 106, 3, 184, 33, 125, 74, 37, 1, 48, 180, 126, 121, 72, 62, 0, 173, 83, 119, 152, 23, 95, 73, 179, 44, 58, 120, 127, 157, 20, 163, 69, 190, 26, 112, 6, 134, 29, 64, 192, 172, 174, 28, 45, 168, 8, 46, 31, 116, 85, 131, 51, 32, 176, 198, 151, 42], 'val_indices': [175, 156, 7, 191, 76, 117, 54, 16, 2, 80, 41, 118, 78, 90, 100, 160, 149, 161, 171, 18, 82, 182, 101, 61, 91, 167, 144, 133, 196, 67, 22, 57, 137, 136, 98, 111, 89, 13, 178, 97], 'accuracy': 0.975, 'kappa': 0.95, 'auc': 0.9974999999999999}, {'fold_index': 2, 'train_indices': [3, 109, 165, 70, 15, 172, 19, 5, 38, 146, 77, 11, 147, 198, 92, 18, 174, 2, 176, 168, 118, 199, 63, 100, 158, 17, 134, 86, 105, 24, 34, 175, 61, 166, 125, 97, 39, 108, 78, 79, 80, 31, 46, 180, 60, 113, 127, 87, 186, 144, 124, 67, 13, 136, 74, 65, 115, 167, 123, 72, 191, 182, 82, 23, 110, 40, 119, 183, 148, 128, 143, 85, 142, 107, 189, 30, 130, 145, 103, 96, 164, 151, 98, 64, 101, 43, 81, 49, 75, 69, 89, 106, 66, 162, 154, 161, 122, 188, 121, 10, 20, 91, 52, 111, 137, 57, 93, 178, 102, 138, 55, 47, 133, 42, 12, 196, 99, 177, 44, 169, 37, 193, 157, 1, 190, 0, 26, 141, 155, 173, 28, 27, 16, 32, 7, 195, 131, 197, 14, 156, 185, 36, 95, 71, 51, 160, 194, 117, 56, 68, 126, 41, 59, 135, 129, 4, 53, 90, 94, 179], 'val_indices': [58, 152, 153, 54, 171, 88, 170, 45, 21, 84, 181, 73, 150, 22, 29, 184, 25, 120, 159, 114, 116, 187, 6, 149, 83, 33, 50, 139, 104, 9, 48, 132, 112, 35, 76, 163, 8, 140, 192, 62], 'accuracy': 0.975, 'kappa': 0.95, 'auc': 1.0}, {'fold_index': 3, 'train_indices': [66, 43, 45, 22, 69, 48, 44, 60, 123, 74, 179, 25, 150, 171, 132, 28, 165, 96, 73, 113, 127, 72, 135, 52, 38, 23, 122, 100, 177, 92, 137, 148, 12, 8, 91, 159, 172, 125, 187, 32, 29, 173, 40, 108, 4, 151, 37, 186, 34, 21, 1, 33, 190, 176, 35, 146, 143, 68, 160, 136, 107, 103, 53, 49, 141, 131, 15, 50, 54, 199, 126, 154, 7, 193, 0, 89, 55, 56, 10, 98, 134, 106, 161, 168, 138, 112, 63, 88, 83, 174, 121, 81, 65, 61, 109, 78, 26, 47, 104, 9, 153, 180, 31, 94, 71, 77, 18, 195, 167, 75, 164, 162, 86, 85, 157, 119, 3, 84, 149, 142, 82, 95, 175, 191, 139, 133, 117, 24, 76, 41, 62, 198, 6, 111, 183, 110, 30, 11, 99, 178, 93, 87, 13, 166, 189, 170, 185, 118, 130, 197, 120, 128, 158, 140, 16, 59, 145, 101, 17, 181], 'val_indices': [20, 14, 169, 144, 196, 105, 67, 182, 36, 39, 97, 57, 64, 58, 79, 90, 188, 194, 155, 129, 102, 192, 27, 5, 124, 116, 80, 184, 152, 163, 46, 156, 114, 147, 115, 70, 19, 2, 51, 42], 'accuracy': 0.95, 'kappa': 0.9, 'auc': 0.9974999999999999}, {'fold_index': 4, 'train_indices': [52, 4, 194, 64, 46, 59, 38, 21, 193, 157, 28, 57, 17, 154, 184, 97, 139, 125, 102, 182, 30, 143, 180, 50, 126, 13, 161, 100, 15, 135, 45, 74, 153, 51, 115, 189, 181, 187, 37, 133, 118, 168, 16, 136, 66, 73, 19, 174, 22, 24, 71, 192, 63, 144, 122, 72, 54, 175, 147, 155, 85, 107, 149, 103, 69, 31, 27, 145, 7, 84, 77, 191, 88, 79, 114, 49, 90, 124, 5, 111, 36, 172, 131, 61, 32, 185, 173, 2, 166, 39, 148, 110, 34, 199, 65, 186, 23, 91, 159, 170, 93, 119, 195, 116, 129, 76, 53, 158, 101, 130, 178, 156, 6, 94, 138, 167, 96, 68, 132, 165, 92, 140, 12, 137, 44, 188, 160, 83, 47, 60, 98, 81, 105, 78, 58, 11, 25, 26, 82, 141, 171, 196, 62, 48, 1, 177, 70, 121, 8, 163, 109, 95, 104, 43, 117, 150, 14, 197, 127, 33], 'val_indices': [123, 35, 89, 183, 0, 80, 75, 134, 10, 87, 120, 40, 151, 67, 86, 99, 152, 42, 20, 176, 162, 169, 41, 190, 56, 9, 142, 146, 112, 108, 3, 128, 198, 106, 55, 29, 18, 164, 113, 179], 'accuracy': 1.0, 'kappa': 1.0, 'auc': 1.0}], 'std_acc': 0.019, 'std_kappa': 0.037, 'std_auc': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "\n",
    "subjects = [23,5,43]\n",
    "\n",
    "for sbj in subjects[:]:\n",
    "  print('sbj = ', sbj)\n",
    "  load_args['sbj'] = sbj\n",
    "  results = train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed)\n",
    "  with open('sbj' + str(load_args['sbj']) + '.txt', 'wb') as f:\n",
    "    dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a313318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:45:28.111501Z",
     "iopub.status.busy": "2025-04-09T05:45:28.110849Z",
     "iopub.status.idle": "2025-04-09T05:45:30.244217Z",
     "shell.execute_reply": "2025-04-09T05:45:30.243325Z"
    },
    "id": "V7-P0xjwzXVX",
    "outputId": "270dceef-351d-48d1-f71e-2c3367c7fdac",
    "papermill": {
     "duration": 2.149098,
     "end_time": "2025-04-09T05:45:30.245981",
     "exception": false,
     "start_time": "2025-04-09T05:45:28.096883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: sbj23.h5 (deflated 65%)\r\n",
      "  adding: sbj43.h5 (deflated 64%)\r\n",
      "  adding: sbj5.h5 (deflated 65%)\r\n",
      "  adding: sbj23.txt (deflated 42%)\r\n",
      "  adding: sbj43.txt (deflated 43%)\r\n",
      "  adding: sbj5.txt (deflated 43%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip Models_64ch_TCNet.zip ./*.h5 \n",
    "!zip Results_64ch_TCNet.zip ./*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd21850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:45:30.274456Z",
     "iopub.status.busy": "2025-04-09T05:45:30.274129Z",
     "iopub.status.idle": "2025-04-09T05:45:30.278034Z",
     "shell.execute_reply": "2025-04-09T05:45:30.277279Z"
    },
    "papermill": {
     "duration": 0.019772,
     "end_time": "2025-04-09T05:45:30.279780",
     "exception": false,
     "start_time": "2025-04-09T05:45:30.260008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle as pkl\n",
    "\n",
    "#with open(file= '/kaggle/working/sbj14.txt', mode = 'rb' ) as f:\n",
    "#    results_64ch_ShallowConvNet = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f4cb5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:45:30.307159Z",
     "iopub.status.busy": "2025-04-09T05:45:30.306747Z",
     "iopub.status.idle": "2025-04-09T05:45:30.310462Z",
     "shell.execute_reply": "2025-04-09T05:45:30.309646Z"
    },
    "papermill": {
     "duration": 0.018981,
     "end_time": "2025-04-09T05:45:30.311970",
     "exception": false,
     "start_time": "2025-04-09T05:45:30.292989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_64ch_ShallowConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c2c0cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:45:30.339580Z",
     "iopub.status.busy": "2025-04-09T05:45:30.339110Z",
     "iopub.status.idle": "2025-04-09T05:45:30.342551Z",
     "shell.execute_reply": "2025-04-09T05:45:30.341791Z"
    },
    "papermill": {
     "duration": 0.018947,
     "end_time": "2025-04-09T05:45:30.344168",
     "exception": false,
     "start_time": "2025-04-09T05:45:30.325221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(file= '/kaggle/working/sbj2.txt', mode = 'rb' ) as f:\n",
    " #   results_64ch_ShallowConvNet = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c4a4eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:45:30.373256Z",
     "iopub.status.busy": "2025-04-09T05:45:30.373036Z",
     "iopub.status.idle": "2025-04-09T05:45:30.376514Z",
     "shell.execute_reply": "2025-04-09T05:45:30.375750Z"
    },
    "papermill": {
     "duration": 0.020756,
     "end_time": "2025-04-09T05:45:30.378291",
     "exception": false,
     "start_time": "2025-04-09T05:45:30.357535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_64ch_ShallowConvNet"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1645904,
     "sourceId": 2702213,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1269900,
     "sourceId": 2702226,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2984453,
     "sourceId": 5137200,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3008205,
     "sourceId": 5175158,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25924.788688,
   "end_time": "2025-04-09T05:45:33.708987",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-08T22:33:28.920299",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
